{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Quanta.Guru This online document helps the absolute beginners to persue the future direction in coding and Quantum Computing. The lesson starts with fundamental of running D-Wave Ocean, IBM-Q Qiskit, Microsoft Q#, Google Cirq and Rigetti pyQuil. Join our facebook group and follow us at GitHub","title":"Home"},{"location":"#quantaguru","text":"This online document helps the absolute beginners to persue the future direction in coding and Quantum Computing. The lesson starts with fundamental of running D-Wave Ocean, IBM-Q Qiskit, Microsoft Q#, Google Cirq and Rigetti pyQuil. Join our facebook group and follow us at GitHub","title":"Quanta.Guru"},{"location":"Fundamentals/Q/q/","text":"Coming soon!","title":"Q#"},{"location":"Fundamentals/Q/q/#coming-soon","text":"","title":"Coming soon!"},{"location":"Fundamentals/cirq/cirq/","text":"Coming soon!","title":"Cirq"},{"location":"Fundamentals/cirq/cirq/#coming-soon","text":"","title":"Coming soon!"},{"location":"Fundamentals/dwave/dwave/","text":"Quantum Computing with D-Wave Quantum Computer Open in GitHub Introduction source Quantum computing has the potential to help solve some of the most complex technical, scientific, national defense, and commercial problems that organizations face. For quantum computing, as for classical, the first step in solving a problem is to express it in a mathematical formulation compatible with the underlying physical hardware. D-Wave systems solve problems that can be mapped onto an Ising model or a quadratic unconstrained binary optimization (QUBO) problem . is an objective function of N binary variables represented as an upper-diagonal matrix Q, where diagonal terms are the linear coefficients and the nonzero off-diagonal terms the quadratic coefficients. The mapped problem must be formulated to be compatible with the constraints of the physical system and as robust as possible to analog control errors. Example from constraint satisfaction problem (CSP) This example solves a map coloring problem to demonstrate an out-of-the-box use of Ocean\u2019s classical-quantum hybrid sampler, dwave-hybrid Kerberos , that enables you to solve problems of arbitrary structure and size. Map coloring is an example of a constraint satisfaction problem (CSP) . CSPs require that all a problem\u2019s variables be assigned values, out of a finite domain, that result in the satisfying of all constraints. The map-coloring CSP is to assign a color to each region of a map such that any two regions sharing a border have different colors. The Map Coloring advanced example demonstrates lower-level coding of a similar problem, which gives the user more control over the solution procedure but requires the knowledge of some system parameters (e.g., knowing the maximum number of supported variables for the problem). Example Problem With Many Variables demonstrates the hybrid approach to problem solving in more detail by explicitly configuring the classical and quantum workflows. import networkx as nx G = nx . read_adjlist( 'usa.adj' , delimiter = ',' ) Quantum Implementation Solution Steps Section Solving Problems on a D-Wave System describes the process of solving problems on the quantum computer in two steps: - (1) Formulate the problem as a binary quadratic model (BQM) and - (2) Solve the BQM with a D-wave system or classical sampler. In this example, a function in Ocean software handles both steps. Our task is mainly to select the sampler used to solve the problem. For graph G(V,E) of the map problem\u2014no two vertices, V, connected by an edge, E, should select the same color from set C\u2014construct a cost function with binary variables, $x_{v,c}=1$ when $v\u2208V$ selects color $c\u2208C$, by implementing two constraints: $$(\\sum_c x_{v,c} -1)^2$$ which has minimum energy (zero) when vertices select one color only, and $$\\sum_c \\sum_{v_a,v_b \\in E} x_{v_a,c} x_{v_b,c},$$ which adds a penalty if the vertices of an edge select the same color. $$E(x_v,x_{v_a,v_b}) = \\sum_v (\\sum_c x_{v,c} -1)^2 + \\sum_c \\sum_{v_a,v_b \\in E} x_{v_a,c} x_{v_b,c}.$$ The minima (ground states) of this QUBO have zero energy for viable solutions. This formulation of the generic problem must still be applied to the map and color set and then embedded. This section solved the map-coloring problem using a technique of formulating a problem as a constraint satisfaction problem (CSP) using penalty functions. The CSP Reformulation with Penalty Functions section describes this technique and demonstrates it in detail on a simple two-color, two-region part of this map-coloring problem in the Example of CSP reformulation with penalty functions section. import dwave_networkx as dnx from hybrid.reference.kerberos import KerberosSampler Prepare coloring scheme using D-Wave kerberoSamplers coloring = dnx . min_vertex_coloring(G, sampler = KerberosSampler(),\\ chromatic_ub = 4 ,\\ max_iter = 10 ,\\ convergence = 3 ) set (coloring . values()) {0, 1, 2, 3} import matplotlib.pyplot as plt plt . figure(figsize = [ 12 , 10 ]) node_colors = [coloring . get(node) for node in G . nodes()] # adjust the next line if using a different map if dnx . is_vertex_coloring(G, coloring): nx . draw(G, pos = nx . shell_layout(G, nlist = [ list (G . nodes)[x:x + 10 ] \\ for x in range ( 0 , 50 , 10 )] + [[ list (G . nodes)[ 50 ]]]),\\ with_labels = True , \\ node_color = node_colors,\\ node_size = 400 ,\\ cmap = plt . cm . rainbow) plt . show()","title":"D-wave"},{"location":"Fundamentals/dwave/dwave/#quantum-computing-with-d-wave-quantum-computer","text":"Open in GitHub","title":"Quantum Computing with D-Wave Quantum Computer"},{"location":"Fundamentals/dwave/dwave/#introduction-source","text":"Quantum computing has the potential to help solve some of the most complex technical, scientific, national defense, and commercial problems that organizations face. For quantum computing, as for classical, the first step in solving a problem is to express it in a mathematical formulation compatible with the underlying physical hardware. D-Wave systems solve problems that can be mapped onto an Ising model or a quadratic unconstrained binary optimization (QUBO) problem . is an objective function of N binary variables represented as an upper-diagonal matrix Q, where diagonal terms are the linear coefficients and the nonzero off-diagonal terms the quadratic coefficients. The mapped problem must be formulated to be compatible with the constraints of the physical system and as robust as possible to analog control errors.","title":"Introduction source"},{"location":"Fundamentals/dwave/dwave/#example-from-constraint-satisfaction-problem-csp","text":"This example solves a map coloring problem to demonstrate an out-of-the-box use of Ocean\u2019s classical-quantum hybrid sampler, dwave-hybrid Kerberos , that enables you to solve problems of arbitrary structure and size. Map coloring is an example of a constraint satisfaction problem (CSP) . CSPs require that all a problem\u2019s variables be assigned values, out of a finite domain, that result in the satisfying of all constraints. The map-coloring CSP is to assign a color to each region of a map such that any two regions sharing a border have different colors. The Map Coloring advanced example demonstrates lower-level coding of a similar problem, which gives the user more control over the solution procedure but requires the knowledge of some system parameters (e.g., knowing the maximum number of supported variables for the problem). Example Problem With Many Variables demonstrates the hybrid approach to problem solving in more detail by explicitly configuring the classical and quantum workflows. import networkx as nx G = nx . read_adjlist( 'usa.adj' , delimiter = ',' )","title":"Example from constraint satisfaction problem (CSP)"},{"location":"Fundamentals/dwave/dwave/#quantum-implementation","text":"","title":"Quantum Implementation"},{"location":"Fundamentals/dwave/dwave/#solution-steps","text":"Section Solving Problems on a D-Wave System describes the process of solving problems on the quantum computer in two steps: - (1) Formulate the problem as a binary quadratic model (BQM) and - (2) Solve the BQM with a D-wave system or classical sampler. In this example, a function in Ocean software handles both steps. Our task is mainly to select the sampler used to solve the problem. For graph G(V,E) of the map problem\u2014no two vertices, V, connected by an edge, E, should select the same color from set C\u2014construct a cost function with binary variables, $x_{v,c}=1$ when $v\u2208V$ selects color $c\u2208C$, by implementing two constraints: $$(\\sum_c x_{v,c} -1)^2$$ which has minimum energy (zero) when vertices select one color only, and $$\\sum_c \\sum_{v_a,v_b \\in E} x_{v_a,c} x_{v_b,c},$$ which adds a penalty if the vertices of an edge select the same color. $$E(x_v,x_{v_a,v_b}) = \\sum_v (\\sum_c x_{v,c} -1)^2 + \\sum_c \\sum_{v_a,v_b \\in E} x_{v_a,c} x_{v_b,c}.$$ The minima (ground states) of this QUBO have zero energy for viable solutions. This formulation of the generic problem must still be applied to the map and color set and then embedded. This section solved the map-coloring problem using a technique of formulating a problem as a constraint satisfaction problem (CSP) using penalty functions. The CSP Reformulation with Penalty Functions section describes this technique and demonstrates it in detail on a simple two-color, two-region part of this map-coloring problem in the Example of CSP reformulation with penalty functions section. import dwave_networkx as dnx from hybrid.reference.kerberos import KerberosSampler Prepare coloring scheme using D-Wave kerberoSamplers coloring = dnx . min_vertex_coloring(G, sampler = KerberosSampler(),\\ chromatic_ub = 4 ,\\ max_iter = 10 ,\\ convergence = 3 ) set (coloring . values()) {0, 1, 2, 3} import matplotlib.pyplot as plt plt . figure(figsize = [ 12 , 10 ]) node_colors = [coloring . get(node) for node in G . nodes()] # adjust the next line if using a different map if dnx . is_vertex_coloring(G, coloring): nx . draw(G, pos = nx . shell_layout(G, nlist = [ list (G . nodes)[x:x + 10 ] \\ for x in range ( 0 , 50 , 10 )] + [[ list (G . nodes)[ 50 ]]]),\\ with_labels = True , \\ node_color = node_colors,\\ node_size = 400 ,\\ cmap = plt . cm . rainbow) plt . show()","title":"Solution Steps"},{"location":"Fundamentals/ibmq/ibmq/","text":"Coming soon!","title":"IMB-Q"},{"location":"Fundamentals/ibmq/ibmq/#coming-soon","text":"","title":"Coming soon!"},{"location":"GettingStarted/anaconda/","text":"Installing Python To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python. Note- Linux: For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook Note - Cloud For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Guide to starting Python"},{"location":"GettingStarted/anaconda/#installing-python","text":"To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python.","title":"Installing Python"},{"location":"GettingStarted/anaconda/#note-linux","text":"For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook","title":"Note- Linux:"},{"location":"GettingStarted/anaconda/#note-cloud","text":"For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Note - Cloud"},{"location":"GettingStarted/env/","text":"Python Environment Basics To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = \"/Users/username/anaconda/bin: $PATH \" or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup Environments Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate Saving and loading environments A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export > environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, > environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml . Listing environments If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root . Removing environments If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ). Using environments One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican . Sharing environments When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda. More to learn To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"Setting up Python Environment"},{"location":"GettingStarted/env/#python-environment","text":"","title":"Python Environment"},{"location":"GettingStarted/env/#basics","text":"To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = \"/Users/username/anaconda/bin: $PATH \" or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup","title":"Basics"},{"location":"GettingStarted/env/#environments","text":"Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate","title":"Environments"},{"location":"GettingStarted/env/#saving-and-loading-environments","text":"A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export > environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, > environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml .","title":"Saving and loading environments"},{"location":"GettingStarted/env/#listing-environments","text":"If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root .","title":"Listing environments"},{"location":"GettingStarted/env/#removing-environments","text":"If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ).","title":"Removing environments"},{"location":"GettingStarted/env/#using-environments","text":"One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican .","title":"Using environments"},{"location":"GettingStarted/env/#sharing-environments","text":"When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda.","title":"Sharing environments"},{"location":"GettingStarted/env/#more-to-learn","text":"To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"More to learn"},{"location":"GettingStarted/git/","text":"How to git Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m \"First commit\" Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"How to Git"},{"location":"GettingStarted/git/#how-to-git","text":"Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m \"First commit\" Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"How to git"},{"location":"GettingStarted/jupyter/","text":"Installing Jupyter Notebook By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Installing Jupyter Notebook"},{"location":"GettingStarted/jupyter/#installing-jupyter-notebook","text":"By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Installing Jupyter Notebook"},{"location":"GettingStarted/lib/","text":"Python Libraries Following are the best Python Libraries: TensorFlow Scikit-Learn Numpy Keras PyTorch LightGBM Eli5 SciPy Theano Pandas","title":"Guide to Python Libraries"},{"location":"GettingStarted/lib/#python-libraries","text":"Following are the best Python Libraries: TensorFlow Scikit-Learn Numpy Keras PyTorch LightGBM Eli5 SciPy Theano Pandas","title":"Python Libraries"},{"location":"References/ref/","text":"References Mkdocs Deploy MkDocs MkDoc Black and Blue Codehilit Syntax highlight all Syntax highlight code","title":"Reference"},{"location":"References/ref/#references","text":"","title":"References"},{"location":"References/ref/#mkdocs","text":"Deploy MkDocs MkDoc Black and Blue Codehilit Syntax highlight all Syntax highlight code","title":"Mkdocs"}]}