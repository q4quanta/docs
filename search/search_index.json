{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Quanta.Guru This online document helps the absolute beginners to persue the future direction in coding and Quantum Computing. The lesson starts with fundamental of qubits, quantum gates and quantum circuits, quantum algorithms and quantum machine learning.","title":"Home"},{"location":"#quantaguru","text":"This online document helps the absolute beginners to persue the future direction in coding and Quantum Computing. The lesson starts with fundamental of qubits, quantum gates and quantum circuits, quantum algorithms and quantum machine learning.","title":"Quanta.Guru"},{"location":"comingsoon/","text":"Coming Soon Under construction","title":"Comingsoon"},{"location":"comingsoon/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"GettingStarted/anaconda/","text":"Installing Python To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python. Note- Linux: For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook Note - Cloud For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Guide to starting Python"},{"location":"GettingStarted/anaconda/#installing-python","text":"To install Anaconda Python follow the instruction at Anaconda Distribution Website . Based on the operating system select the proper version of the Anaconda package and install it in your PC. After you successfully install the proper version, you will get anaconda application in you PC which will look like the figure below: Best way to start with is the \"Jupyter notebook\". Lunch the jupyter notebook to start with Python.","title":"Installing Python"},{"location":"GettingStarted/anaconda/#note-linux","text":"For Linux user, it could be little bit tricky. SOme time it becomes hard to locate anaconda path to the environment so you need to point the python you want to use. Please, run the command below to point the python: bash export PATH=/home/ubuntu/anaconda3/bin:$PATH There is 'base' or 'anaconda3' environment by defult. You can find the list of available environmet by typing following command on the terminal bash conda env list To start the 'base' environment type bash source activate base To install new package for example 'jupyter notebook' type bash pip install jupyter notebook After sucessfully installing Jupyter notebook, tye following to start it bash Jupyter notebook","title":"Note- Linux:"},{"location":"GettingStarted/anaconda/#note-cloud","text":"For running Jupyter notebook in AWS cloud, it is important to open the \"8888\" to \"8889\" with TCP rule with IP \"0.0.0.0\" and allow to be opend from anywhere. Once port is open, type following to bash jupyter notebook --ip=0.0.0.0 --no-browser","title":"Note - Cloud"},{"location":"GettingStarted/env/","text":"Python Environment Basics To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = \"/Users/username/anaconda/bin: $PATH \" or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup Environments Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate Saving and loading environments A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export > environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, > environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml . Listing environments If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root . Removing environments If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ). Using environments One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican . Sharing environments When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda. More to learn To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"Setting up Python Environment"},{"location":"GettingStarted/env/#python-environment","text":"","title":"Python Environment"},{"location":"GettingStarted/env/#basics","text":"To avoid errors later, it's best to update all the packages in the default environment. Open the Anaconda Prompt application. In the prompt, run the following commands: conda upgrade conda conda upgrade --all If you are seeing the following \"conda command not found\" and are using ZShell, you have to do the following: export PATH = \"/Users/username/anaconda/bin: $PATH \" or update above command line to your .zsh_config file. Once you have Anaconda installed, managing packages is fairly straightforward. To install a package, type conda install package_name in your terminal. For example, to install numpy, type conda install numpy. You can install multiple packages at the same time. Something like conda install numpy scipy pandas will install all those packages simultaneously. It's also possible to specify which version of a package you want by adding the version number such as conda install numpy = 1 .10. Conda also automatically installs dependencies for you. For example scipy depends on numpy, it uses and requires numpy. If you install just scipy (conda install scipy), Conda will also install numpy if it isn't already installed. Most of the commands are pretty intuitive. To uninstall, use conda remove package_name To update a package conda update package_name If you want to update all packages in an environment, which is often useful, use conda update --all And finally, to list installed packages, it's conda list If you don't know the exact name of the package you're looking for, you can try searching with conda search search_term For example, I know I want to install Beautiful Soup, but I'm not sure of the exact package name. So, I try conda search beautifulsoup","title":"Basics"},{"location":"GettingStarted/env/#environments","text":"Conda can be used to create environments to isolate your projects. To create an environment, use conda create -n env_name list of packages in your terminal Here -n env_name sets the name of your environment (-n for name) and list of packages is the list of packages you want installed in the environment. For example, to create an environment named my_env and install numpy in it, type conda create -n my_env numpy When creating an environment, you can specify which version of Python to install in the environment. This is useful when you're working with code in both Python 2.x and Python 3.x. To create an environment with a specific Python version, do something like conda create -n py3 python = 3 or conda create -n py2 python = 2 I actually have both of these environments on my personal computer. I use them as general environments not tied to any specific project, but rather for general work with each Python version easily accessible. These commands will install the most recent version of Python 3 and 2, respectively. To install a specific version, use conda create -n py python = 3 .3 for Python 3.3. Once you have an environment created, use source activate my_env to enter it on OSX/Linux. On Windows, use activate my_env When you're in the environment, you'll see the environment name in the terminal prompt. Something like (my_env) ~ $. The environment has only a few packages installed by default, plus the ones you installed when creating it. You can check this out with conda list. Installing packages in the environment is the same as before: conda install package_name Only this time, the specific packages you install will only be available when you're in the environment. To leave the environment, type source deactivate ( on OSX/Linux ) On Windows, use deactivate","title":"Environments"},{"location":"GettingStarted/env/#saving-and-loading-environments","text":"A really useful feature is sharing environments so others can install all the packages used in your code, with the correct versions. You can save the packages to a YAML file with conda env export > environment.yaml The first part conda env export writes out all the packages in the environment, including the Python version. Above you can see the name of the environment and all the dependencies (along with versions) are listed. The second part of the export command, > environment.yaml writes the exported text to a YAML file environment.yaml . This file can now be shared and others will be able to create the same environment you used for the project. To create an environment from an environment file use conda env create -f environment.yaml This will create a new environment with the same name listed in environment.yaml .","title":"Saving and loading environments"},{"location":"GettingStarted/env/#listing-environments","text":"If you forget what your environments are named (happens to me sometimes), use conda env list to list out all the environments you've created. You should see a list of environments, there will be an asterisk next to the environment you're currently in. The default environment, the environment used when you aren't in one, is called root .","title":"Listing environments"},{"location":"GettingStarted/env/#removing-environments","text":"If there are environments you don't use anymore, conda env remove -n env_name will remove the specified environment (here, named env_name ).","title":"Removing environments"},{"location":"GettingStarted/env/#using-environments","text":"One thing that\u2019s helped me tremendously is having separate environments for Python 2 and Python 3. I used conda create -n py2 python = 2 and conda create -n py3 python = 3 to create two separate environments, py2 and py3 . Now I have a general use environment for each Python version. In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.) I\u2019ve also found it useful to create environments for each project I\u2019m working on. It works great for non-data related projects too like web apps with Flask. For example, I have an environment for my personal blog using Pelican .","title":"Using environments"},{"location":"GettingStarted/env/#sharing-environments","text":"When sharing your code on GitHub, it's good practice to make an environment file and include it in the repository. This will make it easier for people to install all the dependencies for your code. I also usually include a pip requirements.txt file using pip freeze ( learn more here ) for people not using conda.","title":"Sharing environments"},{"location":"GettingStarted/env/#more-to-learn","text":"To learn more about conda and how it fits in the Python ecosystem, check out this article by Jake Vanderplas: Conda myths and misconceptions. And here's the conda documentation you can reference later.","title":"More to learn"},{"location":"GettingStarted/git/","text":"How to git Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m \"First commit\" Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"How to Git"},{"location":"GettingStarted/git/#how-to-git","text":"Reference : How to Git Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. git init Add the files in your new local repository. This stages them for the first commit. git add . Adds the files in the local repository and stages them for commit. To unstage a file, use 'git reset HEAD YOUR-FILE'. Commit the files that you've staged in your local repository. git commit -m \"First commit\" Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use 'git reset --soft HEAD~1' and commit and add the file again. Copy remote repository URL fieldAt the top of your GitHub repository's Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. git remote add origin remote repository URL Sets the new remote git remote -v Verifies the new remote URL Push the changes in your local repository to GitHub. git push origin master Pushes the changes in your local repository up to the remote repository you specified as the origin","title":"How to git"},{"location":"GettingStarted/jupyter/","text":"Installing Jupyter Notebook By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Installing Jupyter Notebook"},{"location":"GettingStarted/jupyter/#installing-jupyter-notebook","text":"By far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. You'll be able to use notebooks from the default environment. To install Jupyter notebooks in a conda environment, use conda install jupyter notebook Jupyter notebooks are also available through pip with pip install jupyter notebook Markdown Cheatsheet : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Convert a notebook to an HTML file, in your terminal use jupyter nbconvert --to html notebook.ipynb Convert: https://nbconvert.readthedocs.io/en/latest/usage.html To create the slideshow from the notebook file, you'll need to use nbconvert: jupyter nbconvert notebook.ipynb --to slides This just converts the notebook to the necessary files for the slideshow, but you need to serve it with an HTTP server to actually see the presentation. To convert it and immediately see it, use jupyter nbconvert notebook.ipynb --to slides --post serve This will open up the slideshow in your browser so you can present it. panda presentation: presentation","title":"Installing Jupyter Notebook"},{"location":"GettingStarted/lib/","text":"Python Libraries Following are the best Python Libraries: TensorFlow Scikit-Learn Numpy Keras PyTorch LightGBM Eli5 SciPy Theano Pandas","title":"Guide to Python Libraries"},{"location":"GettingStarted/lib/#python-libraries","text":"Following are the best Python Libraries: TensorFlow Scikit-Learn Numpy Keras PyTorch LightGBM Eli5 SciPy Theano Pandas","title":"Python Libraries"},{"location":"References/ref/","text":"References Mkdocs Deploy MkDocs MkDoc Black and Blue Codehilit Syntax highlight all Syntax highlight code","title":"Reference"},{"location":"References/ref/#references","text":"","title":"References"},{"location":"References/ref/#mkdocs","text":"Deploy MkDocs MkDoc Black and Blue Codehilit Syntax highlight all Syntax highlight code","title":"Mkdocs"},{"location":"algorithms/grover/grover/","text":"Coming Soon Under construction","title":"Grover's Algorithm"},{"location":"algorithms/grover/grover/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"algorithms/hhl/hhl/","text":"Qiskit Aqua: Solving linear systems of equations with the HHL algorithm Contributors David Bucher [1] , Jan Mueggenburg [1] , Gawel Kus [1] , Isabel Haide [1] , Shubha Deutschle [1] , Harry Barowski [1] , Dominik Steenken [1] , and Albert Frisch [1] Affiliation [1] IBMQ The HHL algorithm (after the author\u2019s surnames Harrow-Hassidim-Lloyd) [1] is a quantum algorithm to solve systems of linear equations\\(A \\vec{x} = \\vec{b}\\)To perform this calculation quantum mechanically, we need in general 4 main steps requiring three qubit registers: First, we have to express the vector \\(\\vec{b}\\) as a quantum state \\(|b\\rangle\\) on a quantum register. Now, we have to decompose\\(\\vec{b}\\)into a superposition of eigenvectors of A remembering on the linear combination of the vector \\(\\vec{b}\\) We achieve this using the Quantum Phase Estimation algorithm (Quantum Phase Estimation (QPE)). Since the matrix is hereby diagonalized wherefore\\(A\\)is easily invertible. The inversion of the eigenvector base of \\(A\\) is achieved by rotating an ancillary qubit by an angle \\(\\arcsin \\left( \\frac{C}{\\lambda {\\text{i}}} \\right)\\) around the y-axis where \\(\\lambda {\\text{i}}\\) are the eigenvalues of \\(A\\) Now, we obtain the state \\(A^{-1}|b\\rangle = |x \\rangle\\) . We need to uncompute the register storing the eigenvalues using the inverse QPE. We measure the ancillary qubit whereby the measurement of 1 indicates that the matrix inversion was successful. The inverse QPE leaves the system in a state proportional to the solution vector \\(|x\\rangle \\) In many cases one is not interested in the single vector elements of \\(|x\\rangle\\) but only on certain properties. These are accessible by applying a problem-specific operator \\(M\\) o the state \\(|x\\rangle\\) Another use-case of the HHL algorithm is the implementation in a larger quantum program. Currently only hermitian matrices with a dimension of \\(2^n\\) are supported. Take into account that in the general case, the entries of\\(\\vec{x}\\)can not be efficiently read out because we would need to know all coefficients describing the quantum state. In the following examples, we ignore this constraint and show for our small linear system as a proof of principle that\\(\\vec{x}\\) is calculated correctly. References: A. W. Harrow, A. Hassidim, and S. Lloyd, Phys. Rev. Lett. 103, 150502 (2009), e-print arXiv 0811.3171 S. Barz, I. Kassal, M. Ringbauer, Y. Ole Lipp, B. Daki\u0107, A. Aspuru-Guzik, and P. Walther, Sci Rep. 4: 6115 (2014), e-print arXiv 1302.1210 from qiskit.aqua import run_algorithm from qiskit.aqua.input import LinearSystemInput from qiskit.quantum_info import state_fidelity from qiskit.aqua.algorithms.classical import ExactLSsolver import numpy as np qiskit.providers.ibmq.ibmqprovider params = { 'problem' : { 'name' : 'linear_system' }, 'algorithm' : { 'name' : 'HHL' }, 'eigs' : { 'expansion_mode' : 'suzuki' , 'expansion_order' : 2 , 'name' : 'EigsQPE' , 'num_ancillae' : 3 , 'num_time_slices' : 50 }, 'reciprocal' : { 'name' : 'Lookup' }, 'backend' : { 'provider' : 'qiskit.BasicAer' , 'name' : 'statevector_simulator' } } def fidelity (hhl, ref): solution_hhl_normed = hhl / np . linalg . norm(hhl) solution_ref_normed = ref / np . linalg . norm(ref) fidelity = state_fidelity(solution_hhl_normed, solution_ref_normed) print ( \"fidelity %f \" % fidelity) 2x2 diagonal matrix First, we show an example for running the HHL algorithm with Qiskit Aqua on a diagonal matrix as input $$ A= \\begin{bmatrix} 1 & 0 \\ 0 & 2 \\end{bmatrix}$$ with the vector \\(\\vec{b}= \\left( \\begin{array}{c}1 \\ 4 \\end{array} \\right)\\) The result dictionary contains several return values. The HHL solution for\\(\\vec{x}\\)is accessible by the key 'solution' . For comparison, also the classical solution of the linear system of equations is calculated using standard linear algebra functions in numpy. The fidelity between the HHL solution and the classical solution is also given in the output. Furthermore, the probability is shown with which HHL was running successfully, i.e. the HHL ancillary qubit has been measured to be\\(|1\\rangle\\). matrix = [[ 1 , 0 ], [ 0 , 2 ]] vector = [ 1 , 4 ] params[ 'input' ] = { 'name' : 'LinearSystemInput' , 'matrix' : matrix, 'vector' : vector } result = run_algorithm(params) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) solution [1.05859+0.j 1.99245+0.j] classical solution [1. 2.] probability 0.024630 fidelity 0.999389 The probabilty that HHL runs successfully depends on the constant\\(C\\)(see step 3. in the introduction). In the HHL algorithm,\\(C\\)can be given as the parameter scale \\(\\in [0,1]\\)In the above example scale is not defined in the params dictionary and the HHL algorithm initializes it to the smallest possible eigenvalue before execution. Alternatively, we can set scale to 0.5 and see how the results are influenced thereby. params2 = params params2[ 'reciprocal' ] = { 'scale' : 0.5 } result = run_algorithm(params2) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) solution [0.84664+0.j 2.01762+0.j] classical solution [1. 2.] probability 0.361437 fidelity 0.995605 If you want to know how many qubits are required (circuit width) or how large the maximum number of gates applied to a single qubit (circuit depth) is, you can print it out by print ( \"circuit_width\" , result[ 'circuit_info' ][ 'width' ]) print ( \"circuit_depth\" , result[ 'circuit_info' ][ 'depth' ]) circuit_width 7 circuit_depth 12256 2x2 non-diagonal matrix Here we show an example for running the HHL algorithm with Qiskit Aqua on a non-diagonal matrix as input $$ A = \\begin{bmatrix} 1 & 3 \\\\ 3 & 2 \\end{bmatrix}$$ with the vector \\(\\vec{b}= \\left( \\begin{array}{c}1 \\\\ 1 \\end{array} \\right) \\) matrix = [[ 1 , 3 ], [ 3 , 2 ]] vector = [ 1 , 1 ] params3 = params params3[ 'input' ] = { 'name' : 'LinearSystemInput' , 'matrix' : matrix, 'vector' : vector } params3[ 'reciprocal' ] = { 'negative_evals' : True } params3[ 'eigs' ] = { 'negative_evals' : True } result = run_algorithm(params3) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) solution [0.14223-5.e-05j 0.28622+7.e-05j] classical solution [0.14286 0.28571] probability 0.000316 fidelity 0.999994 Compared to the the first example, the circuit depth is increased approximately by a factor of 6 print ( \"circuit_width\" , result[ 'circuit_info' ][ 'width' ]) print ( \"circuit_depth\" , result[ 'circuit_info' ][ 'depth' ]) circuit_width 11 circuit_depth 73313 8x8 non-diagonal matrix For simplicity, we show a HHL execution of a linear systom of equations defined by the following 8x8 dimensional matrix $$ A = \\begin{bmatrix} 4 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\ 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 8 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 5 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 2 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\ 1 & 0 & 0 & 0 & 0 & 0 & 0 & 5 \\end{bmatrix}$$ and the vector \\(\\vec{b}= \\left( \\begin{array}{c}1 \\\\0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{array} \\right)\\) matrix = [[ 4 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ], [ 0 , 3 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 0 , 8 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 0 , 0 , 5 , 0 , 0 , 0 , 0 ], [ 0 , 0 , 0 , 0 , 2 , 1 , 0 , 0 ], [ 0 , 0 , 0 , 0 , 1 , 1 , 0 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 ], [ 1 , 0 , 0 , 0 , 0 , 0 , 0 , 5 ]] vector = [ 1 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ] params4 = params params4[ 'input' ] = { 'name' : 'LinearSystemInput' , 'matrix' : matrix, 'vector' : vector } result = run_algorithm(params4) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) solution [ 0.18195-0.j 0. -0.j 0. -0.j -0. +0.j 0. +0.j -0. +0.j -0. -0.j 0.18041+0.j] classical solution [0.21053 0. 0. 0. 0. 0. 0. 0.15789] probability 0.935566 fidelity 0.981173 Considering the circuit depth and circuit width print ( \"circuit_width\" , result[ 'circuit_info' ][ 'width' ]) print ( \"circuit_depth\" , result[ 'circuit_info' ][ 'depth' ]) circuit_width 9 circuit_depth 315281 4x4 randomly-generated matrix Now, we show the application of HHL on a randomly-generated 4x4 matrix. We use the function random_hermitian to generate a random hermitian matrix and initialize the random seed to achieve reproducibility of the HHL run. Since the matrix can have negative eigenvalues, the params dictionary has to be modified by \"negative_evals\": True in \"eigs\" and \"reciprocal\" , respectively. We choose $$\\vec{b}= \\left( \\begin{array}{c}1 \\ 2 \\ 3 \\ 1 \\end{array} \\right)$$ from qiskit import BasicAer from qiskit.aqua import QuantumInstance from qiskit.aqua.algorithms.single_sample import HHL from qiskit.aqua.utils import random_hermitian It is needed for this example to define the \"initial_state\", the \"qft\" and the \"iqft\" additionally: params5 = params params5[ 'algorithm' ] = { 'truncate_powerdim' : False , 'truncate_hermitian' : False } params5[ 'reciprocal' ] = { 'name' : 'Lookup' , 'negative_evals' : True } params5[ 'eigs' ] = { 'expansion_mode' : 'suzuki' , 'expansion_order' : 2 , 'name' : 'EigsQPE' , 'negative_evals' : True , 'num_ancillae' : 6 , 'num_time_slices' : 70 } params5[ 'initial_state' ] = { 'name' : 'CUSTOM' } params5[ 'iqft' ] = { 'name' : 'STANDARD' } params5[ 'qft' ] = { 'name' : 'STANDARD' } In this example, we create an instance of the HHL class and run the algorithm with an input that is created programatically. To get the same pseudo-random matrix for every run, we set the random seed by using np.random.seed(1) . # set the random seed to get the same pseudo-random matrix for every run np . random . seed( 1 ) matrix = random_hermitian( 4 ) vector = [ 1 , 2 , 3 , 1 ] print ( \"random matrix:\" ) m = np . array(matrix) print (np . round(m, 3 )) algo_input = LinearSystemInput(matrix = matrix, vector = vector) hhl = HHL . init_params(params5, algo_input) backend = BasicAer . get_backend( 'statevector_simulator' ) quantum_instance = QuantumInstance(backend = backend) result = hhl . run(quantum_instance) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) random matrix: [[ 0.284-0.j -0.257-0.051j -0.124+0.033j 0.038+0.023j] [-0.257+0.051j 0.404+0.j 0.067-0.079j 0.054+0.055j] [-0.124-0.033j 0.067+0.079j 0.282-0.j 0.043+0.004j] [ 0.038-0.023j 0.054-0.055j 0.043-0.004j 0.206-0.j ]] solution [ 79.9768 +4.52073j 60.28272 +3.09211j 37.51853 -9.5858j -35.02324+26.46894j] classical solution [ 76.1399 +1.92451j 57.30622 +1.20141j 35.96381-10.07775j -32.03837+25.90593j] probability 0.256771 fidelity 0.999946 The circuit width and depth are print ( \"circuit_width\" , result[ 'circuit_info' ][ 'width' ]) print ( \"circuit_depth\" , result[ 'circuit_info' ][ 'depth' ]) circuit_width 12 circuit_depth 973537","title":"Linear Equation (HHL)"},{"location":"algorithms/hhl/hhl/#qiskit-aqua-solving-linear-systems-of-equations-with-the-hhl-algorithm","text":"","title":"Qiskit Aqua: Solving linear systems of equations with the HHL algorithm"},{"location":"algorithms/hhl/hhl/#contributors","text":"David Bucher [1] , Jan Mueggenburg [1] , Gawel Kus [1] , Isabel Haide [1] , Shubha Deutschle [1] , Harry Barowski [1] , Dominik Steenken [1] , and Albert Frisch [1]","title":"Contributors"},{"location":"algorithms/hhl/hhl/#affiliation","text":"[1] IBMQ The HHL algorithm (after the author\u2019s surnames Harrow-Hassidim-Lloyd) [1] is a quantum algorithm to solve systems of linear equations\\(A \\vec{x} = \\vec{b}\\)To perform this calculation quantum mechanically, we need in general 4 main steps requiring three qubit registers: First, we have to express the vector \\(\\vec{b}\\) as a quantum state \\(|b\\rangle\\) on a quantum register. Now, we have to decompose\\(\\vec{b}\\)into a superposition of eigenvectors of A remembering on the linear combination of the vector \\(\\vec{b}\\) We achieve this using the Quantum Phase Estimation algorithm (Quantum Phase Estimation (QPE)). Since the matrix is hereby diagonalized wherefore\\(A\\)is easily invertible. The inversion of the eigenvector base of \\(A\\) is achieved by rotating an ancillary qubit by an angle \\(\\arcsin \\left( \\frac{C}{\\lambda {\\text{i}}} \\right)\\) around the y-axis where \\(\\lambda {\\text{i}}\\) are the eigenvalues of \\(A\\) Now, we obtain the state \\(A^{-1}|b\\rangle = |x \\rangle\\) . We need to uncompute the register storing the eigenvalues using the inverse QPE. We measure the ancillary qubit whereby the measurement of 1 indicates that the matrix inversion was successful. The inverse QPE leaves the system in a state proportional to the solution vector \\(|x\\rangle \\) In many cases one is not interested in the single vector elements of \\(|x\\rangle\\) but only on certain properties. These are accessible by applying a problem-specific operator \\(M\\) o the state \\(|x\\rangle\\) Another use-case of the HHL algorithm is the implementation in a larger quantum program. Currently only hermitian matrices with a dimension of \\(2^n\\) are supported. Take into account that in the general case, the entries of\\(\\vec{x}\\)can not be efficiently read out because we would need to know all coefficients describing the quantum state. In the following examples, we ignore this constraint and show for our small linear system as a proof of principle that\\(\\vec{x}\\) is calculated correctly. References: A. W. Harrow, A. Hassidim, and S. Lloyd, Phys. Rev. Lett. 103, 150502 (2009), e-print arXiv 0811.3171 S. Barz, I. Kassal, M. Ringbauer, Y. Ole Lipp, B. Daki\u0107, A. Aspuru-Guzik, and P. Walther, Sci Rep. 4: 6115 (2014), e-print arXiv 1302.1210 from qiskit.aqua import run_algorithm from qiskit.aqua.input import LinearSystemInput from qiskit.quantum_info import state_fidelity from qiskit.aqua.algorithms.classical import ExactLSsolver import numpy as np qiskit.providers.ibmq.ibmqprovider params = { 'problem' : { 'name' : 'linear_system' }, 'algorithm' : { 'name' : 'HHL' }, 'eigs' : { 'expansion_mode' : 'suzuki' , 'expansion_order' : 2 , 'name' : 'EigsQPE' , 'num_ancillae' : 3 , 'num_time_slices' : 50 }, 'reciprocal' : { 'name' : 'Lookup' }, 'backend' : { 'provider' : 'qiskit.BasicAer' , 'name' : 'statevector_simulator' } } def fidelity (hhl, ref): solution_hhl_normed = hhl / np . linalg . norm(hhl) solution_ref_normed = ref / np . linalg . norm(ref) fidelity = state_fidelity(solution_hhl_normed, solution_ref_normed) print ( \"fidelity %f \" % fidelity)","title":"Affiliation"},{"location":"algorithms/hhl/hhl/#2x2-diagonal-matrix","text":"First, we show an example for running the HHL algorithm with Qiskit Aqua on a diagonal matrix as input $$ A= \\begin{bmatrix} 1 & 0 \\ 0 & 2 \\end{bmatrix}$$ with the vector \\(\\vec{b}= \\left( \\begin{array}{c}1 \\ 4 \\end{array} \\right)\\) The result dictionary contains several return values. The HHL solution for\\(\\vec{x}\\)is accessible by the key 'solution' . For comparison, also the classical solution of the linear system of equations is calculated using standard linear algebra functions in numpy. The fidelity between the HHL solution and the classical solution is also given in the output. Furthermore, the probability is shown with which HHL was running successfully, i.e. the HHL ancillary qubit has been measured to be\\(|1\\rangle\\). matrix = [[ 1 , 0 ], [ 0 , 2 ]] vector = [ 1 , 4 ] params[ 'input' ] = { 'name' : 'LinearSystemInput' , 'matrix' : matrix, 'vector' : vector } result = run_algorithm(params) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) solution [1.05859+0.j 1.99245+0.j] classical solution [1. 2.] probability 0.024630 fidelity 0.999389 The probabilty that HHL runs successfully depends on the constant\\(C\\)(see step 3. in the introduction). In the HHL algorithm,\\(C\\)can be given as the parameter scale \\(\\in [0,1]\\)In the above example scale is not defined in the params dictionary and the HHL algorithm initializes it to the smallest possible eigenvalue before execution. Alternatively, we can set scale to 0.5 and see how the results are influenced thereby. params2 = params params2[ 'reciprocal' ] = { 'scale' : 0.5 } result = run_algorithm(params2) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) solution [0.84664+0.j 2.01762+0.j] classical solution [1. 2.] probability 0.361437 fidelity 0.995605 If you want to know how many qubits are required (circuit width) or how large the maximum number of gates applied to a single qubit (circuit depth) is, you can print it out by print ( \"circuit_width\" , result[ 'circuit_info' ][ 'width' ]) print ( \"circuit_depth\" , result[ 'circuit_info' ][ 'depth' ]) circuit_width 7 circuit_depth 12256","title":"2x2 diagonal matrix"},{"location":"algorithms/hhl/hhl/#2x2-non-diagonal-matrix","text":"Here we show an example for running the HHL algorithm with Qiskit Aqua on a non-diagonal matrix as input $$ A = \\begin{bmatrix} 1 & 3 \\\\ 3 & 2 \\end{bmatrix}$$ with the vector \\(\\vec{b}= \\left( \\begin{array}{c}1 \\\\ 1 \\end{array} \\right) \\) matrix = [[ 1 , 3 ], [ 3 , 2 ]] vector = [ 1 , 1 ] params3 = params params3[ 'input' ] = { 'name' : 'LinearSystemInput' , 'matrix' : matrix, 'vector' : vector } params3[ 'reciprocal' ] = { 'negative_evals' : True } params3[ 'eigs' ] = { 'negative_evals' : True } result = run_algorithm(params3) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) solution [0.14223-5.e-05j 0.28622+7.e-05j] classical solution [0.14286 0.28571] probability 0.000316 fidelity 0.999994 Compared to the the first example, the circuit depth is increased approximately by a factor of 6 print ( \"circuit_width\" , result[ 'circuit_info' ][ 'width' ]) print ( \"circuit_depth\" , result[ 'circuit_info' ][ 'depth' ]) circuit_width 11 circuit_depth 73313","title":"2x2 non-diagonal matrix"},{"location":"algorithms/hhl/hhl/#8x8-non-diagonal-matrix","text":"For simplicity, we show a HHL execution of a linear systom of equations defined by the following 8x8 dimensional matrix $$ A = \\begin{bmatrix} 4 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\ 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 8 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 5 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 2 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\ 1 & 0 & 0 & 0 & 0 & 0 & 0 & 5 \\end{bmatrix}$$ and the vector \\(\\vec{b}= \\left( \\begin{array}{c}1 \\\\0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{array} \\right)\\) matrix = [[ 4 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ], [ 0 , 3 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 0 , 8 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 0 , 0 , 5 , 0 , 0 , 0 , 0 ], [ 0 , 0 , 0 , 0 , 2 , 1 , 0 , 0 ], [ 0 , 0 , 0 , 0 , 1 , 1 , 0 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 ], [ 1 , 0 , 0 , 0 , 0 , 0 , 0 , 5 ]] vector = [ 1 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ] params4 = params params4[ 'input' ] = { 'name' : 'LinearSystemInput' , 'matrix' : matrix, 'vector' : vector } result = run_algorithm(params4) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) solution [ 0.18195-0.j 0. -0.j 0. -0.j -0. +0.j 0. +0.j -0. +0.j -0. -0.j 0.18041+0.j] classical solution [0.21053 0. 0. 0. 0. 0. 0. 0.15789] probability 0.935566 fidelity 0.981173 Considering the circuit depth and circuit width print ( \"circuit_width\" , result[ 'circuit_info' ][ 'width' ]) print ( \"circuit_depth\" , result[ 'circuit_info' ][ 'depth' ]) circuit_width 9 circuit_depth 315281","title":"8x8 non-diagonal matrix"},{"location":"algorithms/hhl/hhl/#4x4-randomly-generated-matrix","text":"Now, we show the application of HHL on a randomly-generated 4x4 matrix. We use the function random_hermitian to generate a random hermitian matrix and initialize the random seed to achieve reproducibility of the HHL run. Since the matrix can have negative eigenvalues, the params dictionary has to be modified by \"negative_evals\": True in \"eigs\" and \"reciprocal\" , respectively. We choose $$\\vec{b}= \\left( \\begin{array}{c}1 \\ 2 \\ 3 \\ 1 \\end{array} \\right)$$ from qiskit import BasicAer from qiskit.aqua import QuantumInstance from qiskit.aqua.algorithms.single_sample import HHL from qiskit.aqua.utils import random_hermitian It is needed for this example to define the \"initial_state\", the \"qft\" and the \"iqft\" additionally: params5 = params params5[ 'algorithm' ] = { 'truncate_powerdim' : False , 'truncate_hermitian' : False } params5[ 'reciprocal' ] = { 'name' : 'Lookup' , 'negative_evals' : True } params5[ 'eigs' ] = { 'expansion_mode' : 'suzuki' , 'expansion_order' : 2 , 'name' : 'EigsQPE' , 'negative_evals' : True , 'num_ancillae' : 6 , 'num_time_slices' : 70 } params5[ 'initial_state' ] = { 'name' : 'CUSTOM' } params5[ 'iqft' ] = { 'name' : 'STANDARD' } params5[ 'qft' ] = { 'name' : 'STANDARD' } In this example, we create an instance of the HHL class and run the algorithm with an input that is created programatically. To get the same pseudo-random matrix for every run, we set the random seed by using np.random.seed(1) . # set the random seed to get the same pseudo-random matrix for every run np . random . seed( 1 ) matrix = random_hermitian( 4 ) vector = [ 1 , 2 , 3 , 1 ] print ( \"random matrix:\" ) m = np . array(matrix) print (np . round(m, 3 )) algo_input = LinearSystemInput(matrix = matrix, vector = vector) hhl = HHL . init_params(params5, algo_input) backend = BasicAer . get_backend( 'statevector_simulator' ) quantum_instance = QuantumInstance(backend = backend) result = hhl . run(quantum_instance) print ( \"solution \" , np . round(result[ 'solution' ], 5 )) result_ref = ExactLSsolver(matrix, vector) . run() print ( \"classical solution \" , np . round(result_ref[ 'solution' ], 5 )) print ( \"probability %f \" % result[ 'probability_result' ]) fidelity(result[ 'solution' ], result_ref[ 'solution' ]) random matrix: [[ 0.284-0.j -0.257-0.051j -0.124+0.033j 0.038+0.023j] [-0.257+0.051j 0.404+0.j 0.067-0.079j 0.054+0.055j] [-0.124-0.033j 0.067+0.079j 0.282-0.j 0.043+0.004j] [ 0.038-0.023j 0.054-0.055j 0.043-0.004j 0.206-0.j ]] solution [ 79.9768 +4.52073j 60.28272 +3.09211j 37.51853 -9.5858j -35.02324+26.46894j] classical solution [ 76.1399 +1.92451j 57.30622 +1.20141j 35.96381-10.07775j -32.03837+25.90593j] probability 0.256771 fidelity 0.999946 The circuit width and depth are print ( \"circuit_width\" , result[ 'circuit_info' ][ 'width' ]) print ( \"circuit_depth\" , result[ 'circuit_info' ][ 'depth' ]) circuit_width 12 circuit_depth 973537","title":"4x4 randomly-generated matrix"},{"location":"algorithms/qft/qft/","text":"Quantum Fourier Transform In quantum computing, the quantum Fourier transform (for short: QFT) is a linear transformation on quantum bits, and is the quantum analogue of the inverse discrete Fourier transform. The quantum Fourier transform is a part of many quantum algorithms, notably Shor's algorithm for factoring and computing the discrete logarithm, the quantum phase estimation algorithm for estimating the eigenvalues of a unitary operator, and algorithms for the hidden subgroup problem Wikipedia . Import 'Quiskit' libraries. % matplotlib inline # Importing standard Qiskit libraries and configuring account from qiskit import QuantumCircuit,QuantumRegister,ClassicalRegister from qiskit import execute, Aer, IBMQ from qiskit.compiler import transpile, assemble from qiskit.tools.jupyter import * from qiskit.visualization import * Theory QFT is defined as $$ \\large{QFT:|x> = \\frac{1}{\\sqrt{N}}\\sum_{k=0}^{N-1} \\omega_{x}^{k}|k>}$$ where \\( \\omega_{x}^{k}\\) is \\( N^{th} (N = 2^{n})\\) root of unity: \\( e^{\\frac{2\\pi i}{2^{n}}}\\). $$ QFT_{N} = \\frac{1}{\\sqrt{N}} \\left( \\begin{array}{cccccc} 1 & 1 & 1 & 1 & \\cdots &1 \\\\ 1 & \\omega_{n} & \\omega_{n}^{2} & \\omega_{n}^{3} & \\cdots & \\omega_{n} ^{N-1} \\\\ 1 & \\omega_{n}^{2} & \\omega_{n}^{4} & \\omega_{n}^{6} & \\cdots & \\omega_{n} ^{2(N-1)} \\\\ 1 & \\omega_{n}^{3} &\\omega_{n}^{6} & \\omega_{n}^{9} & \\cdots & \\omega_{n} ^{3(N-1)} \\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\dots & \\vdots \\\\ 1 & \\omega_{n}^{(N-1)} & \\omega_{n}^{2(N-1)} & \\omega_{n}^{3(N-1)} &\\cdots & \\omega_{n} ^{(N-1((N-1)} \\\\ \\end{array} \\right) $$ Single qubit QFT Theory For single qubit circuit \\( (n = 1, N = 2^{1} = 2)\\) and \\( \\omega_n = e^{\\frac{2\\pi i}{2^{n}}} = -1 \\). $$ QFT_{1} = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right)$$ How is state |0> transformed ? $$QFT_1|0> = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) \\left( \\begin{array}{c} 1 \\\\ 0 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{c} 1 \\\\ 1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} (|0> + |1>)$$ How is state |1> transformed ? $$QFT_1|1> = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) \\left( \\begin{array}{c} 0 \\\\ 1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{c} 1 \\\\ -1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} (|0> - |1>)$$ How is state \\( c_1|0> + c_2|1> \\) transformed? $$QFT_1(c_1|0> + c_2|1>) = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) \\left( \\begin{array}{cc} c_1 \\\\ c_2 \\end{array} \\right)$$ $$ = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} c_1 + c_2 \\\\ c_2 - c1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} ((c_1 + c_2)|0> - (c_2 - c1)|1>)$$ How to realize the quantum circuit? It is Hadamard gate ! Quantum Circuit - single qubit QFT Quantum Circuit def qft_1 (): n = 1 qc = QuantumCircuit() q = QuantumRegister(n, 'q' ) c = ClassicalRegister(n, 'c' ) qc . add_register(q) qc . add_register(c) qc . h(q[ 0 ]) return qc,q,c Measurement qc,q,c = qft_1() qc . measure(q[ 0 ], c[ 0 ]) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } qc . draw(output = 'mpl' , style = style) Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(qc, simulator) . result() counts = result . get_counts(qc) plot_histogram(counts, title = 'QFT counts' ) Unitary representation from qiskit.providers.aer import UnitarySimulator qc,q,c = qft_1() # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(qc, simulator) . result() unitary = result . get_unitary(qc) print ( unitary) [[ 0.70710678+0.j 0.70710678+0.j] [ 0.70710678+0.j -0.70710678+0.j]] Two qubit QFT Theory: For two qubit circuit, \\( (n =2, N = 2^{2} = 4) \\) where \\( \\omega_{n} = e^{\\frac{2\\pi i}{2^{n}}} = i\\). $$QFT_2 = \\frac{1}{{2}} \\left( \\begin{array}{cc} 1 & 1 & 1 & 1\\\\ 1 & i & -1 & -i\\\\ 1 & -1 & 1 & -1\\\\ 1 & -i & -1 & i \\end{array} \\right)$$ How is state |00> transformed ? $$QFT_2|00> = \\frac{1}{{2}} \\left( \\begin{array}{cccc} 1 & 1 & 1 & 1\\\\ 1 & i & -1 & -i\\\\ 1 & -1 & 1 & -1\\\\ 1 & -i & -1 & i \\end{array} \\right) \\left( \\begin{array}{c} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ \\end{array} \\right) = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{c} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{array} \\right) = \\frac{1}{{2}} (|00> + |10> + |01> + |11>)$$ How is state \\( c_1|00> + c_2|10> + c_3 |01> + c_4 |11> \\) transformed? $$QFT_2|(c_1|00> + c_2|10> + c_3 |01> + c_4 |11>) = \\frac{1}{{2}} \\left( \\begin{array}{cccc} 1 & 1 & 1 & 1\\\\ 1 & i & -1 & -i\\\\ 1 & -1 & 1 & -1\\\\ 1 & -i & -1 & i \\end{array} \\right) \\left( \\begin{array}{c} c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\\\ \\end{array} \\right) $$ $$= \\frac{1}{{2}} \\left( \\begin{array}{c} c_1 +c_2 +c_3 +c_4 \\\\ c_1 +ic_2 -c_3 -ic_4 \\\\ c_1 -c_2 +c_3 -c_4 \\\\ c_1 -ic_2 -c_3 +ic_4 \\end{array} \\right) = \\frac{1}{{2}} (d_1|00> + d_2|10> + d_3|01> + d_4|11>)$$ How to realize the quantum circuit? $$H \\otimes I = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) \\otimes \\left( \\begin{array}{cc} 1 & 0 \\\\ 0 & 1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}}\\left( \\begin{array}{cccc} 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1\\\\ 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{array} \\right) $$ $$C_{u1} = \\left( \\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 0 & i \\end{array} \\right)$$ $$I \\otimes H = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 0 \\\\ 0 & 1 \\end{array} \\right) \\otimes \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}}\\left( \\begin{array}{cccc} 1 & 1 & 0 & 0\\\\ 1 & -1 & 0 & 0\\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & -1 \\end{array} \\right) $$ $$ SWAP = \\left( \\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 0 & 1 \\end{array} \\right)$$ $$QFT_2 = (H \\otimes I) \\times C_{u1} \\times (I \\otimes H) \\times SWAP $$ $$ = \\frac{1}{\\sqrt{2}}\\left( \\begin{array}{cccc} 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1\\\\ 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{array} \\right)\\left( \\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 0 & i \\end{array} \\right)\\frac{1}{\\sqrt{2}}\\left( \\begin{array}{cccc} 1 & 1 & 0 & 0\\\\ 1 & -1 & 0 & 0\\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & -1 \\end{array} \\right) \\left( \\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 0 & 1 \\end{array} \\right)$$ $$ = \\frac{1}{{2}} \\left( \\begin{array}{cccc} 1 & 1 & 1 & 1\\\\ 1 & i & -1 & -i\\\\ 1 & -1 & 1 & -1\\\\ 1 & -i & -1 & i \\end{array} \\right)$$ Numpy check: HI = np . array([[ 1 , 0 , 1 , 0 ],[ 0 , 1 , 0 , 1 ],[ 1 , 0 , - 1 , 0 ],[ 0 , 1 , 0 , - 1 ]]) CU1 = np . array([[ 1 , 0 , 0 , 0 ],[ 0 , 1 , 0 , 0 ],[ 0 , 0 , 1 , 0 ],[ 0 , 0 , 0 , 0. + 1.j ]]) IH = np . array([[ 1 , 1 , 0 , 0 ],[ 1 , - 1 , 0 , 0 ],[ 0 , 0 , 1 , 1 ],[ 0 , 0 , 1 , - 1 ]]) SWAP = np . array([[ 1 , 0 , 0 , 0 ],[ 0 , 0 , 1 , 0 ],[ 0 , 1 , 0 , 0 ],[ 0 , 0 , 0 , 1 ]]) np . dot(HI,np . dot(CU1,np . dot(IH,SWAP))) array([[ 1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j], [ 1.+0.j, 0.+1.j, -1.+0.j, 0.-1.j], [ 1.+0.j, -1.+0.j, 1.+0.j, -1.+0.j], [ 1.+0.j, 0.-1.j, -1.+0.j, 0.+1.j]]) Quantum Circuit - two qubit QFT import numpy as np Quantum circuit def qft_2 (): n = 2 qc = QuantumCircuit() q = QuantumRegister(n, 'q' ) c = ClassicalRegister(n, 'c' ) qc . add_register(q) qc . add_register(c) qc . h(q[ 1 ]) qc . cu1(np . pi / 2 , q[ 0 ], q[ 1 ]) qc . h(q[ 0 ]) qc . swap(q[ 0 ], q[ 1 ]) return qc,q,c Measurement qc,q,c = qft_2() qc . measure(q, c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } qc . draw(output = 'mpl' , style = style) Manual approach: Initial state: |00> After Hadamard Gate on qubit 2 : \\(\\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|01> \\) After phase shift Gate : \\(\\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|01> \\) After Hadamard Gate on qubit 1 : \\(\\frac{1}{{2}}|00> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|01> - \\frac{1}{{2}}|11>\\) After SWAP: \\( \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> - \\frac{1}{{2}}|11>\\) Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(qc, simulator) . result() counts = result . get_counts(qc) plot_histogram(counts, title = 'QFT counts' ) Unitary representation from qiskit.providers.aer import UnitarySimulator qc,q,c = qft_2() # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(qc, simulator) . result() unitary = result . get_unitary(qc) print ( unitary) [[ 0.5+0.j 0.5+0.j 0.5+0.j 0.5+0.j ] [ 0.5+0.j 0. +0.5j -0.5+0.j 0. -0.5j] [ 0.5+0.j -0.5+0.j 0.5+0.j -0.5+0.j ] [ 0.5+0.j 0. -0.5j -0.5+0.j 0. +0.5j]] Quantum Circuit - three qubit QFT Quantum circuit def qft_3 (): n = 3 qc = QuantumCircuit() q = QuantumRegister(n, 'q' ) c = ClassicalRegister(n, 'c' ) qc . add_register(q) qc . add_register(c) qc . h(q[ 2 ]) qc . cu1(np . pi / 2 , q[ 1 ], q[ 2 ]) qc . h(q[ 1 ]) qc . cu1(np . pi / 4 , q[ 0 ], q[ 2 ]) qc . cu1(np . pi / 2 , q[ 0 ], q[ 1 ]) qc . h(q[ 0 ]) qc . swap(q[ 0 ], q[ 2 ]) return qc,q,c Measuremrnt qc,q,c = qft_3() qc . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } qc . draw(output = 'mpl' , style = style) Manual Approach: Initial state: |000> After Hadamard Gate on 3rd qubit : \\(\\frac{1}{\\sqrt{2}}(|000> + |001>) \\) After CU1 gate on qubit (2,3) : \\(\\frac{1}{\\sqrt{2}}(|000> + |001>) \\) After CU1 gate on qubit (1,3) : \\(\\frac{1}{\\sqrt{2}}(|000> + |001>) \\) After Hadamard Gate on qubit 2 : \\(\\frac{1}{{2}}(|000> + |010> + |001> -|011> )\\) After CU1 gate on qubit (0,1): \\(\\frac{1}{{2}}(|000> + |010> + |001> -|011> )\\) After Hadamard Gate on qubit 3 : \\(\\frac{1}{2\\sqrt{2}}(|000> + |001> + |010> + |011> + |000> - |001> - |010> + |011)\\) Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(qc, simulator) . result() counts = result . get_counts(qc) plot_histogram(counts, title = 'QFT counts' ) Unitary representation from qiskit.providers.aer import UnitarySimulator qc,q,c = qft_3() # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(qc, simulator) . result() unitary = result . get_unitary(qc) print ( unitary) [[ 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j ] [ 0.35355339+0.j 0.25 +0.25j 0. +0.35355339j -0.25 +0.25j -0.35355339+0.j -0.25 -0.25j 0. -0.35355339j 0.25 -0.25j ] [ 0.35355339+0.j 0. +0.35355339j -0.35355339+0.j 0. -0.35355339j 0.35355339+0.j 0. +0.35355339j -0.35355339+0.j 0. -0.35355339j] [ 0.35355339+0.j -0.25 +0.25j 0. -0.35355339j 0.25 +0.25j -0.35355339+0.j 0.25 -0.25j 0. +0.35355339j -0.25 -0.25j ] [ 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j ] [ 0.35355339+0.j -0.25 -0.25j 0. +0.35355339j 0.25 -0.25j -0.35355339+0.j 0.25 +0.25j 0. -0.35355339j -0.25 +0.25j ] [ 0.35355339+0.j 0. -0.35355339j -0.35355339+0.j 0. +0.35355339j 0.35355339+0.j 0. -0.35355339j -0.35355339+0.j 0. +0.35355339j] [ 0.35355339+0.j 0.25 -0.25j 0. -0.35355339j -0.25 -0.25j -0.35355339+0.j -0.25 +0.25j 0. +0.35355339j 0.25 +0.25j ]] Quantum Circuit - four qubit QFT Quantum circuit def qft_4 (): n = 4 qc = QuantumCircuit() q = QuantumRegister(n, 'q' ) c = ClassicalRegister(n, 'c' ) qc . add_register(q) qc . add_register(c) qc . h(q[ 3 ]) qc . cu1(np . pi / 2 , q[ 2 ], q[ 3 ]) qc . h(q[ 2 ]) qc . cu1(np . pi / 4 , q[ 1 ], q[ 3 ]) qc . cu1(np . pi / 2 , q[ 1 ], q[ 2 ]) qc . h(q[ 1 ]) qc . cu1(np . pi / 8 , q[ 0 ], q[ 3 ]) qc . cu1(np . pi / 4 , q[ 0 ], q[ 2 ]) qc . cu1(np . pi / 2 , q[ 0 ], q[ 1 ]) qc . h(q[ 0 ]) qc . swap(q[ 0 ], q[ 3 ]) qc . swap(q[ 1 ], q[ 2 ]) return qc,q,c Measurement qc,q,c = qft_4() qc . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } qc . draw(output = 'mpl' , style = style) Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(qc, simulator) . result() counts = result . get_counts(qc) plot_histogram(counts, title = 'QFT counts' ) Unitary representation qc = qft_circuit( 4 ) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(qc, simulator) . result() unitary = result . get_unitary(qc) print ( unitary) [[ 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j ] [ 0.25 +0.j 0.23096988+0.09567086j 0.1767767 +0.1767767j 0.09567086+0.23096988j 0. +0.25j -0.09567086+0.23096988j -0.1767767 +0.1767767j -0.23096988+0.09567086j -0.25 +0.j -0.23096988-0.09567086j -0.1767767 -0.1767767j -0.09567086-0.23096988j 0. -0.25j 0.09567086-0.23096988j 0.1767767 -0.1767767j 0.23096988-0.09567086j] [ 0.25 +0.j 0.1767767 +0.1767767j 0. +0.25j -0.1767767 +0.1767767j -0.25 +0.j -0.1767767 -0.1767767j 0. -0.25j 0.1767767 -0.1767767j 0.25 +0.j 0.1767767 +0.1767767j 0. +0.25j -0.1767767 +0.1767767j -0.25 +0.j -0.1767767 -0.1767767j 0. -0.25j 0.1767767 -0.1767767j ] [ 0.25 +0.j 0.09567086+0.23096988j -0.1767767 +0.1767767j -0.23096988-0.09567086j 0. -0.25j 0.23096988-0.09567086j 0.1767767 +0.1767767j -0.09567086+0.23096988j -0.25 +0.j -0.09567086-0.23096988j 0.1767767 -0.1767767j 0.23096988+0.09567086j 0. +0.25j -0.23096988+0.09567086j -0.1767767 -0.1767767j 0.09567086-0.23096988j] [ 0.25 +0.j 0. +0.25j -0.25 +0.j 0. -0.25j 0.25 +0.j 0. +0.25j -0.25 +0.j 0. -0.25j 0.25 +0.j 0. +0.25j -0.25 +0.j 0. -0.25j 0.25 +0.j 0. +0.25j -0.25 +0.j 0. -0.25j ] [ 0.25 +0.j -0.09567086+0.23096988j -0.1767767 -0.1767767j 0.23096988-0.09567086j 0. +0.25j -0.23096988-0.09567086j 0.1767767 -0.1767767j 0.09567086+0.23096988j -0.25 +0.j 0.09567086-0.23096988j 0.1767767 +0.1767767j -0.23096988+0.09567086j 0. -0.25j 0.23096988+0.09567086j -0.1767767 +0.1767767j -0.09567086-0.23096988j] [ 0.25 +0.j -0.1767767 +0.1767767j 0. -0.25j 0.1767767 +0.1767767j -0.25 +0.j 0.1767767 -0.1767767j 0. +0.25j -0.1767767 -0.1767767j 0.25 +0.j -0.1767767 +0.1767767j 0. -0.25j 0.1767767 +0.1767767j -0.25 +0.j 0.1767767 -0.1767767j 0. +0.25j -0.1767767 -0.1767767j ] [ 0.25 +0.j -0.23096988+0.09567086j 0.1767767 -0.1767767j -0.09567086+0.23096988j 0. -0.25j 0.09567086+0.23096988j -0.1767767 -0.1767767j 0.23096988+0.09567086j -0.25 +0.j 0.23096988-0.09567086j -0.1767767 +0.1767767j 0.09567086-0.23096988j 0. +0.25j -0.09567086-0.23096988j 0.1767767 +0.1767767j -0.23096988-0.09567086j] [ 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j ] [ 0.25 +0.j -0.23096988-0.09567086j 0.1767767 +0.1767767j -0.09567086-0.23096988j 0. +0.25j 0.09567086-0.23096988j -0.1767767 +0.1767767j 0.23096988-0.09567086j -0.25 +0.j 0.23096988+0.09567086j -0.1767767 -0.1767767j 0.09567086+0.23096988j 0. -0.25j -0.09567086+0.23096988j 0.1767767 -0.1767767j -0.23096988+0.09567086j] [ 0.25 +0.j -0.1767767 -0.1767767j 0. +0.25j 0.1767767 -0.1767767j -0.25 +0.j 0.1767767 +0.1767767j 0. -0.25j -0.1767767 +0.1767767j 0.25 +0.j -0.1767767 -0.1767767j 0. +0.25j 0.1767767 -0.1767767j -0.25 +0.j 0.1767767 +0.1767767j 0. -0.25j -0.1767767 +0.1767767j ] [ 0.25 +0.j -0.09567086-0.23096988j -0.1767767 +0.1767767j 0.23096988+0.09567086j 0. -0.25j -0.23096988+0.09567086j 0.1767767 +0.1767767j 0.09567086-0.23096988j -0.25 +0.j 0.09567086+0.23096988j 0.1767767 -0.1767767j -0.23096988-0.09567086j 0. +0.25j 0.23096988-0.09567086j -0.1767767 -0.1767767j -0.09567086+0.23096988j] [ 0.25 +0.j 0. -0.25j -0.25 +0.j 0. +0.25j 0.25 +0.j 0. -0.25j -0.25 +0.j 0. +0.25j 0.25 +0.j 0. -0.25j -0.25 +0.j 0. +0.25j 0.25 +0.j 0. -0.25j -0.25 +0.j 0. +0.25j ] [ 0.25 +0.j 0.09567086-0.23096988j -0.1767767 -0.1767767j -0.23096988+0.09567086j 0. +0.25j 0.23096988+0.09567086j 0.1767767 -0.1767767j -0.09567086-0.23096988j -0.25 +0.j -0.09567086+0.23096988j 0.1767767 +0.1767767j 0.23096988-0.09567086j 0. -0.25j -0.23096988-0.09567086j -0.1767767 +0.1767767j 0.09567086+0.23096988j] [ 0.25 +0.j 0.1767767 -0.1767767j 0. -0.25j -0.1767767 -0.1767767j -0.25 +0.j -0.1767767 +0.1767767j 0. +0.25j 0.1767767 +0.1767767j 0.25 +0.j 0.1767767 -0.1767767j 0. -0.25j -0.1767767 -0.1767767j -0.25 +0.j -0.1767767 +0.1767767j 0. +0.25j 0.1767767 +0.1767767j ] [ 0.25 +0.j 0.23096988-0.09567086j 0.1767767 -0.1767767j 0.09567086-0.23096988j 0. -0.25j -0.09567086-0.23096988j -0.1767767 -0.1767767j -0.23096988-0.09567086j -0.25 +0.j -0.23096988+0.09567086j -0.1767767 +0.1767767j -0.09567086+0.23096988j 0. +0.25j 0.09567086+0.23096988j 0.1767767 +0.1767767j 0.23096988+0.09567086j]] References https://www.youtube.com/watch?v=bntew-yoMzk","title":"Quantum Fourier Transform"},{"location":"algorithms/qft/qft/#quantum-fourier-transform","text":"In quantum computing, the quantum Fourier transform (for short: QFT) is a linear transformation on quantum bits, and is the quantum analogue of the inverse discrete Fourier transform. The quantum Fourier transform is a part of many quantum algorithms, notably Shor's algorithm for factoring and computing the discrete logarithm, the quantum phase estimation algorithm for estimating the eigenvalues of a unitary operator, and algorithms for the hidden subgroup problem Wikipedia . Import 'Quiskit' libraries. % matplotlib inline # Importing standard Qiskit libraries and configuring account from qiskit import QuantumCircuit,QuantumRegister,ClassicalRegister from qiskit import execute, Aer, IBMQ from qiskit.compiler import transpile, assemble from qiskit.tools.jupyter import * from qiskit.visualization import *","title":"Quantum Fourier Transform"},{"location":"algorithms/qft/qft/#theory","text":"QFT is defined as $$ \\large{QFT:|x> = \\frac{1}{\\sqrt{N}}\\sum_{k=0}^{N-1} \\omega_{x}^{k}|k>}$$ where \\( \\omega_{x}^{k}\\) is \\( N^{th} (N = 2^{n})\\) root of unity: \\( e^{\\frac{2\\pi i}{2^{n}}}\\). $$ QFT_{N} = \\frac{1}{\\sqrt{N}} \\left( \\begin{array}{cccccc} 1 & 1 & 1 & 1 & \\cdots &1 \\\\ 1 & \\omega_{n} & \\omega_{n}^{2} & \\omega_{n}^{3} & \\cdots & \\omega_{n} ^{N-1} \\\\ 1 & \\omega_{n}^{2} & \\omega_{n}^{4} & \\omega_{n}^{6} & \\cdots & \\omega_{n} ^{2(N-1)} \\\\ 1 & \\omega_{n}^{3} &\\omega_{n}^{6} & \\omega_{n}^{9} & \\cdots & \\omega_{n} ^{3(N-1)} \\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\dots & \\vdots \\\\ 1 & \\omega_{n}^{(N-1)} & \\omega_{n}^{2(N-1)} & \\omega_{n}^{3(N-1)} &\\cdots & \\omega_{n} ^{(N-1((N-1)} \\\\ \\end{array} \\right) $$","title":"Theory"},{"location":"algorithms/qft/qft/#single-qubit-qft","text":"","title":"Single qubit QFT"},{"location":"algorithms/qft/qft/#theory_1","text":"For single qubit circuit \\( (n = 1, N = 2^{1} = 2)\\) and \\( \\omega_n = e^{\\frac{2\\pi i}{2^{n}}} = -1 \\). $$ QFT_{1} = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right)$$ How is state |0> transformed ? $$QFT_1|0> = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) \\left( \\begin{array}{c} 1 \\\\ 0 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{c} 1 \\\\ 1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} (|0> + |1>)$$ How is state |1> transformed ? $$QFT_1|1> = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) \\left( \\begin{array}{c} 0 \\\\ 1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{c} 1 \\\\ -1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} (|0> - |1>)$$ How is state \\( c_1|0> + c_2|1> \\) transformed? $$QFT_1(c_1|0> + c_2|1>) = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) \\left( \\begin{array}{cc} c_1 \\\\ c_2 \\end{array} \\right)$$ $$ = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} c_1 + c_2 \\\\ c_2 - c1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}} ((c_1 + c_2)|0> - (c_2 - c1)|1>)$$ How to realize the quantum circuit? It is Hadamard gate !","title":"Theory"},{"location":"algorithms/qft/qft/#quantum-circuit-single-qubit-qft","text":"","title":"Quantum Circuit - single qubit QFT"},{"location":"algorithms/qft/qft/#quantum-circuit","text":"def qft_1 (): n = 1 qc = QuantumCircuit() q = QuantumRegister(n, 'q' ) c = ClassicalRegister(n, 'c' ) qc . add_register(q) qc . add_register(c) qc . h(q[ 0 ]) return qc,q,c","title":"Quantum Circuit"},{"location":"algorithms/qft/qft/#measurement","text":"qc,q,c = qft_1() qc . measure(q[ 0 ], c[ 0 ]) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } qc . draw(output = 'mpl' , style = style)","title":"Measurement"},{"location":"algorithms/qft/qft/#simulation","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(qc, simulator) . result() counts = result . get_counts(qc) plot_histogram(counts, title = 'QFT counts' )","title":"Simulation"},{"location":"algorithms/qft/qft/#unitary-representation","text":"from qiskit.providers.aer import UnitarySimulator qc,q,c = qft_1() # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(qc, simulator) . result() unitary = result . get_unitary(qc) print ( unitary) [[ 0.70710678+0.j 0.70710678+0.j] [ 0.70710678+0.j -0.70710678+0.j]]","title":"Unitary representation"},{"location":"algorithms/qft/qft/#two-qubit-qft","text":"","title":"Two qubit QFT"},{"location":"algorithms/qft/qft/#theory_2","text":"For two qubit circuit, \\( (n =2, N = 2^{2} = 4) \\) where \\( \\omega_{n} = e^{\\frac{2\\pi i}{2^{n}}} = i\\). $$QFT_2 = \\frac{1}{{2}} \\left( \\begin{array}{cc} 1 & 1 & 1 & 1\\\\ 1 & i & -1 & -i\\\\ 1 & -1 & 1 & -1\\\\ 1 & -i & -1 & i \\end{array} \\right)$$ How is state |00> transformed ? $$QFT_2|00> = \\frac{1}{{2}} \\left( \\begin{array}{cccc} 1 & 1 & 1 & 1\\\\ 1 & i & -1 & -i\\\\ 1 & -1 & 1 & -1\\\\ 1 & -i & -1 & i \\end{array} \\right) \\left( \\begin{array}{c} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ \\end{array} \\right) = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{c} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{array} \\right) = \\frac{1}{{2}} (|00> + |10> + |01> + |11>)$$ How is state \\( c_1|00> + c_2|10> + c_3 |01> + c_4 |11> \\) transformed? $$QFT_2|(c_1|00> + c_2|10> + c_3 |01> + c_4 |11>) = \\frac{1}{{2}} \\left( \\begin{array}{cccc} 1 & 1 & 1 & 1\\\\ 1 & i & -1 & -i\\\\ 1 & -1 & 1 & -1\\\\ 1 & -i & -1 & i \\end{array} \\right) \\left( \\begin{array}{c} c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\\\ \\end{array} \\right) $$ $$= \\frac{1}{{2}} \\left( \\begin{array}{c} c_1 +c_2 +c_3 +c_4 \\\\ c_1 +ic_2 -c_3 -ic_4 \\\\ c_1 -c_2 +c_3 -c_4 \\\\ c_1 -ic_2 -c_3 +ic_4 \\end{array} \\right) = \\frac{1}{{2}} (d_1|00> + d_2|10> + d_3|01> + d_4|11>)$$ How to realize the quantum circuit? $$H \\otimes I = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) \\otimes \\left( \\begin{array}{cc} 1 & 0 \\\\ 0 & 1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}}\\left( \\begin{array}{cccc} 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1\\\\ 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{array} \\right) $$ $$C_{u1} = \\left( \\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 0 & i \\end{array} \\right)$$ $$I \\otimes H = \\frac{1}{\\sqrt{2}} \\left( \\begin{array}{cc} 1 & 0 \\\\ 0 & 1 \\end{array} \\right) \\otimes \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & -1 \\end{array} \\right) = \\frac{1}{\\sqrt{2}}\\left( \\begin{array}{cccc} 1 & 1 & 0 & 0\\\\ 1 & -1 & 0 & 0\\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & -1 \\end{array} \\right) $$ $$ SWAP = \\left( \\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 0 & 1 \\end{array} \\right)$$ $$QFT_2 = (H \\otimes I) \\times C_{u1} \\times (I \\otimes H) \\times SWAP $$ $$ = \\frac{1}{\\sqrt{2}}\\left( \\begin{array}{cccc} 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1\\\\ 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{array} \\right)\\left( \\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 0 & i \\end{array} \\right)\\frac{1}{\\sqrt{2}}\\left( \\begin{array}{cccc} 1 & 1 & 0 & 0\\\\ 1 & -1 & 0 & 0\\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & -1 \\end{array} \\right) \\left( \\begin{array}{cccc} 1 & 0 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 0 & 1 \\end{array} \\right)$$ $$ = \\frac{1}{{2}} \\left( \\begin{array}{cccc} 1 & 1 & 1 & 1\\\\ 1 & i & -1 & -i\\\\ 1 & -1 & 1 & -1\\\\ 1 & -i & -1 & i \\end{array} \\right)$$ Numpy check: HI = np . array([[ 1 , 0 , 1 , 0 ],[ 0 , 1 , 0 , 1 ],[ 1 , 0 , - 1 , 0 ],[ 0 , 1 , 0 , - 1 ]]) CU1 = np . array([[ 1 , 0 , 0 , 0 ],[ 0 , 1 , 0 , 0 ],[ 0 , 0 , 1 , 0 ],[ 0 , 0 , 0 , 0. + 1.j ]]) IH = np . array([[ 1 , 1 , 0 , 0 ],[ 1 , - 1 , 0 , 0 ],[ 0 , 0 , 1 , 1 ],[ 0 , 0 , 1 , - 1 ]]) SWAP = np . array([[ 1 , 0 , 0 , 0 ],[ 0 , 0 , 1 , 0 ],[ 0 , 1 , 0 , 0 ],[ 0 , 0 , 0 , 1 ]]) np . dot(HI,np . dot(CU1,np . dot(IH,SWAP))) array([[ 1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j], [ 1.+0.j, 0.+1.j, -1.+0.j, 0.-1.j], [ 1.+0.j, -1.+0.j, 1.+0.j, -1.+0.j], [ 1.+0.j, 0.-1.j, -1.+0.j, 0.+1.j]])","title":"Theory:"},{"location":"algorithms/qft/qft/#quantum-circuit-two-qubit-qft","text":"import numpy as np","title":"Quantum Circuit - two qubit QFT"},{"location":"algorithms/qft/qft/#quantum-circuit_1","text":"def qft_2 (): n = 2 qc = QuantumCircuit() q = QuantumRegister(n, 'q' ) c = ClassicalRegister(n, 'c' ) qc . add_register(q) qc . add_register(c) qc . h(q[ 1 ]) qc . cu1(np . pi / 2 , q[ 0 ], q[ 1 ]) qc . h(q[ 0 ]) qc . swap(q[ 0 ], q[ 1 ]) return qc,q,c","title":"Quantum circuit"},{"location":"algorithms/qft/qft/#measurement_1","text":"qc,q,c = qft_2() qc . measure(q, c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } qc . draw(output = 'mpl' , style = style)","title":"Measurement"},{"location":"algorithms/qft/qft/#manual-approach","text":"Initial state: |00> After Hadamard Gate on qubit 2 : \\(\\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|01> \\) After phase shift Gate : \\(\\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|01> \\) After Hadamard Gate on qubit 1 : \\(\\frac{1}{{2}}|00> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|01> - \\frac{1}{{2}}|11>\\) After SWAP: \\( \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> - \\frac{1}{{2}}|11>\\)","title":"Manual approach:"},{"location":"algorithms/qft/qft/#simulation_1","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(qc, simulator) . result() counts = result . get_counts(qc) plot_histogram(counts, title = 'QFT counts' )","title":"Simulation"},{"location":"algorithms/qft/qft/#unitary-representation_1","text":"from qiskit.providers.aer import UnitarySimulator qc,q,c = qft_2() # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(qc, simulator) . result() unitary = result . get_unitary(qc) print ( unitary) [[ 0.5+0.j 0.5+0.j 0.5+0.j 0.5+0.j ] [ 0.5+0.j 0. +0.5j -0.5+0.j 0. -0.5j] [ 0.5+0.j -0.5+0.j 0.5+0.j -0.5+0.j ] [ 0.5+0.j 0. -0.5j -0.5+0.j 0. +0.5j]]","title":"Unitary representation"},{"location":"algorithms/qft/qft/#quantum-circuit-three-qubit-qft","text":"","title":"Quantum Circuit - three qubit QFT"},{"location":"algorithms/qft/qft/#quantum-circuit_2","text":"def qft_3 (): n = 3 qc = QuantumCircuit() q = QuantumRegister(n, 'q' ) c = ClassicalRegister(n, 'c' ) qc . add_register(q) qc . add_register(c) qc . h(q[ 2 ]) qc . cu1(np . pi / 2 , q[ 1 ], q[ 2 ]) qc . h(q[ 1 ]) qc . cu1(np . pi / 4 , q[ 0 ], q[ 2 ]) qc . cu1(np . pi / 2 , q[ 0 ], q[ 1 ]) qc . h(q[ 0 ]) qc . swap(q[ 0 ], q[ 2 ]) return qc,q,c","title":"Quantum circuit"},{"location":"algorithms/qft/qft/#measuremrnt","text":"qc,q,c = qft_3() qc . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } qc . draw(output = 'mpl' , style = style)","title":"Measuremrnt"},{"location":"algorithms/qft/qft/#manual-approach_1","text":"Initial state: |000> After Hadamard Gate on 3rd qubit : \\(\\frac{1}{\\sqrt{2}}(|000> + |001>) \\) After CU1 gate on qubit (2,3) : \\(\\frac{1}{\\sqrt{2}}(|000> + |001>) \\) After CU1 gate on qubit (1,3) : \\(\\frac{1}{\\sqrt{2}}(|000> + |001>) \\) After Hadamard Gate on qubit 2 : \\(\\frac{1}{{2}}(|000> + |010> + |001> -|011> )\\) After CU1 gate on qubit (0,1): \\(\\frac{1}{{2}}(|000> + |010> + |001> -|011> )\\) After Hadamard Gate on qubit 3 : \\(\\frac{1}{2\\sqrt{2}}(|000> + |001> + |010> + |011> + |000> - |001> - |010> + |011)\\)","title":"Manual Approach:"},{"location":"algorithms/qft/qft/#simulation_2","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(qc, simulator) . result() counts = result . get_counts(qc) plot_histogram(counts, title = 'QFT counts' )","title":"Simulation"},{"location":"algorithms/qft/qft/#unitary-representation_2","text":"from qiskit.providers.aer import UnitarySimulator qc,q,c = qft_3() # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(qc, simulator) . result() unitary = result . get_unitary(qc) print ( unitary) [[ 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j ] [ 0.35355339+0.j 0.25 +0.25j 0. +0.35355339j -0.25 +0.25j -0.35355339+0.j -0.25 -0.25j 0. -0.35355339j 0.25 -0.25j ] [ 0.35355339+0.j 0. +0.35355339j -0.35355339+0.j 0. -0.35355339j 0.35355339+0.j 0. +0.35355339j -0.35355339+0.j 0. -0.35355339j] [ 0.35355339+0.j -0.25 +0.25j 0. -0.35355339j 0.25 +0.25j -0.35355339+0.j 0.25 -0.25j 0. +0.35355339j -0.25 -0.25j ] [ 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j ] [ 0.35355339+0.j -0.25 -0.25j 0. +0.35355339j 0.25 -0.25j -0.35355339+0.j 0.25 +0.25j 0. -0.35355339j -0.25 +0.25j ] [ 0.35355339+0.j 0. -0.35355339j -0.35355339+0.j 0. +0.35355339j 0.35355339+0.j 0. -0.35355339j -0.35355339+0.j 0. +0.35355339j] [ 0.35355339+0.j 0.25 -0.25j 0. -0.35355339j -0.25 -0.25j -0.35355339+0.j -0.25 +0.25j 0. +0.35355339j 0.25 +0.25j ]]","title":"Unitary representation"},{"location":"algorithms/qft/qft/#quantum-circuit-four-qubit-qft","text":"","title":"Quantum Circuit - four qubit QFT"},{"location":"algorithms/qft/qft/#quantum-circuit_3","text":"def qft_4 (): n = 4 qc = QuantumCircuit() q = QuantumRegister(n, 'q' ) c = ClassicalRegister(n, 'c' ) qc . add_register(q) qc . add_register(c) qc . h(q[ 3 ]) qc . cu1(np . pi / 2 , q[ 2 ], q[ 3 ]) qc . h(q[ 2 ]) qc . cu1(np . pi / 4 , q[ 1 ], q[ 3 ]) qc . cu1(np . pi / 2 , q[ 1 ], q[ 2 ]) qc . h(q[ 1 ]) qc . cu1(np . pi / 8 , q[ 0 ], q[ 3 ]) qc . cu1(np . pi / 4 , q[ 0 ], q[ 2 ]) qc . cu1(np . pi / 2 , q[ 0 ], q[ 1 ]) qc . h(q[ 0 ]) qc . swap(q[ 0 ], q[ 3 ]) qc . swap(q[ 1 ], q[ 2 ]) return qc,q,c","title":"Quantum circuit"},{"location":"algorithms/qft/qft/#measurement_2","text":"qc,q,c = qft_4() qc . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } qc . draw(output = 'mpl' , style = style)","title":"Measurement"},{"location":"algorithms/qft/qft/#simulation_3","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(qc, simulator) . result() counts = result . get_counts(qc) plot_histogram(counts, title = 'QFT counts' )","title":"Simulation"},{"location":"algorithms/qft/qft/#unitary-representation_3","text":"qc = qft_circuit( 4 ) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(qc, simulator) . result() unitary = result . get_unitary(qc) print ( unitary) [[ 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j 0.25 +0.j ] [ 0.25 +0.j 0.23096988+0.09567086j 0.1767767 +0.1767767j 0.09567086+0.23096988j 0. +0.25j -0.09567086+0.23096988j -0.1767767 +0.1767767j -0.23096988+0.09567086j -0.25 +0.j -0.23096988-0.09567086j -0.1767767 -0.1767767j -0.09567086-0.23096988j 0. -0.25j 0.09567086-0.23096988j 0.1767767 -0.1767767j 0.23096988-0.09567086j] [ 0.25 +0.j 0.1767767 +0.1767767j 0. +0.25j -0.1767767 +0.1767767j -0.25 +0.j -0.1767767 -0.1767767j 0. -0.25j 0.1767767 -0.1767767j 0.25 +0.j 0.1767767 +0.1767767j 0. +0.25j -0.1767767 +0.1767767j -0.25 +0.j -0.1767767 -0.1767767j 0. -0.25j 0.1767767 -0.1767767j ] [ 0.25 +0.j 0.09567086+0.23096988j -0.1767767 +0.1767767j -0.23096988-0.09567086j 0. -0.25j 0.23096988-0.09567086j 0.1767767 +0.1767767j -0.09567086+0.23096988j -0.25 +0.j -0.09567086-0.23096988j 0.1767767 -0.1767767j 0.23096988+0.09567086j 0. +0.25j -0.23096988+0.09567086j -0.1767767 -0.1767767j 0.09567086-0.23096988j] [ 0.25 +0.j 0. +0.25j -0.25 +0.j 0. -0.25j 0.25 +0.j 0. +0.25j -0.25 +0.j 0. -0.25j 0.25 +0.j 0. +0.25j -0.25 +0.j 0. -0.25j 0.25 +0.j 0. +0.25j -0.25 +0.j 0. -0.25j ] [ 0.25 +0.j -0.09567086+0.23096988j -0.1767767 -0.1767767j 0.23096988-0.09567086j 0. +0.25j -0.23096988-0.09567086j 0.1767767 -0.1767767j 0.09567086+0.23096988j -0.25 +0.j 0.09567086-0.23096988j 0.1767767 +0.1767767j -0.23096988+0.09567086j 0. -0.25j 0.23096988+0.09567086j -0.1767767 +0.1767767j -0.09567086-0.23096988j] [ 0.25 +0.j -0.1767767 +0.1767767j 0. -0.25j 0.1767767 +0.1767767j -0.25 +0.j 0.1767767 -0.1767767j 0. +0.25j -0.1767767 -0.1767767j 0.25 +0.j -0.1767767 +0.1767767j 0. -0.25j 0.1767767 +0.1767767j -0.25 +0.j 0.1767767 -0.1767767j 0. +0.25j -0.1767767 -0.1767767j ] [ 0.25 +0.j -0.23096988+0.09567086j 0.1767767 -0.1767767j -0.09567086+0.23096988j 0. -0.25j 0.09567086+0.23096988j -0.1767767 -0.1767767j 0.23096988+0.09567086j -0.25 +0.j 0.23096988-0.09567086j -0.1767767 +0.1767767j 0.09567086-0.23096988j 0. +0.25j -0.09567086-0.23096988j 0.1767767 +0.1767767j -0.23096988-0.09567086j] [ 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j 0.25 +0.j -0.25 +0.j ] [ 0.25 +0.j -0.23096988-0.09567086j 0.1767767 +0.1767767j -0.09567086-0.23096988j 0. +0.25j 0.09567086-0.23096988j -0.1767767 +0.1767767j 0.23096988-0.09567086j -0.25 +0.j 0.23096988+0.09567086j -0.1767767 -0.1767767j 0.09567086+0.23096988j 0. -0.25j -0.09567086+0.23096988j 0.1767767 -0.1767767j -0.23096988+0.09567086j] [ 0.25 +0.j -0.1767767 -0.1767767j 0. +0.25j 0.1767767 -0.1767767j -0.25 +0.j 0.1767767 +0.1767767j 0. -0.25j -0.1767767 +0.1767767j 0.25 +0.j -0.1767767 -0.1767767j 0. +0.25j 0.1767767 -0.1767767j -0.25 +0.j 0.1767767 +0.1767767j 0. -0.25j -0.1767767 +0.1767767j ] [ 0.25 +0.j -0.09567086-0.23096988j -0.1767767 +0.1767767j 0.23096988+0.09567086j 0. -0.25j -0.23096988+0.09567086j 0.1767767 +0.1767767j 0.09567086-0.23096988j -0.25 +0.j 0.09567086+0.23096988j 0.1767767 -0.1767767j -0.23096988-0.09567086j 0. +0.25j 0.23096988-0.09567086j -0.1767767 -0.1767767j -0.09567086+0.23096988j] [ 0.25 +0.j 0. -0.25j -0.25 +0.j 0. +0.25j 0.25 +0.j 0. -0.25j -0.25 +0.j 0. +0.25j 0.25 +0.j 0. -0.25j -0.25 +0.j 0. +0.25j 0.25 +0.j 0. -0.25j -0.25 +0.j 0. +0.25j ] [ 0.25 +0.j 0.09567086-0.23096988j -0.1767767 -0.1767767j -0.23096988+0.09567086j 0. +0.25j 0.23096988+0.09567086j 0.1767767 -0.1767767j -0.09567086-0.23096988j -0.25 +0.j -0.09567086+0.23096988j 0.1767767 +0.1767767j 0.23096988-0.09567086j 0. -0.25j -0.23096988-0.09567086j -0.1767767 +0.1767767j 0.09567086+0.23096988j] [ 0.25 +0.j 0.1767767 -0.1767767j 0. -0.25j -0.1767767 -0.1767767j -0.25 +0.j -0.1767767 +0.1767767j 0. +0.25j 0.1767767 +0.1767767j 0.25 +0.j 0.1767767 -0.1767767j 0. -0.25j -0.1767767 -0.1767767j -0.25 +0.j -0.1767767 +0.1767767j 0. +0.25j 0.1767767 +0.1767767j ] [ 0.25 +0.j 0.23096988-0.09567086j 0.1767767 -0.1767767j 0.09567086-0.23096988j 0. -0.25j -0.09567086-0.23096988j -0.1767767 -0.1767767j -0.23096988-0.09567086j -0.25 +0.j -0.23096988+0.09567086j -0.1767767 +0.1767767j -0.09567086+0.23096988j 0. +0.25j 0.09567086+0.23096988j 0.1767767 +0.1767767j 0.23096988+0.09567086j]]","title":"Unitary representation"},{"location":"algorithms/qft/qft/#references","text":"https://www.youtube.com/watch?v=bntew-yoMzk","title":"References"},{"location":"algorithms/shor/shor/","text":"Coming Soon Under construction","title":"Shor's Algorithm"},{"location":"algorithms/shor/shor/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"circuits/bell/bell/","text":"Bell State The Bell states, a concept in quantum information science, are specific quantum states of two qubits that represent the simplest (and maximal) examples of quantum entanglement. The Bell states are a form of entangled and normalized basis vectors. This normalization implies that the overall probability of the particle being in one of the mentioned states is 1.[Wikipedia] Import 'Qiskit' libraries % matplotlib inline # Importing standard Qiskit libraries and configuring account from qiskit import QuantumCircuit,QuantumRegister,ClassicalRegister, execute, Aer, IBMQ from qiskit.compiler import transpile, assemble from qiskit.tools.jupyter import * from qiskit.visualization import * Bell circuit Design a Bell state circuit. num_qubits = 2 ; num_bits = 2 ; bell = QuantumCircuit( 2 , 2 ) bell . h( 0 ) bell . cx( 0 , 1 ) bell . measure([ 0 , 1 ], [ 0 , 1 ]) bell . draw(output = 'mpl' ) Manual approach initial state = |00> After application of Hadamard Gate: \\( \\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|10> \\) After application of CNOT Gate: \\( \\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|11> \\) Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(bell, simulator) . result() counts = result . get_counts(bell) plot_histogram(counts, title = 'Bell-State counts' ) Extended Bell circuit -1 Extend the bell state circuit by adding one more Hadamard gate on second qubit and CNOT gate. num_qubits = 2 ; num_bits = 2 ; bell = QuantumCircuit( 2 , 2 ) bell . h( 0 ) bell . cx( 0 , 1 ) bell . h( 1 ) bell . cx( 0 , 1 ) bell . measure([ 0 , 1 ], [ 0 , 1 ]) bell . draw(output = 'mpl' ) Manual approach: Initial state = |00> After application of Hadamard Gate: \\( \\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|10> \\) After application of CNOT Gate: \\( \\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|11> \\) After application of Hadamard Gate: \\( \\frac{1}{2}|00> + \\frac{1}{2}|01> + \\frac{1}{2}|10> - \\frac{1}{2}|11> \\) After application of CNOT Gate: \\( \\frac{1}{2}|00> + \\frac{1}{2}|01> + \\frac{1}{2}|11> - \\frac{1}{2}|10> \\) Simulation simulator = Aer.get_backend('qasm_simulator') result = execute(bell, simulator).result() counts = result.get_counts(bell) plot_histogram(counts, title='Bell-State counts') Extended Bell circuit - 2 Extend the bell state circuit by adding two more Hadamard gates and two CNOT gates with three qubits. n = 3 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . cx(q[ 0 ], q[ 1 ]) circ . h(q[ 1 ]) circ . cx(q[ 1 ], q[ 2 ]) circ . h(q[ 2 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style) Manual approach Initial state: |000> After Hadamard Gate : \\( \\frac{1}{\\sqrt{2}}|000> + \\frac{1}{\\sqrt{2}}|100> \\) After CNOT Gate : \\( \\frac{1}{\\sqrt{2}}|000> + \\frac{1}{\\sqrt{2}}|110> \\) After Hadamard Gate :\\( \\frac{1}{{2}}|000> + \\frac{1}{{2}}|010> + \\frac{1}{{2}}|100> - \\frac{1}{{2}}|110>\\) After CNOT Gate :\\( \\frac{1}{{2}}|000> + \\frac{1}{{2}}|011> + \\frac{1}{{2}}|100> - \\frac{1}{{2}}|111>\\) After Hadamard Gate :\\( \\frac{1}{2\\sqrt{2}}( |000> + |001> + |010> - |011> + |100> + |101> - |110> + |111>) \\) Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' ) Reference https://www.quantum-inspire.com/kbase/hadamard/","title":"Bell state"},{"location":"circuits/bell/bell/#bell-state","text":"The Bell states, a concept in quantum information science, are specific quantum states of two qubits that represent the simplest (and maximal) examples of quantum entanglement. The Bell states are a form of entangled and normalized basis vectors. This normalization implies that the overall probability of the particle being in one of the mentioned states is 1.[Wikipedia] Import 'Qiskit' libraries % matplotlib inline # Importing standard Qiskit libraries and configuring account from qiskit import QuantumCircuit,QuantumRegister,ClassicalRegister, execute, Aer, IBMQ from qiskit.compiler import transpile, assemble from qiskit.tools.jupyter import * from qiskit.visualization import *","title":"Bell State"},{"location":"circuits/bell/bell/#bell-circuit","text":"Design a Bell state circuit. num_qubits = 2 ; num_bits = 2 ; bell = QuantumCircuit( 2 , 2 ) bell . h( 0 ) bell . cx( 0 , 1 ) bell . measure([ 0 , 1 ], [ 0 , 1 ]) bell . draw(output = 'mpl' )","title":"Bell circuit"},{"location":"circuits/bell/bell/#manual-approach","text":"initial state = |00> After application of Hadamard Gate: \\( \\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|10> \\) After application of CNOT Gate: \\( \\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|11> \\)","title":"Manual approach"},{"location":"circuits/bell/bell/#simulation","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(bell, simulator) . result() counts = result . get_counts(bell) plot_histogram(counts, title = 'Bell-State counts' )","title":"Simulation"},{"location":"circuits/bell/bell/#extended-bell-circuit-1","text":"Extend the bell state circuit by adding one more Hadamard gate on second qubit and CNOT gate. num_qubits = 2 ; num_bits = 2 ; bell = QuantumCircuit( 2 , 2 ) bell . h( 0 ) bell . cx( 0 , 1 ) bell . h( 1 ) bell . cx( 0 , 1 ) bell . measure([ 0 , 1 ], [ 0 , 1 ]) bell . draw(output = 'mpl' )","title":"Extended Bell circuit -1"},{"location":"circuits/bell/bell/#manual-approach_1","text":"Initial state = |00> After application of Hadamard Gate: \\( \\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|10> \\) After application of CNOT Gate: \\( \\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|11> \\) After application of Hadamard Gate: \\( \\frac{1}{2}|00> + \\frac{1}{2}|01> + \\frac{1}{2}|10> - \\frac{1}{2}|11> \\) After application of CNOT Gate: \\( \\frac{1}{2}|00> + \\frac{1}{2}|01> + \\frac{1}{2}|11> - \\frac{1}{2}|10> \\)","title":"Manual approach:"},{"location":"circuits/bell/bell/#simulation_1","text":"simulator = Aer.get_backend('qasm_simulator') result = execute(bell, simulator).result() counts = result.get_counts(bell) plot_histogram(counts, title='Bell-State counts')","title":"Simulation"},{"location":"circuits/bell/bell/#extended-bell-circuit-2","text":"Extend the bell state circuit by adding two more Hadamard gates and two CNOT gates with three qubits. n = 3 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . cx(q[ 0 ], q[ 1 ]) circ . h(q[ 1 ]) circ . cx(q[ 1 ], q[ 2 ]) circ . h(q[ 2 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style)","title":"Extended Bell circuit - 2"},{"location":"circuits/bell/bell/#manual-approach_2","text":"Initial state: |000> After Hadamard Gate : \\( \\frac{1}{\\sqrt{2}}|000> + \\frac{1}{\\sqrt{2}}|100> \\) After CNOT Gate : \\( \\frac{1}{\\sqrt{2}}|000> + \\frac{1}{\\sqrt{2}}|110> \\) After Hadamard Gate :\\( \\frac{1}{{2}}|000> + \\frac{1}{{2}}|010> + \\frac{1}{{2}}|100> - \\frac{1}{{2}}|110>\\) After CNOT Gate :\\( \\frac{1}{{2}}|000> + \\frac{1}{{2}}|011> + \\frac{1}{{2}}|100> - \\frac{1}{{2}}|111>\\) After Hadamard Gate :\\( \\frac{1}{2\\sqrt{2}}( |000> + |001> + |010> - |011> + |100> + |101> - |110> + |111>) \\)","title":"Manual approach"},{"location":"circuits/bell/bell/#simulation_2","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' )","title":"Simulation"},{"location":"circuits/bell/bell/#reference","text":"https://www.quantum-inspire.com/kbase/hadamard/","title":"Reference"},{"location":"circuits/hadamard/hadamard/","text":"Hadamard Gate and Circuits Hadamard gate is single qubit operator. This transforms |0> state to a superposed state \\(\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>\\) and stae|1> to a superposed state \\(\\frac{1}{\\sqrt{2}}|0> - \\frac{1}{\\sqrt{2}}|1>\\). This gate is very important gate to construct Bell state, Quantum Fourier Transform (QFT) and many more. Import python library to perform computation in 'Qiskit' environment. % matplotlib inline # Importing standard Qiskit libraries and configuring account from qiskit import QuantumCircuit, QuantumRegister,ClassicalRegister from qiskit import execute, Aer, IBMQ from qiskit.compiler import transpile, assemble from qiskit.tools.jupyter import * from qiskit.visualization import * from qiskit.providers.aer import UnitarySimulator Hadamard Gate (1 qubit) Design the single Hadamard gate quantum circuit. n = 1 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style) Manual approach: Initial state: |0> After Hadamard Gate: \\(\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>\\) Algebra: $$ H = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}; |1 > = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} ; |0> = \\begin{bmatrix} 0\\\\ 1 \\end{bmatrix}$$ Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' ) Unitary representation n = 1 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.70710678+0.j 0.70710678+0.j] [ 0.70710678+0.j -0.70710678+0.j]] Hadamard Gate (2 qubits) Lets perform three different configurations of quantum circuit with two qubits and Hadamard gates. Type -I : Hadamard gate on first qubit $$I \\otimes H = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 & 0 & 0\\\\ 1 & -1 & 0 & 0\\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & -1 \\end{bmatrix} $$ Design circuit with two qubit with Hadamard on first qubit and perform the measurement. n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style) Unitary representation n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.70710678+0.j 0.70710678+0.j 0. +0.j 0. +0.j] [ 0.70710678+0.j -0.70710678+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0.70710678+0.j 0.70710678+0.j] [ 0. +0.j 0. +0.j 0.70710678+0.j -0.70710678+0.j]] Type -II : Hadamard on second qubit $$ H \\otimes I = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1\\\\ 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{bmatrix} $$ Design a quantum circuit with two qubits and Hadamard gate on first qubit. Perform the measurement. n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 1 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style) Unitary representation n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 1 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.70710678+0.j 0. +0.j 0.70710678+0.j 0. +0.j] [ 0. +0.j 0.70710678+0.j 0. +0.j 0.70710678+0.j] [ 0.70710678+0.j 0. +0.j -0.70710678+0.j 0. +0.j] [ 0. +0.j 0.70710678+0.j 0. +0.j -0.70710678+0.j]] Type -III : Hadamard gate on both qubits $$ H_1 \\otimes H_1 = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\frac{1}{2} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ \\end{bmatrix}$$ Design the quantum circuit with two Hadamard gates and perform measurement. n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . h(q[ 1 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style) Manual approach Initial state: |00> After Hadamard Gate: \\(\\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|10>\\) After Hadamard Gate: \\(\\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11>\\) This is tensor product of two Hadamard transform: \\(H|0>_A \\otimes H|0>_B\\) i.e., \\((\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) \\otimes (\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) = \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11> \\) Tensor Algebra: H operator in product space, \\(H_2 = H_1 \\otimes H_1\\) : $$\\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\frac{1}{2} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ \\end{bmatrix}$$ Basis States in product space, \\(|q_1q_2> = q_1 \\otimes q_2\\) : $$|00> = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ 0 \\end{bmatrix} ; |01> = \\begin{bmatrix} 0\\\\ 1\\\\ 0\\\\ 0 \\end{bmatrix} ; |10> = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1\\\\ 0 \\end{bmatrix} ; |11> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 1 \\end{bmatrix}$$ Linear transformation in product space: Above transformation can be represented as : $$H_2|00> = \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11>$$ With above basis vector, a state \\( \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11>\\) can be expressed as: $$\\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ \\frac{1}{2}\\\\ \\frac{1}{2} \\end{bmatrix}$$ Thus in Matrix Form: $$ H_2|00> = \\frac{1}{2} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ \\end{bmatrix}\\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ 0 \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ \\frac{1}{2}\\\\ \\frac{1}{2} \\end{bmatrix}$$ $$= \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11> $$ Tensor product of linear map: The tensor product also operates on linear maps between vector spaces. Specifically, given two linear maps \\(\ud835\udc46:\ud835\udc49\u2192\ud835\udc4b\\) and \\(\ud835\udc47:\ud835\udc4a\u2192\ud835\udc4c\\) between vector spaces, the tensor product of the two linear maps \ud835\udc46 and \ud835\udc47 is a linear map \\((\ud835\udc46 \\otimes \ud835\udc47)(v \\otimes w) = \ud835\udc46(v) \\otimes \ud835\udc47(w) \\). Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' ) Unitary representation n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . h(q[ 1 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.5+0.j 0.5+0.j 0.5+0.j 0.5+0.j] [ 0.5+0.j -0.5+0.j 0.5+0.j -0.5+0.j] [ 0.5+0.j 0.5+0.j -0.5+0.j -0.5+0.j] [ 0.5+0.j -0.5+0.j -0.5+0.j 0.5+0.j]] Multiple Hadamard gates (3 qubits) Desigh the quantum circuit and perform measurement n = 3 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . h(q[ 1 ]) circ . h(q[ 2 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style) Manual approach Initial state: |000> After Hadamard gate on first qubit: \\( \\frac{1}{\\sqrt{2}}|000> + \\frac{1}{\\sqrt{2}}|100> \\) After Hadamard gate on second qubit: \\(\\frac{1}{{2}}|000> + \\frac{1}{{2}}|010> + \\frac{1}{{2}}|100> + \\frac{1}{{2}}|110>\\) After Hadamard gate on third qubit: \\( \\frac{1}{2\\sqrt{2}}(|000> + |001> + |010> + |011> + |100> + |101> + |110> + |111>) \\) which is equivalent to \\((\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) \\otimes (\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) \\otimes (\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) \\) Tensor Algebra: H operator in product space: \\( H_3 = H_1 \\otimes H_1 \\otimes H_1 = H_2 \\otimes H_1\\): $$ \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\frac{1}{2} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}$$ $$ = \\frac{1}{2\\sqrt{2}} \\begin{bmatrix} 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 & 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 & 1 & -1 & -1 & 1 \\\\ 1 & 1 & 1 & 1 & -1 & -1 & -1 & -1 \\\\ 1 & -1 & 1 & -1 & -1 & 1 & -1 & 1 \\\\ 1 & 1 & -1 & -1 & -1 & -1 & 1 & 1 \\\\ 1 & -1 & -1 & 1 & -1 & 1 & 1 & -1 \\\\ \\end{bmatrix}$$ Basis states in product space: \\( |q_1q_2q_3> = q_1 \\otimes q_2 \\otimes q_3\\) : $$ |000> = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ \\end{bmatrix} ; |001> = \\begin{bmatrix} 0\\\\ 1\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}; |010> = \\begin{bmatrix} 0\\\\ 0\\\\ 1\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}; |011> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 1\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}; |100> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}$$ $$ |101> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\ 0\\\\ 0 \\end{bmatrix}; |110> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\ 0 \\end{bmatrix}; |111> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1 \\end{bmatrix}$$ Above transformation can be represented as : \\( H_3|000> = \\frac{1}{2\\sqrt{2}}(|000> + |001> + |010> + |011> + |100> + |101> + |110> +|111>)\\). With above basis vector this quantum state can be expressed as: $$\\begin{bmatrix} \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}} \\end{bmatrix}$$ Thus in Matrix Form: $$ H_3|000> = \\frac{1}{2\\sqrt{2}} \\begin{bmatrix} 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 & 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 & 1 & -1 & -1 & 1 \\\\ 1 & 1 & 1 & 1 & -1 & -1 & -1 & -1 \\\\ 1 & -1 & 1 & -1 & -1 & 1 & -1 & 1 \\\\ 1 & 1 & -1 & -1 & -1 & -1 & 1 & 1 \\\\ 1 & -1 & -1 & 1 & -1 & 1 & 1 & -1 \\\\ \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}} \\end{bmatrix} $$ $$ = \\frac{1}{2\\sqrt{2}}(|000> + |001> + |010> + |011> + |100> + |101> + |110> +|111>)$$ Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' ) Unitary representation n = 3 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . h(q[ 1 ]) circ . h(q[ 2 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j] [ 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j] [ 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j] [ 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j] [ 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j -0.35355339+0.j -0.35355339+0.j] [ 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j] [ 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j 0.35355339+0.j] [ 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j]] Multiple Hadamard gates (8 Qubits) Quantum Circuit n = 8 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) for k in range ( 8 ): circ . h(q[k]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightpink' } circ . draw(output = 'mpl' , style = style) Simulation simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' ) Unitary representation n = 8 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) for k in range ( 8 ): circ . h(q[k]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.0625+0.j 0.0625+0.j 0.0625+0.j ... 0.0625+0.j 0.0625+0.j 0.0625+0.j] [ 0.0625+0.j -0.0625+0.j 0.0625+0.j ... -0.0625+0.j 0.0625+0.j -0.0625+0.j] [ 0.0625+0.j 0.0625+0.j -0.0625+0.j ... 0.0625+0.j -0.0625+0.j -0.0625+0.j] ... [ 0.0625+0.j -0.0625+0.j 0.0625+0.j ... -0.0625+0.j 0.0625+0.j -0.0625+0.j] [ 0.0625+0.j 0.0625+0.j -0.0625+0.j ... 0.0625+0.j -0.0625+0.j -0.0625+0.j] [ 0.0625+0.j -0.0625+0.j -0.0625+0.j ... -0.0625+0.j -0.0625+0.j 0.0625+0.j]] unitary . shape (256, 256) The End Reference: https://quantumcomputing.stackexchange.com/questions/2270/how-to-input-2-qubits-in-2-hadamard-gates","title":"Superposition"},{"location":"circuits/hadamard/hadamard/#hadamard-gate-and-circuits","text":"Hadamard gate is single qubit operator. This transforms |0> state to a superposed state \\(\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>\\) and stae|1> to a superposed state \\(\\frac{1}{\\sqrt{2}}|0> - \\frac{1}{\\sqrt{2}}|1>\\). This gate is very important gate to construct Bell state, Quantum Fourier Transform (QFT) and many more. Import python library to perform computation in 'Qiskit' environment. % matplotlib inline # Importing standard Qiskit libraries and configuring account from qiskit import QuantumCircuit, QuantumRegister,ClassicalRegister from qiskit import execute, Aer, IBMQ from qiskit.compiler import transpile, assemble from qiskit.tools.jupyter import * from qiskit.visualization import * from qiskit.providers.aer import UnitarySimulator","title":"Hadamard Gate and Circuits"},{"location":"circuits/hadamard/hadamard/#hadamard-gate-1-qubit","text":"Design the single Hadamard gate quantum circuit. n = 1 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style)","title":"Hadamard Gate (1 qubit)"},{"location":"circuits/hadamard/hadamard/#manual-approach","text":"Initial state: |0> After Hadamard Gate: \\(\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>\\)","title":"Manual approach:"},{"location":"circuits/hadamard/hadamard/#algebra","text":"$$ H = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}; |1 > = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} ; |0> = \\begin{bmatrix} 0\\\\ 1 \\end{bmatrix}$$","title":"Algebra:"},{"location":"circuits/hadamard/hadamard/#simulation","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' )","title":"Simulation"},{"location":"circuits/hadamard/hadamard/#unitary-representation","text":"n = 1 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.70710678+0.j 0.70710678+0.j] [ 0.70710678+0.j -0.70710678+0.j]]","title":"Unitary representation"},{"location":"circuits/hadamard/hadamard/#hadamard-gate-2-qubits","text":"Lets perform three different configurations of quantum circuit with two qubits and Hadamard gates.","title":"Hadamard Gate (2 qubits)"},{"location":"circuits/hadamard/hadamard/#type-i-hadamard-gate-on-first-qubit","text":"$$I \\otimes H = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 & 0 & 0\\\\ 1 & -1 & 0 & 0\\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & -1 \\end{bmatrix} $$ Design circuit with two qubit with Hadamard on first qubit and perform the measurement. n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style)","title":"Type -I : Hadamard gate on first qubit"},{"location":"circuits/hadamard/hadamard/#unitary-representation_1","text":"n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.70710678+0.j 0.70710678+0.j 0. +0.j 0. +0.j] [ 0.70710678+0.j -0.70710678+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0.70710678+0.j 0.70710678+0.j] [ 0. +0.j 0. +0.j 0.70710678+0.j -0.70710678+0.j]]","title":"Unitary representation"},{"location":"circuits/hadamard/hadamard/#type-ii-hadamard-on-second-qubit","text":"$$ H \\otimes I = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1\\\\ 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1 \\end{bmatrix} $$ Design a quantum circuit with two qubits and Hadamard gate on first qubit. Perform the measurement. n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 1 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style)","title":"Type -II : Hadamard on second qubit"},{"location":"circuits/hadamard/hadamard/#unitary-representation_2","text":"n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 1 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.70710678+0.j 0. +0.j 0.70710678+0.j 0. +0.j] [ 0. +0.j 0.70710678+0.j 0. +0.j 0.70710678+0.j] [ 0.70710678+0.j 0. +0.j -0.70710678+0.j 0. +0.j] [ 0. +0.j 0.70710678+0.j 0. +0.j -0.70710678+0.j]]","title":"Unitary representation"},{"location":"circuits/hadamard/hadamard/#type-iii-hadamard-gate-on-both-qubits","text":"$$ H_1 \\otimes H_1 = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\frac{1}{2} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ \\end{bmatrix}$$ Design the quantum circuit with two Hadamard gates and perform measurement. n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . h(q[ 1 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style)","title":"Type -III : Hadamard gate on both qubits"},{"location":"circuits/hadamard/hadamard/#manual-approach_1","text":"Initial state: |00> After Hadamard Gate: \\(\\frac{1}{\\sqrt{2}}|00> + \\frac{1}{\\sqrt{2}}|10>\\) After Hadamard Gate: \\(\\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11>\\) This is tensor product of two Hadamard transform: \\(H|0>_A \\otimes H|0>_B\\) i.e., \\((\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) \\otimes (\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) = \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11> \\)","title":"Manual approach"},{"location":"circuits/hadamard/hadamard/#tensor-algebra","text":"H operator in product space, \\(H_2 = H_1 \\otimes H_1\\) : $$\\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\frac{1}{2} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ \\end{bmatrix}$$ Basis States in product space, \\(|q_1q_2> = q_1 \\otimes q_2\\) : $$|00> = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ 0 \\end{bmatrix} ; |01> = \\begin{bmatrix} 0\\\\ 1\\\\ 0\\\\ 0 \\end{bmatrix} ; |10> = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1\\\\ 0 \\end{bmatrix} ; |11> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 1 \\end{bmatrix}$$ Linear transformation in product space: Above transformation can be represented as : $$H_2|00> = \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11>$$ With above basis vector, a state \\( \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11>\\) can be expressed as: $$\\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ \\frac{1}{2}\\\\ \\frac{1}{2} \\end{bmatrix}$$ Thus in Matrix Form: $$ H_2|00> = \\frac{1}{2} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ \\end{bmatrix}\\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ 0 \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ \\frac{1}{2}\\\\ \\frac{1}{2} \\end{bmatrix}$$ $$= \\frac{1}{{2}}|00> + \\frac{1}{{2}}|01> + \\frac{1}{{2}}|10> + \\frac{1}{{2}}|11> $$","title":"Tensor Algebra:"},{"location":"circuits/hadamard/hadamard/#tensor-product-of-linear-map","text":"The tensor product also operates on linear maps between vector spaces. Specifically, given two linear maps \\(\ud835\udc46:\ud835\udc49\u2192\ud835\udc4b\\) and \\(\ud835\udc47:\ud835\udc4a\u2192\ud835\udc4c\\) between vector spaces, the tensor product of the two linear maps \ud835\udc46 and \ud835\udc47 is a linear map \\((\ud835\udc46 \\otimes \ud835\udc47)(v \\otimes w) = \ud835\udc46(v) \\otimes \ud835\udc47(w) \\).","title":"Tensor product of linear map:"},{"location":"circuits/hadamard/hadamard/#simulation_1","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' )","title":"Simulation"},{"location":"circuits/hadamard/hadamard/#unitary-representation_3","text":"n = 2 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . h(q[ 1 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.5+0.j 0.5+0.j 0.5+0.j 0.5+0.j] [ 0.5+0.j -0.5+0.j 0.5+0.j -0.5+0.j] [ 0.5+0.j 0.5+0.j -0.5+0.j -0.5+0.j] [ 0.5+0.j -0.5+0.j -0.5+0.j 0.5+0.j]]","title":"Unitary representation"},{"location":"circuits/hadamard/hadamard/#multiple-hadamard-gates-3-qubits","text":"Desigh the quantum circuit and perform measurement n = 3 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . h(q[ 1 ]) circ . h(q[ 2 ]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightgreen' } circ . draw(output = 'mpl' , style = style)","title":"Multiple Hadamard gates (3 qubits)"},{"location":"circuits/hadamard/hadamard/#manual-approach_2","text":"Initial state: |000> After Hadamard gate on first qubit: \\( \\frac{1}{\\sqrt{2}}|000> + \\frac{1}{\\sqrt{2}}|100> \\) After Hadamard gate on second qubit: \\(\\frac{1}{{2}}|000> + \\frac{1}{{2}}|010> + \\frac{1}{{2}}|100> + \\frac{1}{{2}}|110>\\) After Hadamard gate on third qubit: \\( \\frac{1}{2\\sqrt{2}}(|000> + |001> + |010> + |011> + |100> + |101> + |110> + |111>) \\) which is equivalent to \\((\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) \\otimes (\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) \\otimes (\\frac{1}{\\sqrt{2}}|0> + \\frac{1}{\\sqrt{2}}|1>) \\)","title":"Manual approach"},{"location":"circuits/hadamard/hadamard/#tensor-algebra_1","text":"H operator in product space: \\( H_3 = H_1 \\otimes H_1 \\otimes H_1 = H_2 \\otimes H_1\\): $$ \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\frac{1}{2} \\begin{bmatrix} 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ \\end{bmatrix} \\otimes \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}$$ $$ = \\frac{1}{2\\sqrt{2}} \\begin{bmatrix} 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 & 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 & 1 & -1 & -1 & 1 \\\\ 1 & 1 & 1 & 1 & -1 & -1 & -1 & -1 \\\\ 1 & -1 & 1 & -1 & -1 & 1 & -1 & 1 \\\\ 1 & 1 & -1 & -1 & -1 & -1 & 1 & 1 \\\\ 1 & -1 & -1 & 1 & -1 & 1 & 1 & -1 \\\\ \\end{bmatrix}$$ Basis states in product space: \\( |q_1q_2q_3> = q_1 \\otimes q_2 \\otimes q_3\\) : $$ |000> = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ \\end{bmatrix} ; |001> = \\begin{bmatrix} 0\\\\ 1\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}; |010> = \\begin{bmatrix} 0\\\\ 0\\\\ 1\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}; |011> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 1\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}; |100> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix}$$ $$ |101> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\ 0\\\\ 0 \\end{bmatrix}; |110> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1\\\\ 0 \\end{bmatrix}; |111> = \\begin{bmatrix} 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 1 \\end{bmatrix}$$ Above transformation can be represented as : \\( H_3|000> = \\frac{1}{2\\sqrt{2}}(|000> + |001> + |010> + |011> + |100> + |101> + |110> +|111>)\\). With above basis vector this quantum state can be expressed as: $$\\begin{bmatrix} \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}} \\end{bmatrix}$$ Thus in Matrix Form: $$ H_3|000> = \\frac{1}{2\\sqrt{2}} \\begin{bmatrix} 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 & 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 & 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1 & 1 & -1 & -1 & 1 \\\\ 1 & 1 & 1 & 1 & -1 & -1 & -1 & -1 \\\\ 1 & -1 & 1 & -1 & -1 & 1 & -1 & 1 \\\\ 1 & 1 & -1 & -1 & -1 & -1 & 1 & 1 \\\\ 1 & -1 & -1 & 1 & -1 & 1 & 1 & -1 \\\\ \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0\\\\ 0 \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}} \\\\ \\frac{1}{2\\sqrt{2}}\\\\ \\frac{1}{2\\sqrt{2}} \\end{bmatrix} $$ $$ = \\frac{1}{2\\sqrt{2}}(|000> + |001> + |010> + |011> + |100> + |101> + |110> +|111>)$$","title":"Tensor Algebra:"},{"location":"circuits/hadamard/hadamard/#simulation_2","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' )","title":"Simulation"},{"location":"circuits/hadamard/hadamard/#unitary-representation_4","text":"n = 3 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) circ . h(q[ 0 ]) circ . h(q[ 1 ]) circ . h(q[ 2 ]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j] [ 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j] [ 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j] [ 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j] [ 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j -0.35355339+0.j -0.35355339+0.j] [ 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j] [ 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j 0.35355339+0.j] [ 0.35355339+0.j -0.35355339+0.j -0.35355339+0.j 0.35355339+0.j -0.35355339+0.j 0.35355339+0.j 0.35355339+0.j -0.35355339+0.j]]","title":"Unitary representation"},{"location":"circuits/hadamard/hadamard/#multiple-hadamard-gates-8-qubits","text":"","title":"Multiple Hadamard gates (8 Qubits)"},{"location":"circuits/hadamard/hadamard/#quantum-circuit","text":"n = 8 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) for k in range ( 8 ): circ . h(q[k]) circ . measure(q,c) # Change the background color in mpl style = { 'backgroundcolor' : 'lightpink' } circ . draw(output = 'mpl' , style = style)","title":"Quantum Circuit"},{"location":"circuits/hadamard/hadamard/#simulation_3","text":"simulator = Aer . get_backend( 'qasm_simulator' ) result = execute(circ, simulator) . result() counts = result . get_counts(circ) plot_histogram(counts, title = 'Bell-State counts' )","title":"Simulation"},{"location":"circuits/hadamard/hadamard/#unitary-representation_5","text":"n = 8 q = QuantumRegister(n) c = ClassicalRegister(n) circ = QuantumCircuit(q,c) for k in range ( 8 ): circ . h(q[k]) # Select the UnitarySimulator from the Aer provider simulator = Aer . get_backend( 'unitary_simulator' ) # Execute and get counts result = execute(circ, simulator) . result() unitary = result . get_unitary(circ) print ( unitary) [[ 0.0625+0.j 0.0625+0.j 0.0625+0.j ... 0.0625+0.j 0.0625+0.j 0.0625+0.j] [ 0.0625+0.j -0.0625+0.j 0.0625+0.j ... -0.0625+0.j 0.0625+0.j -0.0625+0.j] [ 0.0625+0.j 0.0625+0.j -0.0625+0.j ... 0.0625+0.j -0.0625+0.j -0.0625+0.j] ... [ 0.0625+0.j -0.0625+0.j 0.0625+0.j ... -0.0625+0.j 0.0625+0.j -0.0625+0.j] [ 0.0625+0.j 0.0625+0.j -0.0625+0.j ... 0.0625+0.j -0.0625+0.j -0.0625+0.j] [ 0.0625+0.j -0.0625+0.j -0.0625+0.j ... -0.0625+0.j -0.0625+0.j 0.0625+0.j]] unitary . shape (256, 256) The End","title":"Unitary representation"},{"location":"circuits/hadamard/hadamard/#reference","text":"https://quantumcomputing.stackexchange.com/questions/2270/how-to-input-2-qubits-in-2-hadamard-gates","title":"Reference:"},{"location":"circuits/random/random/","text":"Qiskit Aqua: Generating Random Variates The latest version of this notebook is available here . Contributors Albert Akhriev [1] , Jakub Marecek [1] Affliation [1] IBMQ Introduction While classical computers use only pseudo-random routines, quantum computers can generate true random variates. For example, the measurement of a quantum superposition is intrinsically random, as suggested by Born's rule. Consequently, some of the best random-number generators are based on such quantum-mechanical effects. (See the Further, with a logarithmic amount of random bits, quantum computers can produce linearly many more bits, which is known as randomness expansion protocols. In practical applications, one wishes to use random variates of well-known distributions, rather than random bits. In this notebook, we illustrate ways of generating random variates of several popular distributions on IBM Q. Random Bits and the Bernoulli distribution It is clear that there are many options for generating random bits (i.e., Bernoulli-distributed scalars, taking values either 0 or 1). Starting from a simple circuit such as a Hadamard gate followed by measurement, one can progress to vectors of Bernoulli-distributed elements. By addition of such random variates, we could get binomial distributions. By multiplication we could get geometric distributions, although perhaps leading to a circuit depth that may be impratical at the moment, though. Let us start by importing the basic modules and creating a quantum circuit for generating random bits: import matplotlib.pyplot as plt % matplotlib inline import numpy as np import sys , math , time import warnings warnings . filterwarnings( \"ignore\" , category = DeprecationWarning ) from qiskit import BasicAer from qiskit import QuantumCircuit, QuantumRegister from qiskit import ClassicalRegister, execute # In this example we use 'qasm_simulator' backend. glo_backend = BasicAer . get_backend( \"qasm_simulator\" ) In the next step we create a quantum circuit, which will be used for generation: # Number of qubits utilised simultaneously. glo_num_qubits = 5 def create_circuit (num_target_qubits: int ) -> QuantumCircuit: \"\"\" Creates and returns quantum circuit for random variate generation. :param num_target_qubits: number of qubits to be used. :return: quantum curcuit. \"\"\" assert isinstance (num_target_qubits, int ) and num_target_qubits > 0 q = QuantumRegister(num_target_qubits) c = ClassicalRegister(num_target_qubits) circuit = QuantumCircuit(q, c) circuit . h(q) circuit . barrier() circuit . measure(q, c) return circuit # Create and plot generating quantum circuit. circuit = create_circuit(glo_num_qubits) #print(circuit) circuit . draw(output = 'mpl' ) Uniformly-distributed scalars and vectors It is clear that there are many options for approximating uniformly-distributed scalars by the choice of an integer from a finite range uniformly at random, e.g., by a binary-code construction from the Bernoulli-distributed vectors. In the following snippet, we generate random bits, which we then convert using the binary-code construction, up to the machine precision of a classical computer. def uniform_rand_float64 (circuit: QuantumCircuit, num_target_qubits: int , size: int , vmin: float , vmax: float ) -> np . ndarray: \"\"\" Generates a vector of random float64 values in the range [vmin, vmax]. :param circuit: quantum circuit for random variate generation. :param num_target_qubits: number of qubits to be used. :param size: length of the vector. :param vmin: lower bound. :param vmax: upper bound. :return: vector of random values. \"\"\" assert sys . maxsize == np . iinfo(np . int64) . max # sizeof(int) == 64 bits assert isinstance (size, int ) and size > 0 assert isinstance (vmin, float ) and isinstance (vmax, float ) and vmin <= vmax nbits = 7 * 8 # nbits > mantissa of float64 bit_str_len = (nbits * size + num_target_qubits - 1 ) // num_target_qubits job = execute(circuit, glo_backend, shots = bit_str_len, memory = True ) bit_str = '' . join(job . result() . get_memory()) scale = float (vmax - vmin) / float ( 2 ** nbits - 1 ) return np . array([vmin + scale * float ( int (bit_str[i:i + nbits], 2 )) for i in range ( 0 , nbits * size, nbits)], dtype = np . float64) def uniform_rand_int64 (circuit: QuantumCircuit, num_target_qubits: int , size: int , vmin: int , vmax: int ) -> np . ndarray: \"\"\" Generates a vector of random int64 values in the range [vmin, vmax]. :param circuit: quantum circuit for random variate generation. :param num_target_qubits: number of qubits to be used. :param size: length of the vector. :param vmin: lower bound. :param vmax: upper bound. :return: vector of random values. \"\"\" assert sys . maxsize == np . iinfo(np . int64) . max # sizeof(int) == 64 bits assert isinstance (size, int ) and size > 0 assert isinstance (vmin, int ) and isinstance (vmax, int ) and vmin <= vmax assert abs (vmin) <= 2 ** 52 and abs (vmax) <= 2 ** 52 # 52 == mantissa of float64 return np . rint(uniform_rand_float64(circuit, num_target_qubits, size, float (vmin), float (vmax))) . astype(np . int64) Uniform distribution over floating point numbers. In this example we draw a random vector of floating-point values uniformly distributed within some arbitrary selected interval: # Draw a sample from uniform distribution. start_time = time . time() sample = uniform_rand_float64(circuit, glo_num_qubits,\\ size = 54321 , vmin =- 7.67 , vmax = 19.52 ) sampling_time = time . time() - start_time # Print out some details. print ( \"Uniform distribution over floating point numbers:\" ) print ( \" sample type:\" , type (sample), \", \\ element type:\" , sample . dtype,\\ \", shape:\" , sample . shape) print ( \" sample min: {:.4f}, max: {:.4f}\" \\ . format(np . amin(sample), np . amax(sample))) print ( \" sampling time: {:.2f} secs\" . format(sampling_time)) # Plotting the distribution. plt . hist(sample . ravel(), bins = min ( int (np . ceil(np . sqrt(sample . size))), 100 ), density = True , facecolor = 'b' , alpha = 0.75 ) plt . xlabel( \"value\" , size = 12 ) plt . ylabel( \"probability\" , size = 12 ) plt . title( \"Uniform distribution over float64 numbers in \\ [{:.2f} ... {:.2f}]\" . format( np . amin(sample), np . amax(sample)), size = 12 ) plt . grid( True ) # plt.savefig(\"uniform_distrib_float.png\", bbox_inches=\"tight\") plt . show() Uniform distribution over floating point numbers: sample type: &lt;class 'numpy.ndarray'&gt; , element type: float64 , shape: (54321,) sample min: -7.6687, max: 19.5191 sampling time: 6.41 secs Uniform distribution over integers. Our next example is similar to the previous one, but here we generate a random vector of integers: # Draw a sample from uniform distribution. start_time = time . time() sample = uniform_rand_int64(circuit, glo_num_qubits,\\ size = 54321 , vmin = 37 , vmax = 841 ) sampling_time = time . time() - start_time # Print out some details. print ( \"Uniform distribution over bounded integer numbers:\" ) print ( \" sample type:\" , type (sample), \", \\ element type:\" , sample . dtype,\\ \", shape:\" , sample . shape) print ( \" sample min: {:d}, max: {:d}\" \\ . format(np . amin(sample), np . amax(sample))) print ( \" sampling time: {:.2f} secs\" \\ . format(sampling_time)) # Plotting the distribution. plt . hist(sample . ravel(), bins = min ( int (np . ceil(np . sqrt(sample . size))), 100 ), density = True , facecolor = 'g' , alpha = 0.75 ) plt . xlabel( \"value\" , size = 12 ) plt . ylabel( \"probability\" , size = 12 ) plt . title( \"Uniform distribution over int64 numbers in \\ [{:d} ... {:d}]\" . format( np . amin(sample), np . amax(sample)), size = 12 ) plt . grid( True ) # plt.savefig(\"uniform_distrib_int.png\", bbox_inches=\"tight\") plt . show() Uniform distribution over bounded integer numbers: sample type: &lt;class 'numpy.ndarray'&gt; , element type: int64 , shape: (54321,) sample min: 37, max: 841 sampling time: 7.15 secs Normal distribution To generate random variates with a standard normal distribution using two independent samples \\(u_1, u_2\\) of the uniform distribution on the unit interval [0, 1], one can consider the Box-Muller transform to obtain a 2-vector: \\begin{align} \\begin{bmatrix} %R\\cos(\\Theta )= {\\sqrt {-2\\ln u_{1}}}\\cos(2\\pi u_{2}) \\ % R\\sin(\\Theta )= {\\sqrt {-2\\ln u_{1}}}\\sin(2\\pi u_{2}) \\end{bmatrix}, \\end{align} wherein we have two independent samples of the standard normal distribution. In IBM Q, this is implemented as follows: def normal_rand_float64 (circuit: QuantumCircuit, num_target_qubits: int , size: int , mu: float , sigma: float ) -> np . ndarray: \"\"\" Draws a sample vector from the normal distribution given the mean and standard deviation, using the Box-Muller method. \"\"\" TINY = np . sqrt(np . finfo(np . float64) . tiny) assert isinstance (size, int ) and size > 0 rand_vec = np . zeros((size,), dtype = np . float64) # Generate array of uniformly distributed samples, factor 1.5 longer that # actually needed. n = ( 3 * size) // 2 x = np . reshape(uniform_rand_float64(circuit, num_target_qubits, 2 * n, 0.0 , 1.0 ), ( - 1 , 2 )) x1 = 0.0 # first sample in a pair c = 0 # counter for d in range (size): r2 = 2.0 while r2 >= 1.0 or r2 < TINY: # Regenerate array of uniformly distributed samples upon shortage. if c >= n: c = 0 n = max (size // 10 , 1 ) x = np . reshape(uniform_rand_float64(circuit, num_target_qubits, 2 * n, 0.0 , 1.0 ), ( - 1 , 2 )) x1 = 2.0 * x[c, 0 ] - 1.0 # first sample in a pair x2 = 2.0 * x[c, 1 ] - 1.0 # second sample in a pair r2 = x1 * x1 + x2 * x2 c += 1 f = np . sqrt(np . abs( - 2.0 * np . log(r2) / r2)) rand_vec[d] = f * x1 return (rand_vec * sigma + mu) The following example demonstrates how to draw a random vector of normally distributed variates: # Mean and standard deviation. mu = 2.4 sigma = 5.1 # Draw a sample from the normal distribution. start_time = time . time() sample = normal_rand_float64(circuit, glo_num_qubits,\\ size = 4321 , mu = mu, sigma = sigma) sampling_time = time . time() - start_time # Print out some details. print ( \"Normal distribution (mu={:.3f}, sigma={:.3f}):\" \\ . format(mu, sigma)) print ( \" sample type:\" , type (sample), \", element type:\" ,\\ sample . dtype, \", shape:\" , sample . shape) print ( \" sample min: {:.4f}, max: {:.4f}\" \\ . format(np . amin(sample), np . amax(sample))) print ( \" sampling time: {:.2f} secs\" . format(sampling_time)) # Plotting the distribution. x = np . linspace(mu - 4.0 * sigma, mu + 4.0 * sigma, 1000 ) analyt = np . exp( - 0.5 * ((x - mu) / sigma) ** 2 )\\ / (sigma * math . sqrt( 2.0 * math . pi)) plt . hist(sample . ravel(), bins = min ( int (np . ceil(np . sqrt(sample . size))), 100 ), density = True , facecolor = 'r' , alpha = 0.75 ) plt . plot(x, analyt, '-b' , lw = 1 ) plt . xlabel( \"value\" , size = 12 ) plt . ylabel( \"probability\" , size = 12 ) plt . title( \"Normal distribution: empirical vs analytic\" , size = 12 ) plt . grid( True ) # plt.savefig(\"normal_distrib.png\", bbox_inches=\"tight\") plt . show() Normal distribution (mu=2.400, sigma=5.100): sample type: &lt;class 'numpy.ndarray'&gt; , element type: float64 , shape: (4321,) sample min: -18.0259, max: 21.2915 sampling time: 1.85 secs There is a substantial amount of further work needed to either certify the quality of the source of random numbers (cf. NIST SP 800-90B, Recommendation for the Entropy Sources Used for Random Bit Generation) or to use random variates within quantum algorithms (cf. uncertainty_models within Qiskit Aqua).","title":"Random Variables"},{"location":"circuits/random/random/#qiskit-aqua-generating-random-variates","text":"The latest version of this notebook is available here .","title":"Qiskit Aqua: Generating Random Variates"},{"location":"circuits/random/random/#contributors","text":"Albert Akhriev [1] , Jakub Marecek [1]","title":"Contributors"},{"location":"circuits/random/random/#affliation","text":"[1] IBMQ","title":"Affliation"},{"location":"circuits/random/random/#introduction","text":"While classical computers use only pseudo-random routines, quantum computers can generate true random variates. For example, the measurement of a quantum superposition is intrinsically random, as suggested by Born's rule. Consequently, some of the best random-number generators are based on such quantum-mechanical effects. (See the Further, with a logarithmic amount of random bits, quantum computers can produce linearly many more bits, which is known as randomness expansion protocols. In practical applications, one wishes to use random variates of well-known distributions, rather than random bits. In this notebook, we illustrate ways of generating random variates of several popular distributions on IBM Q.","title":"Introduction"},{"location":"circuits/random/random/#random-bits-and-the-bernoulli-distribution","text":"It is clear that there are many options for generating random bits (i.e., Bernoulli-distributed scalars, taking values either 0 or 1). Starting from a simple circuit such as a Hadamard gate followed by measurement, one can progress to vectors of Bernoulli-distributed elements. By addition of such random variates, we could get binomial distributions. By multiplication we could get geometric distributions, although perhaps leading to a circuit depth that may be impratical at the moment, though. Let us start by importing the basic modules and creating a quantum circuit for generating random bits: import matplotlib.pyplot as plt % matplotlib inline import numpy as np import sys , math , time import warnings warnings . filterwarnings( \"ignore\" , category = DeprecationWarning ) from qiskit import BasicAer from qiskit import QuantumCircuit, QuantumRegister from qiskit import ClassicalRegister, execute # In this example we use 'qasm_simulator' backend. glo_backend = BasicAer . get_backend( \"qasm_simulator\" ) In the next step we create a quantum circuit, which will be used for generation: # Number of qubits utilised simultaneously. glo_num_qubits = 5 def create_circuit (num_target_qubits: int ) -> QuantumCircuit: \"\"\" Creates and returns quantum circuit for random variate generation. :param num_target_qubits: number of qubits to be used. :return: quantum curcuit. \"\"\" assert isinstance (num_target_qubits, int ) and num_target_qubits > 0 q = QuantumRegister(num_target_qubits) c = ClassicalRegister(num_target_qubits) circuit = QuantumCircuit(q, c) circuit . h(q) circuit . barrier() circuit . measure(q, c) return circuit # Create and plot generating quantum circuit. circuit = create_circuit(glo_num_qubits) #print(circuit) circuit . draw(output = 'mpl' )","title":"Random Bits and the Bernoulli distribution"},{"location":"circuits/random/random/#uniformly-distributed-scalars-and-vectors","text":"It is clear that there are many options for approximating uniformly-distributed scalars by the choice of an integer from a finite range uniformly at random, e.g., by a binary-code construction from the Bernoulli-distributed vectors. In the following snippet, we generate random bits, which we then convert using the binary-code construction, up to the machine precision of a classical computer. def uniform_rand_float64 (circuit: QuantumCircuit, num_target_qubits: int , size: int , vmin: float , vmax: float ) -> np . ndarray: \"\"\" Generates a vector of random float64 values in the range [vmin, vmax]. :param circuit: quantum circuit for random variate generation. :param num_target_qubits: number of qubits to be used. :param size: length of the vector. :param vmin: lower bound. :param vmax: upper bound. :return: vector of random values. \"\"\" assert sys . maxsize == np . iinfo(np . int64) . max # sizeof(int) == 64 bits assert isinstance (size, int ) and size > 0 assert isinstance (vmin, float ) and isinstance (vmax, float ) and vmin <= vmax nbits = 7 * 8 # nbits > mantissa of float64 bit_str_len = (nbits * size + num_target_qubits - 1 ) // num_target_qubits job = execute(circuit, glo_backend, shots = bit_str_len, memory = True ) bit_str = '' . join(job . result() . get_memory()) scale = float (vmax - vmin) / float ( 2 ** nbits - 1 ) return np . array([vmin + scale * float ( int (bit_str[i:i + nbits], 2 )) for i in range ( 0 , nbits * size, nbits)], dtype = np . float64) def uniform_rand_int64 (circuit: QuantumCircuit, num_target_qubits: int , size: int , vmin: int , vmax: int ) -> np . ndarray: \"\"\" Generates a vector of random int64 values in the range [vmin, vmax]. :param circuit: quantum circuit for random variate generation. :param num_target_qubits: number of qubits to be used. :param size: length of the vector. :param vmin: lower bound. :param vmax: upper bound. :return: vector of random values. \"\"\" assert sys . maxsize == np . iinfo(np . int64) . max # sizeof(int) == 64 bits assert isinstance (size, int ) and size > 0 assert isinstance (vmin, int ) and isinstance (vmax, int ) and vmin <= vmax assert abs (vmin) <= 2 ** 52 and abs (vmax) <= 2 ** 52 # 52 == mantissa of float64 return np . rint(uniform_rand_float64(circuit, num_target_qubits, size, float (vmin), float (vmax))) . astype(np . int64)","title":"Uniformly-distributed scalars and vectors"},{"location":"circuits/random/random/#uniform-distribution-over-floating-point-numbers","text":"In this example we draw a random vector of floating-point values uniformly distributed within some arbitrary selected interval: # Draw a sample from uniform distribution. start_time = time . time() sample = uniform_rand_float64(circuit, glo_num_qubits,\\ size = 54321 , vmin =- 7.67 , vmax = 19.52 ) sampling_time = time . time() - start_time # Print out some details. print ( \"Uniform distribution over floating point numbers:\" ) print ( \" sample type:\" , type (sample), \", \\ element type:\" , sample . dtype,\\ \", shape:\" , sample . shape) print ( \" sample min: {:.4f}, max: {:.4f}\" \\ . format(np . amin(sample), np . amax(sample))) print ( \" sampling time: {:.2f} secs\" . format(sampling_time)) # Plotting the distribution. plt . hist(sample . ravel(), bins = min ( int (np . ceil(np . sqrt(sample . size))), 100 ), density = True , facecolor = 'b' , alpha = 0.75 ) plt . xlabel( \"value\" , size = 12 ) plt . ylabel( \"probability\" , size = 12 ) plt . title( \"Uniform distribution over float64 numbers in \\ [{:.2f} ... {:.2f}]\" . format( np . amin(sample), np . amax(sample)), size = 12 ) plt . grid( True ) # plt.savefig(\"uniform_distrib_float.png\", bbox_inches=\"tight\") plt . show() Uniform distribution over floating point numbers: sample type: &lt;class 'numpy.ndarray'&gt; , element type: float64 , shape: (54321,) sample min: -7.6687, max: 19.5191 sampling time: 6.41 secs","title":"Uniform distribution over floating point numbers."},{"location":"circuits/random/random/#uniform-distribution-over-integers","text":"Our next example is similar to the previous one, but here we generate a random vector of integers: # Draw a sample from uniform distribution. start_time = time . time() sample = uniform_rand_int64(circuit, glo_num_qubits,\\ size = 54321 , vmin = 37 , vmax = 841 ) sampling_time = time . time() - start_time # Print out some details. print ( \"Uniform distribution over bounded integer numbers:\" ) print ( \" sample type:\" , type (sample), \", \\ element type:\" , sample . dtype,\\ \", shape:\" , sample . shape) print ( \" sample min: {:d}, max: {:d}\" \\ . format(np . amin(sample), np . amax(sample))) print ( \" sampling time: {:.2f} secs\" \\ . format(sampling_time)) # Plotting the distribution. plt . hist(sample . ravel(), bins = min ( int (np . ceil(np . sqrt(sample . size))), 100 ), density = True , facecolor = 'g' , alpha = 0.75 ) plt . xlabel( \"value\" , size = 12 ) plt . ylabel( \"probability\" , size = 12 ) plt . title( \"Uniform distribution over int64 numbers in \\ [{:d} ... {:d}]\" . format( np . amin(sample), np . amax(sample)), size = 12 ) plt . grid( True ) # plt.savefig(\"uniform_distrib_int.png\", bbox_inches=\"tight\") plt . show() Uniform distribution over bounded integer numbers: sample type: &lt;class 'numpy.ndarray'&gt; , element type: int64 , shape: (54321,) sample min: 37, max: 841 sampling time: 7.15 secs","title":"Uniform distribution over integers."},{"location":"circuits/random/random/#normal-distribution","text":"To generate random variates with a standard normal distribution using two independent samples \\(u_1, u_2\\) of the uniform distribution on the unit interval [0, 1], one can consider the Box-Muller transform to obtain a 2-vector: \\begin{align} \\begin{bmatrix} %R\\cos(\\Theta )= {\\sqrt {-2\\ln u_{1}}}\\cos(2\\pi u_{2}) \\ % R\\sin(\\Theta )= {\\sqrt {-2\\ln u_{1}}}\\sin(2\\pi u_{2}) \\end{bmatrix}, \\end{align} wherein we have two independent samples of the standard normal distribution. In IBM Q, this is implemented as follows: def normal_rand_float64 (circuit: QuantumCircuit, num_target_qubits: int , size: int , mu: float , sigma: float ) -> np . ndarray: \"\"\" Draws a sample vector from the normal distribution given the mean and standard deviation, using the Box-Muller method. \"\"\" TINY = np . sqrt(np . finfo(np . float64) . tiny) assert isinstance (size, int ) and size > 0 rand_vec = np . zeros((size,), dtype = np . float64) # Generate array of uniformly distributed samples, factor 1.5 longer that # actually needed. n = ( 3 * size) // 2 x = np . reshape(uniform_rand_float64(circuit, num_target_qubits, 2 * n, 0.0 , 1.0 ), ( - 1 , 2 )) x1 = 0.0 # first sample in a pair c = 0 # counter for d in range (size): r2 = 2.0 while r2 >= 1.0 or r2 < TINY: # Regenerate array of uniformly distributed samples upon shortage. if c >= n: c = 0 n = max (size // 10 , 1 ) x = np . reshape(uniform_rand_float64(circuit, num_target_qubits, 2 * n, 0.0 , 1.0 ), ( - 1 , 2 )) x1 = 2.0 * x[c, 0 ] - 1.0 # first sample in a pair x2 = 2.0 * x[c, 1 ] - 1.0 # second sample in a pair r2 = x1 * x1 + x2 * x2 c += 1 f = np . sqrt(np . abs( - 2.0 * np . log(r2) / r2)) rand_vec[d] = f * x1 return (rand_vec * sigma + mu) The following example demonstrates how to draw a random vector of normally distributed variates: # Mean and standard deviation. mu = 2.4 sigma = 5.1 # Draw a sample from the normal distribution. start_time = time . time() sample = normal_rand_float64(circuit, glo_num_qubits,\\ size = 4321 , mu = mu, sigma = sigma) sampling_time = time . time() - start_time # Print out some details. print ( \"Normal distribution (mu={:.3f}, sigma={:.3f}):\" \\ . format(mu, sigma)) print ( \" sample type:\" , type (sample), \", element type:\" ,\\ sample . dtype, \", shape:\" , sample . shape) print ( \" sample min: {:.4f}, max: {:.4f}\" \\ . format(np . amin(sample), np . amax(sample))) print ( \" sampling time: {:.2f} secs\" . format(sampling_time)) # Plotting the distribution. x = np . linspace(mu - 4.0 * sigma, mu + 4.0 * sigma, 1000 ) analyt = np . exp( - 0.5 * ((x - mu) / sigma) ** 2 )\\ / (sigma * math . sqrt( 2.0 * math . pi)) plt . hist(sample . ravel(), bins = min ( int (np . ceil(np . sqrt(sample . size))), 100 ), density = True , facecolor = 'r' , alpha = 0.75 ) plt . plot(x, analyt, '-b' , lw = 1 ) plt . xlabel( \"value\" , size = 12 ) plt . ylabel( \"probability\" , size = 12 ) plt . title( \"Normal distribution: empirical vs analytic\" , size = 12 ) plt . grid( True ) # plt.savefig(\"normal_distrib.png\", bbox_inches=\"tight\") plt . show() Normal distribution (mu=2.400, sigma=5.100): sample type: &lt;class 'numpy.ndarray'&gt; , element type: float64 , shape: (4321,) sample min: -18.0259, max: 21.2915 sampling time: 1.85 secs There is a substantial amount of further work needed to either certify the quality of the source of random numbers (cf. NIST SP 800-90B, Recommendation for the Entropy Sources Used for Random Bit Generation) or to use random variates within quantum algorithms (cf. uncertainty_models within Qiskit Aqua).","title":"Normal distribution"},{"location":"gates/mgates/mgates/","text":"Coming Soon Under construction","title":"Multiple Qubits Gates"},{"location":"gates/mgates/mgates/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"gates/sgates/sgates/","text":"Coming Soon Under construction","title":"Single Qubit Gates"},{"location":"gates/sgates/sgates/#coming-soon","text":"Under construction","title":"Coming Soon"},{"location":"intro/qiskit/","text":"Getting Started with Qiskit Here, we provide an overview of working with Qiskit. Qiskit provides the basic building blocks necessary to program quantum computers. The fundamental unit of Qiskit is the quantum circuit . A workflow using Qiskit consists of two stages: Build and Execute . Build allows you to make different quantum circuits that represent the problem you are solving, and Execute allows you to run them on different backends. After the jobs have been run, the data is collected. There are methods for putting this data together, depending on the program. This either gives you the answer you wanted, or allows you to make a better program for the next instance. import numpy as np from qiskit import * % matplotlib inline Circuit Basics Building the circuit The basic elements needed for your first program are the QuantumCircuit, and QuantumRegister. # Create a Quantum Register with 3 qubits. q = QuantumRegister( 3 , 'q' ) # Create a Quantum Circuit acting on the q register circ = QuantumCircuit(q) Note: Naming the QuantumRegister is optional and not required. After you create the circuit with its registers, you can add gates (\"operations\") to manipulate the registers. As you proceed through the tutorials you will find more gates and circuits; below is an example of a quantum circuit that makes a three-qubit GHZ state $$|\\psi\\rangle = \\left(|000\\rangle+|111\\rangle\\right)/\\sqrt{2}.$$ To create such a state, we start with a three-qubit quantum register. By default, each qubit in the register is initialized to $|0\\rangle$. To make the GHZ state, we apply the following gates: A Hadamard gate $H$ on qubit 0, which puts it into a superposition state. A controlled-Not operation ($C_{X}$) between qubit 0 and qubit 1. * A controlled-Not operation between qubit 0 and qubit 2. On an ideal quantum computer, the state produced by running this circuit would be the GHZ state above. In Qiskit, operations can be added to the circuit one by one, as shown below. # Add a H gate on qubit 0, putting this qubit in superposition. circ . h(q[ 0 ]) # Add a CX (CNOT) gate on control qubit 0 and target qubit 1, putting # the qubits in a Bell state. circ . cx(q[ 0 ], q[ 1 ]) # Add a CX (CNOT) gate on control qubit 0 and target qubit 2, putting # the qubits in a GHZ state. circ . cx(q[ 0 ], q[ 2 ]) &lt;qiskit.extensions.standard.cx.CnotGate at 0x122bbc1d0&gt; Visualize Circuit You can visualize your circuit using Qiskit QuantumCircuit.draw() , which plots the circuit in the form found in many textbooks. circ . draw() In this circuit, the qubits are put in order, with qubit zero at the top and qubit two at the bottom. The circuit is read left to right (meaning that gates that are applied earlier in the circuit show up further to the left). Note: If you don't have matplotlib set up as your default in '~/.qiskit/settings.conf' it will use a text-based drawer over matplotlib. To set the default to matplotlib, use the following in the settings.conf [default] circuit_drawer = mpl For those that want the full LaTeX experience, you can also set the circuit_drawer = latex. Simulating circuits using Qiskit Aer Qiskit Aer is our package for simulating quantum circuits. It provides many different backends for doing a simulation. Here we use the basic Python version. Statevector backend The most common backend in Qiskit Aer is the statevector_simulator . This simulator returns the quantum state, which is a complex vector of dimensions $2^n$, where $n$ is the number of qubits (so be careful using this as it will quickly get too large to run on your machine). When representing the state of a multi-qubit system, the tensor order used in Qiskit is different than that used in most physics textbooks. Suppose there are $n$ qubits, and qubit $j$ is labeled as $Q_{j}$. Qiskit uses an ordering in which the $n^{\\mathrm{th}}$ qubit is on the left side of the tensor product, so that the basis vectors are labeled as $Q_n\\otimes \\cdots \\otimes Q_1\\otimes Q_0$. For example, if qubit zero is in state 0, qubit 1 is in state 0, and qubit 2 is in state 1, Qiskit would represent this state as $|100\\rangle$, whereas many physics textbooks would represent it as $|001\\rangle$. This difference in labeling affects the way multi-qubit operations are represented as matrices. For example, Qiskit represents a controlled-X ($C_{X}$) operation with qubit 0 being the control and qubit 1 being the target as $$C_X = \\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 0 \\\\\\end{pmatrix}.$$ To run the above circuit using the statevector simulator, first you need to import Aer and then set the backend to statevector_simulator . # Import Aer from qiskit import BasicAer # Run the quantum circuit on a statevector simulator backend backend = BasicAer . get_backend( 'statevector_simulator' ) Now that we have chosen the backend, it's time to compile and run the quantum circuit. In Qiskit we provide the execute function for this. execute returns a job object that encapsulates information about the job submitted to the backend. Tip: You can obtain the above parameters in Jupyter. Simply place the text cursor on a function and press Shift+Tab. # Create a Quantum Program for execution job = execute(circ, backend) When you run a program, a job object is made that has the following two useful methods: job.status() and job.result() , which return the status of the job and a result object, respectively. Note: Jobs run asynchronously, but when the result method is called, it switches to synchronous and waits for it to finish before moving on to another task. result = job . result() The results object contains the data and Qiskit provides the method result.get_statevector(circ) to return the state vector for the quantum circuit. outputstate = result . get_statevector(circ, decimals = 3 ) print (outputstate) [0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j] Qiskit also provides a visualization toolbox to allow you to view these results. Below, we use the visualization function to plot the real and imaginary components of the state density matrix \\rho. from qiskit.visualization import plot_state_city plot_state_city(outputstate) Unitary backend Qiskit Aer also includes a unitary_simulator that works provided all the elements in the circuit are unitary operations . This backend calculates the $2^n \\times 2^n$ matrix representing the gates in the quantum circuit. # Run the quantum circuit on a unitary simulator backend backend = BasicAer . get_backend( 'unitary_simulator' ) job = execute(circ, backend) result = job . result() # Show the results print (result . get_unitary(circ, decimals = 3 )) [[ 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j] [ 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j] [ 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j]] OpenQASM backend The simulators above are useful because they provide information about the state output by the ideal circuit and the matrix representation of the circuit. However, a real experiment terminates by measuring each qubit (usually in the computational $|0\\rangle, |1\\rangle$ basis). Without measurement, we cannot gain information about the state. Measurements cause the quantum system to collapse into classical bits. For example, suppose we make independent measurements on each qubit of the three-qubit GHZ state $$|\\psi\\rangle = |000\\rangle +|111\\rangle)/\\sqrt{2},$$ and let $xyz$ denote the bitstring that results. Recall that, under the qubit labeling used by Qiskit, $x$ would correspond to the outcome on qubit 2, $y$ to the outcome on qubit 1, and $z$ to the outcome on qubit 0. Note: This representation of the bitstring puts the most significant bit (MSB) on the left, and the least significant bit (LSB) on the right. This is the standard ordering of binary bitstrings. We order the qubits in the same way, which is why Qiskit uses a non-standard tensor product order. Recall the probability of obtaining outcome $xyz$ is given by $$\\mathrm{Pr}(xyz) = |\\langle xyz | \\psi \\rangle |^{2}$$ and as such for the GHZ state probability of obtaining 000 or 111 are both 1/2. To simulate a circuit that includes measurement, we need to add measurements to the original circuit above, and use a different Aer backend. # Create a Classical Register with 3 bits. c = ClassicalRegister( 3 , 'c' ) # Create a Quantum Circuit meas = QuantumCircuit(q, c) meas . barrier(q) # map the quantum measurement to the classical bits meas . measure(q,c) # The Qiskit circuit object supports composition using # the addition operator. qc = circ + meas #drawing the circuit qc . draw() This circuit adds a classical register, and three measurements that are used to map the outcome of qubits to the classical bits. To simulate this circuit, we use the qasm_simulator in Qiskit Aer. Each run of this circuit will yield either the bitstring 000 or 111. To build up statistics about the distribution of the bitstrings (to, e.g., estimate $\\mathrm{Pr}(000)$), we need to repeat the circuit many times. The number of times the circuit is repeated can be specified in the execute function, via the shots keyword. # Use Aer's qasm_simulator backend_sim = BasicAer . get_backend( 'qasm_simulator' ) # Execute the circuit on the qasm simulator. # We've set the number of repeats of the circuit # to be 1024, which is the default. job_sim = execute(qc, backend_sim, shots = 1024 ) # Grab the results from the job. result_sim = job_sim . result() Once you have a result object, you can access the counts via the function get_counts(circuit) . This gives you the aggregated binary outcomes of the circuit you submitted. counts = result_sim . get_counts(qc) print (counts) {'000': 506, '111': 518} Approximately 50 percent of the time, the output bitstring is 000. Qiskit also provides a function plot_histogram , which allows you to view the outcomes. from qiskit.visualization import plot_histogram plot_histogram(counts) The estimated outcome probabilities $\\mathrm{Pr}(000)$ and $\\mathrm{Pr}(111)$ are computed by taking the aggregate counts and dividing by the number of shots (times the circuit was repeated). Try changing the shots keyword in the execute function and see how the estimated probabilities change. Running circuits using the IBM Q provider To faciliate access to real quantum computing hardware, we have provided a simple API interface. To access IBM Q devices, you'll need an API token. For the public IBM Q devices, you can generate an API token here (create an account if you don't already have one). For Q Network devices, login to the q-console, click your hub, group, and project, and expand \"Get Access\" to generate your API token and access url. Our IBM Q provider lets you run your circuit on real devices or on our HPC simulator. Currently, this provider exists within Qiskit, and can be imported as shown below. For details on the provider, see The IBM Q Provider . from qiskit import IBMQ After generating your API token, call: IBMQ.save_account('MY_TOKEN') . For Q Network users, you'll also need to include your access url: IBMQ.save_account('MY_TOKEN', 'URL') This will store your IBM Q credentials in a local file. Unless your registration information has changed, you only need to do this once. You may now load your accounts by calling, IBMQ . load_accounts(hub = None ) Once your account has been loaded, you can view the list of backends available to you. print ( \"Available backends:\" ) IBMQ . backends() Available backends: [&lt;IBMQBackend('ibmqx4') from IBMQ()&gt;, &lt;IBMQBackend('ibmqx2') from IBMQ()&gt;, &lt;IBMQBackend('ibmq_16_melbourne') from IBMQ()&gt;, &lt;IBMQSimulator('ibmq_qasm_simulator') from IBMQ()&gt;] Running circuits on real devices Today's quantum information processors are small and noisy, but are advancing at a fast pace. They provide a great opportunity to explore what noisy, intermediate-scale quantum (NISQ) computers can do. The IBM Q provider uses a queue to allocate the devices to users. We now choose a device with the least busy queue that can support our program (has at least 3 qubits). from qiskit.providers.ibmq import least_busy large_enough_devices = IBMQ . backends(filters = lambda x: x . configuration() . n_qubits < 10 and not x . configuration() . simulator) backend = least_busy(large_enough_devices) print ( \"The best backend is \" + backend . name()) The best backend is ibmqx4 To run the circuit on the backend, we need to specify the number of shots and the number of credits we are willing to spend to run the circuit. Then, we execute the circuit on the backend using the execute function. from qiskit.tools.monitor import job_monitor shots = 1024 # Number of shots to run the program (experiment); maximum is 8192 shots. max_credits = 3 # Maximum number of credits to spend on executions. job_exp = execute(qc, backend = backend, shots = shots, max_credits = max_credits) job_monitor(job_exp) Job Status: job has successfully run job_exp has a .result() method that lets us get the results from running our circuit. Note: When the .result() method is called, the code block will wait until the job has finished before releasing the cell. result_exp = job_exp . result() Like before, the counts from the execution can be obtained using get_counts(qc) counts_exp = result_exp . get_counts(qc) plot_histogram([counts_exp,counts]) Simulating circuits using a HPC simulator The IBM Q provider also comes with a remote optimized simulator called ibmq_qasm_simulator . This remote simulator is capable of simulating up to 32 qubits. It can be used the same way as the remote real backends. simulator_backend = IBMQ . get_backend( 'ibmq_qasm_simulator' , hub = None ) shots = 1024 # Number of shots to run the program (experiment); maximum is 8192 shots. max_credits = 3 # Maximum number of credits to spend on executions. job_hpc = execute(qc, backend = simulator_backend, shots = shots, max_credits = max_credits) result_hpc = job_hpc . result() counts_hpc = result_hpc . get_counts(qc) plot_histogram(counts_hpc) Retrieving a previously run job If your experiment takes longer to run then you have time to wait around, or if you simply want to retrieve old jobs, the IBM Q backends allow you to do that. First you would need to note your job's ID: jobID = job_exp . job_id() print ( 'JOB ID: {}' . format(jobID)) JOB ID: 5ccf7d36557a5600718c5793 Given a job ID, that job object can be later reconstructed from the backend using retrieve_job: job_get = backend . retrieve_job(jobID) and then the results can be obtained from the new job object. job_get . result() . get_counts(qc) {'000': 445, '001': 13, '010': 23, '111': 340, '110': 70, '100': 31, '101': 71, '011': 31}","title":"Qiskit"},{"location":"intro/qiskit/#getting-started-with-qiskit","text":"Here, we provide an overview of working with Qiskit. Qiskit provides the basic building blocks necessary to program quantum computers. The fundamental unit of Qiskit is the quantum circuit . A workflow using Qiskit consists of two stages: Build and Execute . Build allows you to make different quantum circuits that represent the problem you are solving, and Execute allows you to run them on different backends. After the jobs have been run, the data is collected. There are methods for putting this data together, depending on the program. This either gives you the answer you wanted, or allows you to make a better program for the next instance. import numpy as np from qiskit import * % matplotlib inline","title":"Getting Started with Qiskit"},{"location":"intro/qiskit/#circuit-basics","text":"","title":"Circuit Basics "},{"location":"intro/qiskit/#building-the-circuit","text":"The basic elements needed for your first program are the QuantumCircuit, and QuantumRegister. # Create a Quantum Register with 3 qubits. q = QuantumRegister( 3 , 'q' ) # Create a Quantum Circuit acting on the q register circ = QuantumCircuit(q) Note: Naming the QuantumRegister is optional and not required. After you create the circuit with its registers, you can add gates (\"operations\") to manipulate the registers. As you proceed through the tutorials you will find more gates and circuits; below is an example of a quantum circuit that makes a three-qubit GHZ state $$|\\psi\\rangle = \\left(|000\\rangle+|111\\rangle\\right)/\\sqrt{2}.$$ To create such a state, we start with a three-qubit quantum register. By default, each qubit in the register is initialized to $|0\\rangle$. To make the GHZ state, we apply the following gates: A Hadamard gate $H$ on qubit 0, which puts it into a superposition state. A controlled-Not operation ($C_{X}$) between qubit 0 and qubit 1. * A controlled-Not operation between qubit 0 and qubit 2. On an ideal quantum computer, the state produced by running this circuit would be the GHZ state above. In Qiskit, operations can be added to the circuit one by one, as shown below. # Add a H gate on qubit 0, putting this qubit in superposition. circ . h(q[ 0 ]) # Add a CX (CNOT) gate on control qubit 0 and target qubit 1, putting # the qubits in a Bell state. circ . cx(q[ 0 ], q[ 1 ]) # Add a CX (CNOT) gate on control qubit 0 and target qubit 2, putting # the qubits in a GHZ state. circ . cx(q[ 0 ], q[ 2 ]) &lt;qiskit.extensions.standard.cx.CnotGate at 0x122bbc1d0&gt;","title":"Building the circuit"},{"location":"intro/qiskit/#visualize-circuit","text":"You can visualize your circuit using Qiskit QuantumCircuit.draw() , which plots the circuit in the form found in many textbooks. circ . draw() In this circuit, the qubits are put in order, with qubit zero at the top and qubit two at the bottom. The circuit is read left to right (meaning that gates that are applied earlier in the circuit show up further to the left). Note: If you don't have matplotlib set up as your default in '~/.qiskit/settings.conf' it will use a text-based drawer over matplotlib. To set the default to matplotlib, use the following in the settings.conf [default] circuit_drawer = mpl For those that want the full LaTeX experience, you can also set the circuit_drawer = latex.","title":"Visualize Circuit"},{"location":"intro/qiskit/#simulating-circuits-using-qiskit-aer","text":"Qiskit Aer is our package for simulating quantum circuits. It provides many different backends for doing a simulation. Here we use the basic Python version.","title":"Simulating circuits using Qiskit Aer "},{"location":"intro/qiskit/#statevector-backend","text":"The most common backend in Qiskit Aer is the statevector_simulator . This simulator returns the quantum state, which is a complex vector of dimensions $2^n$, where $n$ is the number of qubits (so be careful using this as it will quickly get too large to run on your machine). When representing the state of a multi-qubit system, the tensor order used in Qiskit is different than that used in most physics textbooks. Suppose there are $n$ qubits, and qubit $j$ is labeled as $Q_{j}$. Qiskit uses an ordering in which the $n^{\\mathrm{th}}$ qubit is on the left side of the tensor product, so that the basis vectors are labeled as $Q_n\\otimes \\cdots \\otimes Q_1\\otimes Q_0$. For example, if qubit zero is in state 0, qubit 1 is in state 0, and qubit 2 is in state 1, Qiskit would represent this state as $|100\\rangle$, whereas many physics textbooks would represent it as $|001\\rangle$. This difference in labeling affects the way multi-qubit operations are represented as matrices. For example, Qiskit represents a controlled-X ($C_{X}$) operation with qubit 0 being the control and qubit 1 being the target as $$C_X = \\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 0 \\\\\\end{pmatrix}.$$ To run the above circuit using the statevector simulator, first you need to import Aer and then set the backend to statevector_simulator . # Import Aer from qiskit import BasicAer # Run the quantum circuit on a statevector simulator backend backend = BasicAer . get_backend( 'statevector_simulator' ) Now that we have chosen the backend, it's time to compile and run the quantum circuit. In Qiskit we provide the execute function for this. execute returns a job object that encapsulates information about the job submitted to the backend. Tip: You can obtain the above parameters in Jupyter. Simply place the text cursor on a function and press Shift+Tab. # Create a Quantum Program for execution job = execute(circ, backend) When you run a program, a job object is made that has the following two useful methods: job.status() and job.result() , which return the status of the job and a result object, respectively. Note: Jobs run asynchronously, but when the result method is called, it switches to synchronous and waits for it to finish before moving on to another task. result = job . result() The results object contains the data and Qiskit provides the method result.get_statevector(circ) to return the state vector for the quantum circuit. outputstate = result . get_statevector(circ, decimals = 3 ) print (outputstate) [0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j] Qiskit also provides a visualization toolbox to allow you to view these results. Below, we use the visualization function to plot the real and imaginary components of the state density matrix \\rho. from qiskit.visualization import plot_state_city plot_state_city(outputstate)","title":"Statevector backend"},{"location":"intro/qiskit/#unitary-backend","text":"Qiskit Aer also includes a unitary_simulator that works provided all the elements in the circuit are unitary operations . This backend calculates the $2^n \\times 2^n$ matrix representing the gates in the quantum circuit. # Run the quantum circuit on a unitary simulator backend backend = BasicAer . get_backend( 'unitary_simulator' ) job = execute(circ, backend) result = job . result() # Show the results print (result . get_unitary(circ, decimals = 3 )) [[ 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j] [ 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j] [ 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.707+0.j 0.707+0.j] [ 0.707+0.j -0.707+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j]]","title":"Unitary backend"},{"location":"intro/qiskit/#openqasm-backend","text":"The simulators above are useful because they provide information about the state output by the ideal circuit and the matrix representation of the circuit. However, a real experiment terminates by measuring each qubit (usually in the computational $|0\\rangle, |1\\rangle$ basis). Without measurement, we cannot gain information about the state. Measurements cause the quantum system to collapse into classical bits. For example, suppose we make independent measurements on each qubit of the three-qubit GHZ state $$|\\psi\\rangle = |000\\rangle +|111\\rangle)/\\sqrt{2},$$ and let $xyz$ denote the bitstring that results. Recall that, under the qubit labeling used by Qiskit, $x$ would correspond to the outcome on qubit 2, $y$ to the outcome on qubit 1, and $z$ to the outcome on qubit 0. Note: This representation of the bitstring puts the most significant bit (MSB) on the left, and the least significant bit (LSB) on the right. This is the standard ordering of binary bitstrings. We order the qubits in the same way, which is why Qiskit uses a non-standard tensor product order. Recall the probability of obtaining outcome $xyz$ is given by $$\\mathrm{Pr}(xyz) = |\\langle xyz | \\psi \\rangle |^{2}$$ and as such for the GHZ state probability of obtaining 000 or 111 are both 1/2. To simulate a circuit that includes measurement, we need to add measurements to the original circuit above, and use a different Aer backend. # Create a Classical Register with 3 bits. c = ClassicalRegister( 3 , 'c' ) # Create a Quantum Circuit meas = QuantumCircuit(q, c) meas . barrier(q) # map the quantum measurement to the classical bits meas . measure(q,c) # The Qiskit circuit object supports composition using # the addition operator. qc = circ + meas #drawing the circuit qc . draw() This circuit adds a classical register, and three measurements that are used to map the outcome of qubits to the classical bits. To simulate this circuit, we use the qasm_simulator in Qiskit Aer. Each run of this circuit will yield either the bitstring 000 or 111. To build up statistics about the distribution of the bitstrings (to, e.g., estimate $\\mathrm{Pr}(000)$), we need to repeat the circuit many times. The number of times the circuit is repeated can be specified in the execute function, via the shots keyword. # Use Aer's qasm_simulator backend_sim = BasicAer . get_backend( 'qasm_simulator' ) # Execute the circuit on the qasm simulator. # We've set the number of repeats of the circuit # to be 1024, which is the default. job_sim = execute(qc, backend_sim, shots = 1024 ) # Grab the results from the job. result_sim = job_sim . result() Once you have a result object, you can access the counts via the function get_counts(circuit) . This gives you the aggregated binary outcomes of the circuit you submitted. counts = result_sim . get_counts(qc) print (counts) {'000': 506, '111': 518} Approximately 50 percent of the time, the output bitstring is 000. Qiskit also provides a function plot_histogram , which allows you to view the outcomes. from qiskit.visualization import plot_histogram plot_histogram(counts) The estimated outcome probabilities $\\mathrm{Pr}(000)$ and $\\mathrm{Pr}(111)$ are computed by taking the aggregate counts and dividing by the number of shots (times the circuit was repeated). Try changing the shots keyword in the execute function and see how the estimated probabilities change.","title":"OpenQASM backend"},{"location":"intro/qiskit/#running-circuits-using-the-ibm-q-provider","text":"To faciliate access to real quantum computing hardware, we have provided a simple API interface. To access IBM Q devices, you'll need an API token. For the public IBM Q devices, you can generate an API token here (create an account if you don't already have one). For Q Network devices, login to the q-console, click your hub, group, and project, and expand \"Get Access\" to generate your API token and access url. Our IBM Q provider lets you run your circuit on real devices or on our HPC simulator. Currently, this provider exists within Qiskit, and can be imported as shown below. For details on the provider, see The IBM Q Provider . from qiskit import IBMQ After generating your API token, call: IBMQ.save_account('MY_TOKEN') . For Q Network users, you'll also need to include your access url: IBMQ.save_account('MY_TOKEN', 'URL') This will store your IBM Q credentials in a local file. Unless your registration information has changed, you only need to do this once. You may now load your accounts by calling, IBMQ . load_accounts(hub = None ) Once your account has been loaded, you can view the list of backends available to you. print ( \"Available backends:\" ) IBMQ . backends() Available backends: [&lt;IBMQBackend('ibmqx4') from IBMQ()&gt;, &lt;IBMQBackend('ibmqx2') from IBMQ()&gt;, &lt;IBMQBackend('ibmq_16_melbourne') from IBMQ()&gt;, &lt;IBMQSimulator('ibmq_qasm_simulator') from IBMQ()&gt;]","title":"Running circuits using the IBM Q provider "},{"location":"intro/qiskit/#running-circuits-on-real-devices","text":"Today's quantum information processors are small and noisy, but are advancing at a fast pace. They provide a great opportunity to explore what noisy, intermediate-scale quantum (NISQ) computers can do. The IBM Q provider uses a queue to allocate the devices to users. We now choose a device with the least busy queue that can support our program (has at least 3 qubits). from qiskit.providers.ibmq import least_busy large_enough_devices = IBMQ . backends(filters = lambda x: x . configuration() . n_qubits < 10 and not x . configuration() . simulator) backend = least_busy(large_enough_devices) print ( \"The best backend is \" + backend . name()) The best backend is ibmqx4 To run the circuit on the backend, we need to specify the number of shots and the number of credits we are willing to spend to run the circuit. Then, we execute the circuit on the backend using the execute function. from qiskit.tools.monitor import job_monitor shots = 1024 # Number of shots to run the program (experiment); maximum is 8192 shots. max_credits = 3 # Maximum number of credits to spend on executions. job_exp = execute(qc, backend = backend, shots = shots, max_credits = max_credits) job_monitor(job_exp) Job Status: job has successfully run job_exp has a .result() method that lets us get the results from running our circuit. Note: When the .result() method is called, the code block will wait until the job has finished before releasing the cell. result_exp = job_exp . result() Like before, the counts from the execution can be obtained using get_counts(qc) counts_exp = result_exp . get_counts(qc) plot_histogram([counts_exp,counts])","title":"Running circuits on real devices"},{"location":"intro/qiskit/#simulating-circuits-using-a-hpc-simulator","text":"The IBM Q provider also comes with a remote optimized simulator called ibmq_qasm_simulator . This remote simulator is capable of simulating up to 32 qubits. It can be used the same way as the remote real backends. simulator_backend = IBMQ . get_backend( 'ibmq_qasm_simulator' , hub = None ) shots = 1024 # Number of shots to run the program (experiment); maximum is 8192 shots. max_credits = 3 # Maximum number of credits to spend on executions. job_hpc = execute(qc, backend = simulator_backend, shots = shots, max_credits = max_credits) result_hpc = job_hpc . result() counts_hpc = result_hpc . get_counts(qc) plot_histogram(counts_hpc)","title":"Simulating circuits using a HPC simulator"},{"location":"intro/qiskit/#retrieving-a-previously-run-job","text":"If your experiment takes longer to run then you have time to wait around, or if you simply want to retrieve old jobs, the IBM Q backends allow you to do that. First you would need to note your job's ID: jobID = job_exp . job_id() print ( 'JOB ID: {}' . format(jobID)) JOB ID: 5ccf7d36557a5600718c5793 Given a job ID, that job object can be later reconstructed from the backend using retrieve_job: job_get = backend . retrieve_job(jobID) and then the results can be obtained from the new job object. job_get . result() . get_counts(qc) {'000': 445, '001': 13, '010': 23, '111': 340, '110': 70, '100': 31, '101': 71, '011': 31}","title":"Retrieving a previously run job"},{"location":"optimization/dwave/dwave/","text":"Optimization with BQM Introduction source Quantum computing has the potential to help solve some of the most complex technical, scientific, national defense, and commercial problems that organizations face. For quantum computing, as for classical, the first step in solving a problem is to express it in a mathematical formulation compatible with the underlying physical hardware. D-Wave systems solve problems that can be mapped onto an Ising model or a quadratic unconstrained binary optimization (QUBO) problem . is an objective function of N binary variables represented as an upper-diagonal matrix Q, where diagonal terms are the linear coefficients and the nonzero off-diagonal terms the quadratic coefficients. The mapped problem must be formulated to be compatible with the constraints of the physical system and as robust as possible to analog control errors. Example from constraint satisfaction problem (CSP) This example solves a map coloring problem to demonstrate an out-of-the-box use of Ocean\u2019s classical-quantum hybrid sampler, dwave-hybrid Kerberos , that enables you to solve problems of arbitrary structure and size. Map coloring is an example of a constraint satisfaction problem (CSP) . CSPs require that all a problem\u2019s variables be assigned values, out of a finite domain, that result in the satisfying of all constraints. The map-coloring CSP is to assign a color to each region of a map such that any two regions sharing a border have different colors. The Map Coloring advanced example demonstrates lower-level coding of a similar problem, which gives the user more control over the solution procedure but requires the knowledge of some system parameters (e.g., knowing the maximum number of supported variables for the problem). Example Problem With Many Variables demonstrates the hybrid approach to problem solving in more detail by explicitly configuring the classical and quantum workflows. import networkx as nx G = nx . read_adjlist( 'usa.adj' , delimiter = ',' ) Quantum Implementation Solution Steps Section Solving Problems on a D-Wave System describes the process of solving problems on the quantum computer in two steps: - (1) Formulate the problem as a binary quadratic model (BQM) and - (2) Solve the BQM with a D-wave system or classical sampler. In this example, a function in Ocean software handles both steps. Our task is mainly to select the sampler used to solve the problem. For graph G(V,E) of the map problem\u2014no two vertices, V, connected by an edge, E, should select the same color from set C\u2014construct a cost function with binary variables, $x_{v,c}=1$ when $v\u2208V$ selects color $c\u2208C$, by implementing two constraints: $$(\\sum_c x_{v,c} -1)^2$$ which has minimum energy (zero) when vertices select one color only, and $$\\sum_c \\sum_{v_a,v_b \\in E} x_{v_a,c} x_{v_b,c},$$ which adds a penalty if the vertices of an edge select the same color. $$E(x_v,x_{v_a,v_b}) = \\sum_v (\\sum_c x_{v,c} -1)^2 + \\sum_c \\sum_{v_a,v_b \\in E} x_{v_a,c} x_{v_b,c}.$$ The minima (ground states) of this QUBO have zero energy for viable solutions. This formulation of the generic problem must still be applied to the map and color set and then embedded. This section solved the map-coloring problem using a technique of formulating a problem as a constraint satisfaction problem (CSP) using penalty functions. The CSP Reformulation with Penalty Functions section describes this technique and demonstrates it in detail on a simple two-color, two-region part of this map-coloring problem in the Example of CSP reformulation with penalty functions section. import dwave_networkx as dnx from hybrid.reference.kerberos import KerberosSampler Prepare coloring scheme using D-Wave kerberoSamplers coloring = dnx . min_vertex_coloring(G, sampler = KerberosSampler(),\\ chromatic_ub = 4 ,\\ max_iter = 10 ,\\ convergence = 3 ) set (coloring . values()) {0, 1, 2, 3} import matplotlib.pyplot as plt plt . figure(figsize = [ 12 , 10 ]) node_colors = [coloring . get(node) for node in G . nodes()] # adjust the next line if using a different map if dnx . is_vertex_coloring(G, coloring): nx . draw(G, pos = nx . shell_layout(G, nlist = [ list (G . nodes)[x:x + 10 ] \\ for x in range ( 0 , 50 , 10 )] + [[ list (G . nodes)[ 50 ]]]),\\ with_labels = True , \\ node_color = node_colors,\\ node_size = 400 ,\\ cmap = plt . cm . rainbow) plt . show()","title":"Binary Quadratic Model (BQM)"},{"location":"optimization/dwave/dwave/#optimization-with-bqm","text":"","title":"Optimization with BQM"},{"location":"optimization/dwave/dwave/#introduction-source","text":"Quantum computing has the potential to help solve some of the most complex technical, scientific, national defense, and commercial problems that organizations face. For quantum computing, as for classical, the first step in solving a problem is to express it in a mathematical formulation compatible with the underlying physical hardware. D-Wave systems solve problems that can be mapped onto an Ising model or a quadratic unconstrained binary optimization (QUBO) problem . is an objective function of N binary variables represented as an upper-diagonal matrix Q, where diagonal terms are the linear coefficients and the nonzero off-diagonal terms the quadratic coefficients. The mapped problem must be formulated to be compatible with the constraints of the physical system and as robust as possible to analog control errors.","title":"Introduction source"},{"location":"optimization/dwave/dwave/#example-from-constraint-satisfaction-problem-csp","text":"This example solves a map coloring problem to demonstrate an out-of-the-box use of Ocean\u2019s classical-quantum hybrid sampler, dwave-hybrid Kerberos , that enables you to solve problems of arbitrary structure and size. Map coloring is an example of a constraint satisfaction problem (CSP) . CSPs require that all a problem\u2019s variables be assigned values, out of a finite domain, that result in the satisfying of all constraints. The map-coloring CSP is to assign a color to each region of a map such that any two regions sharing a border have different colors. The Map Coloring advanced example demonstrates lower-level coding of a similar problem, which gives the user more control over the solution procedure but requires the knowledge of some system parameters (e.g., knowing the maximum number of supported variables for the problem). Example Problem With Many Variables demonstrates the hybrid approach to problem solving in more detail by explicitly configuring the classical and quantum workflows. import networkx as nx G = nx . read_adjlist( 'usa.adj' , delimiter = ',' )","title":"Example from constraint satisfaction problem (CSP)"},{"location":"optimization/dwave/dwave/#quantum-implementation","text":"","title":"Quantum Implementation"},{"location":"optimization/dwave/dwave/#solution-steps","text":"Section Solving Problems on a D-Wave System describes the process of solving problems on the quantum computer in two steps: - (1) Formulate the problem as a binary quadratic model (BQM) and - (2) Solve the BQM with a D-wave system or classical sampler. In this example, a function in Ocean software handles both steps. Our task is mainly to select the sampler used to solve the problem. For graph G(V,E) of the map problem\u2014no two vertices, V, connected by an edge, E, should select the same color from set C\u2014construct a cost function with binary variables, $x_{v,c}=1$ when $v\u2208V$ selects color $c\u2208C$, by implementing two constraints: $$(\\sum_c x_{v,c} -1)^2$$ which has minimum energy (zero) when vertices select one color only, and $$\\sum_c \\sum_{v_a,v_b \\in E} x_{v_a,c} x_{v_b,c},$$ which adds a penalty if the vertices of an edge select the same color. $$E(x_v,x_{v_a,v_b}) = \\sum_v (\\sum_c x_{v,c} -1)^2 + \\sum_c \\sum_{v_a,v_b \\in E} x_{v_a,c} x_{v_b,c}.$$ The minima (ground states) of this QUBO have zero energy for viable solutions. This formulation of the generic problem must still be applied to the map and color set and then embedded. This section solved the map-coloring problem using a technique of formulating a problem as a constraint satisfaction problem (CSP) using penalty functions. The CSP Reformulation with Penalty Functions section describes this technique and demonstrates it in detail on a simple two-color, two-region part of this map-coloring problem in the Example of CSP reformulation with penalty functions section. import dwave_networkx as dnx from hybrid.reference.kerberos import KerberosSampler Prepare coloring scheme using D-Wave kerberoSamplers coloring = dnx . min_vertex_coloring(G, sampler = KerberosSampler(),\\ chromatic_ub = 4 ,\\ max_iter = 10 ,\\ convergence = 3 ) set (coloring . values()) {0, 1, 2, 3} import matplotlib.pyplot as plt plt . figure(figsize = [ 12 , 10 ]) node_colors = [coloring . get(node) for node in G . nodes()] # adjust the next line if using a different map if dnx . is_vertex_coloring(G, coloring): nx . draw(G, pos = nx . shell_layout(G, nlist = [ list (G . nodes)[x:x + 10 ] \\ for x in range ( 0 , 50 , 10 )] + [[ list (G . nodes)[ 50 ]]]),\\ with_labels = True , \\ node_color = node_colors,\\ node_size = 400 ,\\ cmap = plt . cm . rainbow) plt . show()","title":"Solution Steps"},{"location":"optimization/routing/routing/","text":"Qiskit Aqua: Vehicle Routing The latest version of this notebook is available here . Contributors Andrea Simonetto [1] , Jakub Marecek [1] , Martin Mevissen [1] Affiliation [1] IBMQ The Introduction Logistics is a major industry, with some estimates valuing it at USD 8183 billion globally in 2015. Most service providers operate a number of vehicles (e.g., trucks and container ships), a number of depots, where the vehicles are based overnight, and serve a number of client locations with each vehicle during each day. There are many optimisation and control problems that consider these parameters. Computationally, the key challenge is how to design routes from depots to a number of client locations and back to the depot, so as to minimise vehicle-miles travelled, time spent, or similar objective functions. In this notebook we formalise an idealised version of the problem and showcase its solution using the quantum approximate optimization approach of Farhi, Goldstone, and Gutman (2014). The overall workflow we demonstrate comprises: establish the client locations. Normally, these would be available ahead of the day of deliveries from a database. In our use case, we generate these randomly. compute the pair-wise distances, travel times, or similar. In our case, we consider the Euclidean distance, \"as the crow flies\", which is perhaps the simplest possible. compute the actual routes. This step is run twice, actually. First, we obtain a reference value by a run of a classical solver (IBM CPLEX) on the classical computer. Second, we run an alternative, hybrid algorithm partly on the quantum computer. visualisation of the results. In our case, this is again a simplistic plot. In the following, we first explain the model, before we proceed with the installation of the pre-requisites and the data loading. The Model Mathematically speaking, the vehicle routing problem (VRP) is a combinatorial problem, wherein the best routes from a depot to a number of clients and back to the depot are sought, given a number of available vehicles. There are a number of formulations possible, extending a number of formulations of the travelling salesman problem [Applegate et al, 2006]. Here, we present a formulation known as MTZ [Miller, Tucker, Zemlin, 1960]. Let \\(n\\) be the number of clients (indexed as\\(1,\\dots,n\\), and \\(K\\) be the number of available vehicles. Let\\(x_{ij} = {0,1}\\) be the binary decision variable which, if it is \\(1\\) activates the segment from node \\(i\\) to node \\(j\\) The node index runs from\\(0\\)to\\(n\\) where\\(0\\)is (by convention) the depot. There are twice as many distinct decision variables as edges. For example, in a fully connected graph, there are \\(n(n+1)\\) inary decision variables. If two nodes \\(i\\) and \\(j\\) have a link from \\(i\\) to \\(j\\) we write \\(i \\sim j\\) We also denote with \\(\\delta(i)^+\\) the set of nodes to which \\(i\\) has a link, i.e.,\\(j \\in \\delta(i)^+\\) if and only if \\(i \\sim j\\) Similarly, we denote with $\\delta(i)^-\\) the set of nodes which are connected to \\(i\\) in the sense that \\(j \\in \\delta(i)^-\\) if and only if\\(j \\sim i\\) In addition, we consider continuous variables, for all nodes \\(i = 1,\\dots, n\\) denoted\\(u_i\\) These variables are needed in the MTZ formulation of the problem to eliminate sub-tours between clients. The VRP can be formulated as: $$ (VRP) \\quad f = \\min_{{x_{ij}} {i\\sim j}\\in {0,1}, {u_i} {i=1,\\dots,n}\\in \\mathbb{R}} \\quad \\sum_{i \\sim j} w_{ij} x_{ij} $$ subject to the node-visiting constraint: $$\\sum_{j \\in \\delta(i)^+} x_{ij} = 1, \\,\\sum_{j \\in \\delta(i)^-} x_{ji} = 1,\\, \\forall i \\in {1,\\dots,n},$$ the depot-visiting constraints: $$\\sum_{i \\in \\delta(0)^+} x_{0i} = K, \\, \\sum_{j \\in \\delta(0)^+} x_{j0} = K,$$ and the sub-tour elimination constraints: $$ u_i - u_j + Q x_{ij} \\leq Q-q_j, \\, \\forall i \\sim j, \\,i ,j \\neq 0, \\quad q_i \\leq u_i \\leq Q,\\, \\forall i, i \\neq 0. $$ In particular, The cost function is linear in the cost functions and weighs the different arches based on a positive weight\\(w_{ij}>0\\)(typically the distance between node\\(i\\)and node\\(j\\); The first set of constraints enforce that from and to every client, only one link is allowed; The second set of constraints enforce that from and to the depot, exactly \\(K\\)links are allowed; The third set of constraints enforce the sub-tour elimination constraints and are bounds on\\(u_i\\) with\\(Q>q_j>0\\) and\\(Q,q_i \\in \\mathbb{R}\\) Classical solution We can solve the VRP classically, e.g., by using CPLEX. CPLEX uses a branch-and-bound-and-cut method to find an approximate solution of the VRP, which, in this formulation, is a mixed-integer linear program (MILP). For the sake of notation, we pack the decision variables in one vector as $$ {\\bf z} = [x_{01},x_{02},\\ldots,x_{10}, x_{12},\\ldots,x_{n(n-1)}]^T, $$ wherein \\({\\bf z} \\in {0,1}^N\\) with\\(N = n (n+1)\\) So the dimension of the problem scales quadratically with the number of nodes. Let us denote the optimal solution by \\(z^{*}\\) and the associated optimal cost \\(f^{*}\\) Quantum solution Here, we demonstrate an approach that combines classical and quantum computing steps, following the quantum approximate optimization approach of Farhi, Goldstone, and Gutman (2014). In particular, we use the variational quantum eigensolver (VQE). We stress that given the use of limited depth of the quantum circuits employed (variational forms), it is hard to discuss the speed-up of the algorithm, as the solution obtained is heuristic in nature. At the same time, due to the nature and importance of the target problems, it is worth investigating heuristic approaches, which may be worthwhile for some problem classes. Following [5], the algorithm can be summarised as follows: Preparation steps: Transform the combinatorial problem into a binary polynomial optimization problem with equality constraints only; Map the resulting problem into an Ising Hamiltonian ($H$) for variables\\({\\bf z}\\)and basis\\(Z\\) via penalty methods if necessary; Choose the depth of the quantum circuit\\(m\\) Note that the depth can be modified adaptively. Choose a set of controls\\(\\theta\\)and make a trial function\\(\\big|\\psi(\\boldsymbol\\theta)\\rangle\\) built using a quantum circuit made of C-Phase gates and single-qubit Y rotations, parameterized by the components of\\(\\boldsymbol\\theta\\) Algorithm steps: Evaluate\\(C(\\boldsymbol\\theta) = \\langle\\psi(\\boldsymbol\\theta)\\big|H\\big|\\psi(\\boldsymbol\\theta)\\rangle\\)by sampling the outcome of the circuit in the Z-basis and adding the expectation values of the individual Ising terms together. In general, different control points around\\(\\boldsymbol\\theta\\)have to be estimated, depending on the classical optimizer chosen. Use a classical optimizer to choose a new set of controls. Continue until\\(C(\\boldsymbol\\theta)\\)reaches a minimum, close enough to the solution\\(\\boldsymbol\\theta^*\\) Use the last\\(\\boldsymbol\\theta\\)to generate a final set of samples from the distribution\\(\\Big|\\langle z_i\\big|\\psi(\\boldsymbol\\theta)\\rangle\\Big|^2\\;\\forall i\\)to obtain the answer. There are many parameters throughout, notably the choice of the trial wavefunction. Below, we consider: $$ \\big|\\psi(\\theta)\\rangle = [U_\\mathrm{single}(\\boldsymbol\\theta) U_\\mathrm{entangler}]^m \\big|+\\rangle $$ where\\(U_\\mathrm{entangler}\\)is a collection of C-Phase gates (fully-entangling gates), and\\(U_\\mathrm{single}(\\theta) = \\prod_{i=1}^N Y(\\theta_{i})\\) where\\(N\\)is the number of qubits and\\(m\\)is the depth of the quantum circuit. Construct the Ising Hamiltonian From\\(VRP\\)one can construct a binary polynomial optimization with equality constraints only by considering cases in which\\(K=n-1\\) In these cases the sub-tour elimination constraints are not necessary and the problem is only on the variable\\({\\bf z}\\) In particular, we can write an augmented Lagrangian as $$ (IH) \\quad H = \\sum_{i \\sim j} w_{ij} x_{ij} + A \\sum_{i \\in {1,\\dots,n}} \\Big(\\sum_{j \\in \\delta(i)^+} x_{ij} - 1\\Big)^2 $$ $$ + A \\sum_{i \\in {1,\\dots,n}}\\Big(\\sum_{j \\in \\delta(i)^-} x_{ji} - 1\\Big)^2 +A \\Big(\\sum_{i \\in \\delta(0)^+} x_{0i} - K\\Big)^2 + A\\Big(\\sum_{j \\in \\delta(0)^+} x_{j0} - K\\Big)^2 $$ where \\(A\\) is a big enough parameter. From Hamiltonian to QP formulation In the vector\\({\\bf z}\\) and for a complete graph (\\(\\delta(i)^+ = \\delta(i)^- = {0,1,\\dots,i-1,i+1,\\dots,n}\\), \\(H\\) can be written as follows. $$ \\min_{{\\bf z}\\in {0,1}^{n(n+1)}} {\\bf w}^T {\\bf z} + A \\sum_{i \\in {1,\\dots,n}} \\Big({\\bf e} i \\otimes {\\bf 1}_n^T {\\bf z} - 1\\Big)^2 + A \\sum {i \\in {1,\\dots,n}}\\Big({\\bf v}_i^T {\\bf z} - 1\\Big)^2 + A \\Big(({\\bf e}_0 \\otimes {\\bf 1}_n)^T{\\bf z} - K\\Big)^2 + A\\Big({\\bf v}_0^T{\\bf z} - K\\Big)^2. $$ That is: $$ \\min_{\\bf z\\in {0,1}^{n(n+1)}} \\bf z^T {\\bf Q} \\bf z + {\\bf g}^T \\bf z + c, $$ Where: first term: $$ {\\bf Q} = A \\sum_{i \\in {0,1,\\dots,n}} \\Big[({\\bf e}_i \\otimes {\\bf 1}_n)({\\bf e}_i \\otimes {\\bf 1}_n)^T + {\\bf v}_i{\\bf v}_i^T \\Big] $$ Second term: $$ {\\bf g} = {\\bf w} -2 A \\sum_{i \\in {1,\\dots,n}} \\Big[({\\bf e}_i \\otimes {\\bf 1}_n) + {\\bf v}_i \\Big] -2 A K \\Big[({\\bf e}_0 \\otimes {\\bf 1}_n) + {\\bf v}_0 \\Big] $$ Third term: $$ c = 2An +2AK^2. $$ The QP formulation of the Ising Hamiltonian is ready for the use of VQE. References [1] E. Farhi, J. Goldstone, S. Gutmann e-print arXiv 1411.4028, 2014 [2] https://github.com/Qiskit/qiskit-tutorial/blob/master/qiskit/aqua/optimization/maxcut_and_tsp.ipynb [3] C. E. Miller, E. W. Tucker, and R. A. Zemlin (1960). \"Integer Programming Formulations and Travelling Salesman Problems\". J. ACM. 7: 326\u2013329. doi:10.1145/321043.321046. [4] D. L. Applegate, R. M. Bixby, V. Chv\u00e1tal, and W. J. Cook (2006). The Traveling Salesman Problem. Princeton University Press, ISBN 978-0-691-12993-8. Initialization First of all we load all the packages that we need: - Python 3.6 or greater is required; - CPLEX 12.8 or greater is required for the classical computations; - Latest Qiskit is required for the quantum computations. # Load the packages that are required import numpy as np import operator import matplotlib.pyplot as plt import sys if sys . version_info < ( 3 , 6 ): raise Exception ( 'Please use Python version 3.6 or greater.' ) try : import cplex from cplex.exceptions import CplexError except : print ( \"Warning: Cplex not found.\" ) import math # Qiskit packages from qiskit.quantum_info import Pauli from qiskit.aqua.input import EnergyInput from qiskit.aqua import Operator, run_algorithm # setup aqua logging import logging from qiskit.aqua._logging import set_logging_config, build_logging_config # set_logging_config(build_logging_config(logging.DEBUG)) # choose INFO, DEBUG to see the log Warning: Cplex not found. We then initialize the variables # Initialize the problem by defining the parameters n = 3 # number of nodes + depot (n+1) K = 2 # number of vehicles We define an initializer class that randomly places the nodes in a 2-D plane and computes the distance between them. # Get the data class Initializer (): def __init__ ( self , n): self . n = n def generate_instance ( self ): n = self . n # np.random.seed(33) np . random . seed( 1543 ) xc = (np . random . rand(n) - 0.5 ) * 10 yc = (np . random . rand(n) - 0.5 ) * 10 instance = np . zeros([n, n]) for ii in range ( 0 , n): for jj in range (ii + 1 , n): instance[ii, jj] = (xc[ii] - xc[jj]) ** 2 + (yc[ii] - yc[jj]) ** 2 instance[jj, ii] = instance[ii, jj] return xc, yc, instance # Initialize the problem by randomly generating the instance initializer = Initializer(n) xc,yc,instance = initializer . generate_instance() Classical solution using IBM ILOG CPLEX For a classical solution, we use IBM ILOG CPLEX. CPLEX is able to find the exact solution of this problem. We first define a ClassicalOptimizer class that encodes the problem in a way that CPLEX can solve, and then instantiate the class and solve it. class ClassicalOptimizer : def __init__ ( self , instance,n,K): self . instance = instance self . n = n # number of nodes self . K = K # number of vehicles def compute_allowed_combinations ( self ): f = math . factorial return f( self . n) / f( self . K) / f( self . n - self . K) def cplex_solution ( self ): # refactoring instance = self . instance n = self . n K = self . K my_obj = list (instance . reshape( 1 , n ** 2 )[ 0 ]) + \\ [ 0. for x in range ( 0 ,n - 1 )] my_ub = [ 1 for x in range ( 0 ,n ** 2 + n - 1 )] my_lb = [ 0 for x in range ( 0 ,n ** 2 )] \\ + [ 0.1 for x in range ( 0 ,n - 1 )] my_ctype = \"\" . join([ 'I' for x in range ( 0 ,n ** 2 )]) \\ + \"\" . join([ 'C' for x in range ( 0 ,n - 1 )]) my_rhs = 2 * ([K] + [ 1 for x in range ( 0 ,n - 1 )]) \\ + [ 1 - 0.1 for x in range ( 0 ,(n - 1 ) ** 2 - (n - 1 ))] \\ + [ 0 for x in range ( 0 ,n)] my_sense = \"\" . join([ 'E' for x in range ( 0 , 2 * n)]) \\ + \"\" . join([ 'L' for x in range ( 0 ,(n - 1 ) ** 2 - (n - 1 ))]) + \\ \"\" . join([ 'E' for x in range ( 0 ,n)]) try : my_prob = cplex . Cplex() self . populatebyrow(my_prob,my_obj,my_ub,my_lb,\\ my_ctype,my_sense,my_rhs) my_prob . solve() except CplexError as exc: print (exc) return x = my_prob . solution . get_values() x = np . array(x) cost = my_prob . solution . get_objective_value() return x,cost def populatebyrow ( self ,prob,my_obj,my_ub,my_lb,\\ my_ctype,my_sense,my_rhs): n = self . n prob . objective . set_sense(prob . objective . sense . minimize) prob . variables . add(obj = my_obj, lb = my_lb, \\ ub = my_ub, types = my_ctype) prob . set_log_stream( None ) prob . set_error_stream( None ) prob . set_warning_stream( None ) prob . set_results_stream( None ) rows = [] for ii in range ( 0 ,n): col = [x for x in range ( 0 + n * ii,n + n * ii)] coef = [ 1 for x in range ( 0 ,n)] rows . append([col, coef]) for ii in range ( 0 ,n): col = [x for x in range ( 0 + ii,n ** 2 ,n)] coef = [ 1 for x in range ( 0 ,n)] rows . append([col, coef]) # Sub-tour elimination constraints: for ii in range ( 0 , n): for jj in range ( 0 ,n): if (ii != jj) and (ii * jj > 0 ): col = [ii + (jj * n), n ** 2 + ii - 1 , n ** 2 + jj - 1 ] coef = [ 1 , 1 , - 1 ] rows . append([col, coef]) for ii in range ( 0 ,n): col = [(ii) * (n + 1 )] coef = [ 1 ] rows . append([col, coef]) prob . linear_constraints . add(lin_expr = rows,\\ senses = my_sense, rhs = my_rhs) # Instantiate the classical optimizer class classical_optimizer = ClassicalOptimizer(instance,n,K) # Print number of feasible solutions print ( 'Number of feasible solutions = ' \\ + str (classical_optimizer . compute_allowed_combinations())) Number of feasible solutions = 3.0 # Solve the problem in a classical fashion via CPLEX x = None z = None try : x,classical_cost = classical_optimizer . cplex_solution() # Put the solution in the z variable z = [x[ii] for ii in range (n ** 2 ) if ii // n != ii % n] # Print the solution print (z) except : print ( \"CPLEX may be missing.\" ) CPLEX may be missing. # Visualize the solution def visualize_solution (xc, yc, x, C, n, K, title_str): plt . figure() plt . scatter(xc, yc, s = 200 ) for i in range ( len (xc)): plt . annotate(i, (xc[i] + 0.15 , yc[i]), size = 16 , color = 'r' ) plt . plot(xc[ 0 ], yc[ 0 ], 'r*' , ms = 20 ) plt . grid() for ii in range ( 0 , n ** 2 ): if x[ii] > 0 : ix = ii // n iy = ii % n plt . arrow(xc[ix], yc[ix], xc[iy] - xc[ix], yc[iy] \\ - yc[ix], length_includes_head = True , head_width =. 25 ) plt . title(title_str + ' cost = ' + str ( int (C * 100 ) / 100. )) plt . show() if x: visualize_solution(xc, yc, x, classical_cost, n, K, 'Classical' ) If you have CPLEX, the solution shows the depot with a star and the selected routes for the vehicles with arrows. Quantum solution from the ground up For the quantum solution, we use Qiskit. First, we derive the solution from the ground up, using a class QuantumOptimizer that encodes the quantum approach to solve the problem and then we instantiate it and solve it. We define the following methods inside the class: - binary_representation : encodes the problem\\((M)\\)into a the Ising Hamiltonian QP (that's basically linear algebra); - construct_hamiltonian : constructs the Ising Hamiltonian in terms of the\\(Z\\)basis; - check_hamiltonian : makes sure that the Ising Hamiltonian is correctly encoded in the\\(Z\\)basis: to do this, it solves a eigenvalue-eigenvector problem for a symmetric matrix of dimension\\(2^N \\times 2^N\\) For the problem at hand\\(n=3\\) that is\\(N = 12\\)seems the limit; - vqe_solution : solves the problem\\((M)\\)via VQE by using the SPSA solver (with default parameters); - _q_solution : internal routine to represent the solution in a usable format. class QuantumOptimizer : def __init__ ( self , instance, n, K, max_trials = 1000 ): self . instance = instance self . n = n self . K = K self . max_trials = max_trials def binary_representation ( self ,x_sol = 0 ): instance = self . instance n = self . n K = self . K A = np . max(instance) * 100 # A parameter of cost function # Determine the weights w instance_vec = instance . reshape(n ** 2 ) w_list = [instance_vec[x] for x in range (n ** 2 ) \\ if instance_vec[x] > 0 ] w = np . zeros(n * (n - 1 )) for ii in range ( len (w_list)): w[ii] = w_list[ii] # Some variables I will use Id_n = np . eye(n) Im_n_1 = np . ones([n - 1 , n - 1 ]) Iv_n_1 = np . ones(n) Iv_n_1[ 0 ] = 0 Iv_n = np . ones(n - 1 ) neg_Iv_n_1 = np . ones(n) - Iv_n_1 v = np . zeros([n, n * (n - 1 )]) for ii in range (n): count = ii - 1 for jj in range (n * (n - 1 )): if jj // (n - 1 ) == ii: count = ii if jj // (n - 1 ) != ii and jj % (n - 1 ) == count: v[ii][jj] = 1. vn = np . sum(v[ 1 :], axis = 0 ) # Q defines the interactions between variables Q = A * (np . kron(Id_n, Im_n_1) + np . dot(v . T, v)) # g defines the contribution from the individual variables g = w - 2 * A * (np . kron(Iv_n_1,Iv_n) + vn . T) - \\ 2 * A * K * (np . kron(neg_Iv_n_1, Iv_n) + v[ 0 ] . T) # c is the constant offset c = 2 * A * (n - 1 ) + 2 * A * (K ** 2 ) try : max (x_sol) # Evaluates the cost distance from # a binary representation of a path fun = lambda x: np . dot(np . around(x), np . dot(Q, np . around(x))) + \\ np . dot(g, np . around(x)) + c cost = fun(x_sol) except : cost = 0 return Q,g,c,cost def construct_hamiltonian ( self ): instance = self . instance n = self . n K = self . K N = (n - 1 ) * n # number of qubits Q,g,c,_ = self . binary_representation() # Defining the new matrices in the Z-basis Iv = np . ones(N) Qz = (Q / 4 ) gz = ( - g / 2 - np . dot(Iv, Q / 4 ) - np . dot(Q / 4 , Iv)) cz = (c + np . dot(g / 2 , Iv) + np . dot(Iv, np . dot(Q / 4 , Iv))) cz = cz + np . trace(Qz) Qz = Qz - np . diag(np . diag(Qz)) # Getting the Hamiltonian in the form of a list of Pauli terms pauli_list = [] for i in range (N): if gz[i] != 0 : wp = np . zeros(N) vp = np . zeros(N) vp[i] = 1 pauli_list . append((gz[i], Pauli(vp, wp))) for i in range (N): for j in range (i): if Qz[i, j] != 0 : wp = np . zeros(N) vp = np . zeros(N) vp[i] = 1 vp[j] = 1 pauli_list . append(( 2 * Qz[i, j], Pauli(vp, wp))) pauli_list . append((cz, Pauli(np . zeros(N), np . zeros(N)))) return cz, pauli_list def check_hamiltonian ( self ): cz, op = self . construct_hamiltonian() Op = Operator(paulis = op) qubitOp, offset = Op, 0 algo_input = EnergyInput(qubitOp) # Making the Hamiltonian in its full form and # getting the lowest eigenvalue and eigenvector algorithm_cfg = { 'name' : 'ExactEigensolver' , } params = { 'problem' : { 'name' : 'ising' }, 'algorithm' : algorithm_cfg } result = run_algorithm(params, algo_input) quantum_solution = self . _q_solution(result[ 'eigvecs' ][ 0 ],\\ self . n * ( self . n + 1 )) ground_level = result[ 'energy' ] + offset return quantum_solution, ground_level def vqe_solution ( self ): cz, op = self . construct_hamiltonian() Op = Operator(paulis = op) qubitOp, offset = Op, cz algo_input = EnergyInput(qubitOp) algorithm_cfg = { 'name' : 'VQE' , 'operator_mode' : 'paulis' } optimizer_cfg = { 'name' : 'SPSA' , 'max_trials' : self . max_trials } var_form_cfg = { 'name' : 'RY' , 'depth' : 5 , 'entanglement' : 'linear' } params = { 'problem' : { 'name' : 'ising' , 'random_seed' : 10598 }, 'algorithm' : algorithm_cfg, 'optimizer' : optimizer_cfg, 'variational_form' : var_form_cfg, 'backend' : { 'name' : 'qasm_simulator' } } result = run_algorithm(params, algo_input) #quantum_solution = self._q_solution(result['eigvecs'][0],\\ # self.n * (self.n + 1)) quantum_solution_dict = result[ 'eigvecs' ][ 0 ] q_s = max (quantum_solution_dict . items(), key = operator . itemgetter( 1 ))[ 0 ] quantum_solution = [ int (chars) for chars in q_s] quantum_solution = np . flip(quantum_solution, axis = 0 ) _,_,_,level = self . binary_representation(x_sol = quantum_solution) return quantum_solution_dict, quantum_solution, level def _q_solution ( self , v, N): index_value = [x for x in range ( len (v)) if v[x] == max (v)][ 0 ] string_value = \"{0:b}\" . format(index_value) while len (string_value) < N: string_value = '0' + string_value sol = list () for elements in string_value: if elements == '0' : sol . append( 0 ) else : sol . append( 1 ) sol = np . flip(sol, axis = 0 ) return sol Step 1 Instantiate the quantum optimizer class with parameters: - the instance; - the number of nodes and vehicles n and K ; - the number of iterations for SPSA in VQE (default 1000) # Instantiate the quantum optimizer class with parameters: quantum_optimizer = QuantumOptimizer(instance,n,K, 100 ) Step 2 Encode the problem as a binary formulation (IH-QP). Sanity check: make sure that the binary formulation in the quantum optimizer is correct (i.e., yields the same cost given the same solution). # Check if the binary representation is correct try : if z: Q,g,c,binary_cost = quantum_optimizer . binary_representation(x_sol = z) print (binary_cost,classical_cost) if np . abs(binary_cost - classical_cost) < 0.01 : print ( 'Binary formulation is correct' ) else : print ( 'Error in the binary formulation' ) else : print ( 'Could not verify the correctness, due to CPLEX solution being unavailable.' ) Q,g,c,binary_cost = quantum_optimizer . binary_representation() except NameError as e: print ( \"Warning: Please run the cells above first.\" ) print (e) Could not verify the correctness, due to CPLEX solution being unavailable. Step 3 Encode the problem as an Ising Hamiltonian in the Z basis. Sanity check: make sure that the formulation is correct (i.e., yields the same cost given the same solution) ground_state, ground_level = quantum_optimizer . check_hamiltonian() print (ground_state) if z: if np . abs(ground_level - classical_cost) < 0.01 : print ( 'Ising Hamiltonian in Z basis is correct' ) else : print ( 'Error in the Ising Hamiltonian formulation' ) [1 1 1 0 1 0 0 0 0 0 0 0] Step 4 Solve the problem via VQE. N.B. Depending on the number of qubits, the state-vector simulation can can take a while; for example with 12 qubits, it takes more than 12 hours. Logging useful to see what the program is doing. quantum_dictionary, quantum_solution, quantum_cost = quantum_optimizer . vqe_solution() print (quantum_solution, quantum_cost) [1 1 1 0 1 0] 132.11148115684045 Step 5 Visualize the solution # Put the solution in a way that is compatible with the classical variables x_quantum = np . zeros(n ** 2 ) kk = 0 for ii in range (n ** 2 ): if ii // n != ii % n: x_quantum[ii] = quantum_solution[kk] kk += 1 # visualize the solution visualize_solution(xc, yc, x_quantum, quantum_cost, n, K, 'Quantum' ) # and visualize the classical for comparison if x: visualize_solution(xc, yc, x, classical_cost, n, K, 'Classical' ) The plots present the depot with a star and the selected routes for the vehicles with arrows. Note that in this particular case, we can find the optimal solution of the QP formulation, which happens to coincide with the optimal solution of the ILP. Keep in mind that VQE is an heuristic working on the QP formulation of the Ising Hamiltonian, though. For suitable choices of A, local optima of the QP formulation will be feasible solutions to the ILP. While for some small instances, as above, we can find optimal solutions of the QP formulation which coincide with optima of the ILP, finding optimal solutions of the ILP is harder than finding local optima of the QP formulation, in general, which in turn is harder than finding feasible solutions of the ILP. Even within the VQE, one may provide stronger guarantees, for specific variational forms (trial wave functions). Last but not least, you may be pleased to learn that the above has been packaged in Qiskit Aqua. from qiskit import BasicAer from qiskit.aqua import QuantumInstance from qiskit.aqua import Operator, run_algorithm from qiskit.aqua.input import EnergyInput from qiskit.aqua.algorithms import VQE, QAOA, ExactEigensolver from qiskit.aqua.components.optimizers import COBYLA from qiskit.aqua.components.variational_forms import RY from qiskit.aqua.translators.ising.vehicle_routing import * qubitOp = get_vehiclerouting_qubitops(instance, n, K) backend = BasicAer . get_backend( 'statevector_simulator' ) seed = 50 cobyla = COBYLA() cobyla . set_options(maxiter = 250 ) ry = RY(qubitOp . num_qubits, depth = 3 , entanglement = 'full' ) vqe = VQE(qubitOp, ry, cobyla, 'matrix' ) vqe . random_seed = seed quantum_instance = QuantumInstance(backend = backend,\\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) # print(result) x_quantum2 = get_vehiclerouting_solution(instance, n, K, result) print (x_quantum2) quantum_cost2 = get_vehiclerouting_cost(instance, n, K, x_quantum2) print (quantum_cost2) [1 1 1 0 0 1] 12434.909288240102","title":"Vahicle Routing"},{"location":"optimization/routing/routing/#qiskit-aqua-vehicle-routing","text":"The latest version of this notebook is available here .","title":"Qiskit Aqua: Vehicle Routing"},{"location":"optimization/routing/routing/#contributors","text":"Andrea Simonetto [1] , Jakub Marecek [1] , Martin Mevissen [1]","title":"Contributors"},{"location":"optimization/routing/routing/#affiliation","text":"[1] IBMQ","title":"Affiliation"},{"location":"optimization/routing/routing/#the-introduction","text":"Logistics is a major industry, with some estimates valuing it at USD 8183 billion globally in 2015. Most service providers operate a number of vehicles (e.g., trucks and container ships), a number of depots, where the vehicles are based overnight, and serve a number of client locations with each vehicle during each day. There are many optimisation and control problems that consider these parameters. Computationally, the key challenge is how to design routes from depots to a number of client locations and back to the depot, so as to minimise vehicle-miles travelled, time spent, or similar objective functions. In this notebook we formalise an idealised version of the problem and showcase its solution using the quantum approximate optimization approach of Farhi, Goldstone, and Gutman (2014). The overall workflow we demonstrate comprises: establish the client locations. Normally, these would be available ahead of the day of deliveries from a database. In our use case, we generate these randomly. compute the pair-wise distances, travel times, or similar. In our case, we consider the Euclidean distance, \"as the crow flies\", which is perhaps the simplest possible. compute the actual routes. This step is run twice, actually. First, we obtain a reference value by a run of a classical solver (IBM CPLEX) on the classical computer. Second, we run an alternative, hybrid algorithm partly on the quantum computer. visualisation of the results. In our case, this is again a simplistic plot. In the following, we first explain the model, before we proceed with the installation of the pre-requisites and the data loading.","title":"The Introduction"},{"location":"optimization/routing/routing/#the-model","text":"Mathematically speaking, the vehicle routing problem (VRP) is a combinatorial problem, wherein the best routes from a depot to a number of clients and back to the depot are sought, given a number of available vehicles. There are a number of formulations possible, extending a number of formulations of the travelling salesman problem [Applegate et al, 2006]. Here, we present a formulation known as MTZ [Miller, Tucker, Zemlin, 1960]. Let \\(n\\) be the number of clients (indexed as\\(1,\\dots,n\\), and \\(K\\) be the number of available vehicles. Let\\(x_{ij} = {0,1}\\) be the binary decision variable which, if it is \\(1\\) activates the segment from node \\(i\\) to node \\(j\\) The node index runs from\\(0\\)to\\(n\\) where\\(0\\)is (by convention) the depot. There are twice as many distinct decision variables as edges. For example, in a fully connected graph, there are \\(n(n+1)\\) inary decision variables. If two nodes \\(i\\) and \\(j\\) have a link from \\(i\\) to \\(j\\) we write \\(i \\sim j\\) We also denote with \\(\\delta(i)^+\\) the set of nodes to which \\(i\\) has a link, i.e.,\\(j \\in \\delta(i)^+\\) if and only if \\(i \\sim j\\) Similarly, we denote with $\\delta(i)^-\\) the set of nodes which are connected to \\(i\\) in the sense that \\(j \\in \\delta(i)^-\\) if and only if\\(j \\sim i\\) In addition, we consider continuous variables, for all nodes \\(i = 1,\\dots, n\\) denoted\\(u_i\\) These variables are needed in the MTZ formulation of the problem to eliminate sub-tours between clients. The VRP can be formulated as: $$ (VRP) \\quad f = \\min_{{x_{ij}} {i\\sim j}\\in {0,1}, {u_i} {i=1,\\dots,n}\\in \\mathbb{R}} \\quad \\sum_{i \\sim j} w_{ij} x_{ij} $$ subject to the node-visiting constraint: $$\\sum_{j \\in \\delta(i)^+} x_{ij} = 1, \\,\\sum_{j \\in \\delta(i)^-} x_{ji} = 1,\\, \\forall i \\in {1,\\dots,n},$$ the depot-visiting constraints: $$\\sum_{i \\in \\delta(0)^+} x_{0i} = K, \\, \\sum_{j \\in \\delta(0)^+} x_{j0} = K,$$ and the sub-tour elimination constraints: $$ u_i - u_j + Q x_{ij} \\leq Q-q_j, \\, \\forall i \\sim j, \\,i ,j \\neq 0, \\quad q_i \\leq u_i \\leq Q,\\, \\forall i, i \\neq 0. $$ In particular, The cost function is linear in the cost functions and weighs the different arches based on a positive weight\\(w_{ij}>0\\)(typically the distance between node\\(i\\)and node\\(j\\); The first set of constraints enforce that from and to every client, only one link is allowed; The second set of constraints enforce that from and to the depot, exactly \\(K\\)links are allowed; The third set of constraints enforce the sub-tour elimination constraints and are bounds on\\(u_i\\) with\\(Q>q_j>0\\) and\\(Q,q_i \\in \\mathbb{R}\\)","title":"The Model"},{"location":"optimization/routing/routing/#classical-solution","text":"We can solve the VRP classically, e.g., by using CPLEX. CPLEX uses a branch-and-bound-and-cut method to find an approximate solution of the VRP, which, in this formulation, is a mixed-integer linear program (MILP). For the sake of notation, we pack the decision variables in one vector as $$ {\\bf z} = [x_{01},x_{02},\\ldots,x_{10}, x_{12},\\ldots,x_{n(n-1)}]^T, $$ wherein \\({\\bf z} \\in {0,1}^N\\) with\\(N = n (n+1)\\) So the dimension of the problem scales quadratically with the number of nodes. Let us denote the optimal solution by \\(z^{*}\\) and the associated optimal cost \\(f^{*}\\)","title":"Classical solution"},{"location":"optimization/routing/routing/#quantum-solution","text":"Here, we demonstrate an approach that combines classical and quantum computing steps, following the quantum approximate optimization approach of Farhi, Goldstone, and Gutman (2014). In particular, we use the variational quantum eigensolver (VQE). We stress that given the use of limited depth of the quantum circuits employed (variational forms), it is hard to discuss the speed-up of the algorithm, as the solution obtained is heuristic in nature. At the same time, due to the nature and importance of the target problems, it is worth investigating heuristic approaches, which may be worthwhile for some problem classes. Following [5], the algorithm can be summarised as follows: Preparation steps: Transform the combinatorial problem into a binary polynomial optimization problem with equality constraints only; Map the resulting problem into an Ising Hamiltonian ($H$) for variables\\({\\bf z}\\)and basis\\(Z\\) via penalty methods if necessary; Choose the depth of the quantum circuit\\(m\\) Note that the depth can be modified adaptively. Choose a set of controls\\(\\theta\\)and make a trial function\\(\\big|\\psi(\\boldsymbol\\theta)\\rangle\\) built using a quantum circuit made of C-Phase gates and single-qubit Y rotations, parameterized by the components of\\(\\boldsymbol\\theta\\) Algorithm steps: Evaluate\\(C(\\boldsymbol\\theta) = \\langle\\psi(\\boldsymbol\\theta)\\big|H\\big|\\psi(\\boldsymbol\\theta)\\rangle\\)by sampling the outcome of the circuit in the Z-basis and adding the expectation values of the individual Ising terms together. In general, different control points around\\(\\boldsymbol\\theta\\)have to be estimated, depending on the classical optimizer chosen. Use a classical optimizer to choose a new set of controls. Continue until\\(C(\\boldsymbol\\theta)\\)reaches a minimum, close enough to the solution\\(\\boldsymbol\\theta^*\\) Use the last\\(\\boldsymbol\\theta\\)to generate a final set of samples from the distribution\\(\\Big|\\langle z_i\\big|\\psi(\\boldsymbol\\theta)\\rangle\\Big|^2\\;\\forall i\\)to obtain the answer. There are many parameters throughout, notably the choice of the trial wavefunction. Below, we consider: $$ \\big|\\psi(\\theta)\\rangle = [U_\\mathrm{single}(\\boldsymbol\\theta) U_\\mathrm{entangler}]^m \\big|+\\rangle $$ where\\(U_\\mathrm{entangler}\\)is a collection of C-Phase gates (fully-entangling gates), and\\(U_\\mathrm{single}(\\theta) = \\prod_{i=1}^N Y(\\theta_{i})\\) where\\(N\\)is the number of qubits and\\(m\\)is the depth of the quantum circuit.","title":"Quantum solution"},{"location":"optimization/routing/routing/#construct-the-ising-hamiltonian","text":"From\\(VRP\\)one can construct a binary polynomial optimization with equality constraints only by considering cases in which\\(K=n-1\\) In these cases the sub-tour elimination constraints are not necessary and the problem is only on the variable\\({\\bf z}\\) In particular, we can write an augmented Lagrangian as $$ (IH) \\quad H = \\sum_{i \\sim j} w_{ij} x_{ij} + A \\sum_{i \\in {1,\\dots,n}} \\Big(\\sum_{j \\in \\delta(i)^+} x_{ij} - 1\\Big)^2 $$ $$ + A \\sum_{i \\in {1,\\dots,n}}\\Big(\\sum_{j \\in \\delta(i)^-} x_{ji} - 1\\Big)^2 +A \\Big(\\sum_{i \\in \\delta(0)^+} x_{0i} - K\\Big)^2 + A\\Big(\\sum_{j \\in \\delta(0)^+} x_{j0} - K\\Big)^2 $$ where \\(A\\) is a big enough parameter.","title":"Construct the Ising Hamiltonian"},{"location":"optimization/routing/routing/#from-hamiltonian-to-qp-formulation","text":"In the vector\\({\\bf z}\\) and for a complete graph (\\(\\delta(i)^+ = \\delta(i)^- = {0,1,\\dots,i-1,i+1,\\dots,n}\\), \\(H\\) can be written as follows. $$ \\min_{{\\bf z}\\in {0,1}^{n(n+1)}} {\\bf w}^T {\\bf z} + A \\sum_{i \\in {1,\\dots,n}} \\Big({\\bf e} i \\otimes {\\bf 1}_n^T {\\bf z} - 1\\Big)^2 + A \\sum {i \\in {1,\\dots,n}}\\Big({\\bf v}_i^T {\\bf z} - 1\\Big)^2 + A \\Big(({\\bf e}_0 \\otimes {\\bf 1}_n)^T{\\bf z} - K\\Big)^2 + A\\Big({\\bf v}_0^T{\\bf z} - K\\Big)^2. $$ That is: $$ \\min_{\\bf z\\in {0,1}^{n(n+1)}} \\bf z^T {\\bf Q} \\bf z + {\\bf g}^T \\bf z + c, $$ Where: first term: $$ {\\bf Q} = A \\sum_{i \\in {0,1,\\dots,n}} \\Big[({\\bf e}_i \\otimes {\\bf 1}_n)({\\bf e}_i \\otimes {\\bf 1}_n)^T + {\\bf v}_i{\\bf v}_i^T \\Big] $$ Second term: $$ {\\bf g} = {\\bf w} -2 A \\sum_{i \\in {1,\\dots,n}} \\Big[({\\bf e}_i \\otimes {\\bf 1}_n) + {\\bf v}_i \\Big] -2 A K \\Big[({\\bf e}_0 \\otimes {\\bf 1}_n) + {\\bf v}_0 \\Big] $$ Third term: $$ c = 2An +2AK^2. $$ The QP formulation of the Ising Hamiltonian is ready for the use of VQE.","title":"From Hamiltonian to QP formulation"},{"location":"optimization/routing/routing/#references","text":"[1] E. Farhi, J. Goldstone, S. Gutmann e-print arXiv 1411.4028, 2014 [2] https://github.com/Qiskit/qiskit-tutorial/blob/master/qiskit/aqua/optimization/maxcut_and_tsp.ipynb [3] C. E. Miller, E. W. Tucker, and R. A. Zemlin (1960). \"Integer Programming Formulations and Travelling Salesman Problems\". J. ACM. 7: 326\u2013329. doi:10.1145/321043.321046. [4] D. L. Applegate, R. M. Bixby, V. Chv\u00e1tal, and W. J. Cook (2006). The Traveling Salesman Problem. Princeton University Press, ISBN 978-0-691-12993-8.","title":"References"},{"location":"optimization/routing/routing/#initialization","text":"First of all we load all the packages that we need: - Python 3.6 or greater is required; - CPLEX 12.8 or greater is required for the classical computations; - Latest Qiskit is required for the quantum computations. # Load the packages that are required import numpy as np import operator import matplotlib.pyplot as plt import sys if sys . version_info < ( 3 , 6 ): raise Exception ( 'Please use Python version 3.6 or greater.' ) try : import cplex from cplex.exceptions import CplexError except : print ( \"Warning: Cplex not found.\" ) import math # Qiskit packages from qiskit.quantum_info import Pauli from qiskit.aqua.input import EnergyInput from qiskit.aqua import Operator, run_algorithm # setup aqua logging import logging from qiskit.aqua._logging import set_logging_config, build_logging_config # set_logging_config(build_logging_config(logging.DEBUG)) # choose INFO, DEBUG to see the log Warning: Cplex not found. We then initialize the variables # Initialize the problem by defining the parameters n = 3 # number of nodes + depot (n+1) K = 2 # number of vehicles We define an initializer class that randomly places the nodes in a 2-D plane and computes the distance between them. # Get the data class Initializer (): def __init__ ( self , n): self . n = n def generate_instance ( self ): n = self . n # np.random.seed(33) np . random . seed( 1543 ) xc = (np . random . rand(n) - 0.5 ) * 10 yc = (np . random . rand(n) - 0.5 ) * 10 instance = np . zeros([n, n]) for ii in range ( 0 , n): for jj in range (ii + 1 , n): instance[ii, jj] = (xc[ii] - xc[jj]) ** 2 + (yc[ii] - yc[jj]) ** 2 instance[jj, ii] = instance[ii, jj] return xc, yc, instance # Initialize the problem by randomly generating the instance initializer = Initializer(n) xc,yc,instance = initializer . generate_instance()","title":"Initialization"},{"location":"optimization/routing/routing/#classical-solution-using-ibm-ilog-cplex","text":"For a classical solution, we use IBM ILOG CPLEX. CPLEX is able to find the exact solution of this problem. We first define a ClassicalOptimizer class that encodes the problem in a way that CPLEX can solve, and then instantiate the class and solve it. class ClassicalOptimizer : def __init__ ( self , instance,n,K): self . instance = instance self . n = n # number of nodes self . K = K # number of vehicles def compute_allowed_combinations ( self ): f = math . factorial return f( self . n) / f( self . K) / f( self . n - self . K) def cplex_solution ( self ): # refactoring instance = self . instance n = self . n K = self . K my_obj = list (instance . reshape( 1 , n ** 2 )[ 0 ]) + \\ [ 0. for x in range ( 0 ,n - 1 )] my_ub = [ 1 for x in range ( 0 ,n ** 2 + n - 1 )] my_lb = [ 0 for x in range ( 0 ,n ** 2 )] \\ + [ 0.1 for x in range ( 0 ,n - 1 )] my_ctype = \"\" . join([ 'I' for x in range ( 0 ,n ** 2 )]) \\ + \"\" . join([ 'C' for x in range ( 0 ,n - 1 )]) my_rhs = 2 * ([K] + [ 1 for x in range ( 0 ,n - 1 )]) \\ + [ 1 - 0.1 for x in range ( 0 ,(n - 1 ) ** 2 - (n - 1 ))] \\ + [ 0 for x in range ( 0 ,n)] my_sense = \"\" . join([ 'E' for x in range ( 0 , 2 * n)]) \\ + \"\" . join([ 'L' for x in range ( 0 ,(n - 1 ) ** 2 - (n - 1 ))]) + \\ \"\" . join([ 'E' for x in range ( 0 ,n)]) try : my_prob = cplex . Cplex() self . populatebyrow(my_prob,my_obj,my_ub,my_lb,\\ my_ctype,my_sense,my_rhs) my_prob . solve() except CplexError as exc: print (exc) return x = my_prob . solution . get_values() x = np . array(x) cost = my_prob . solution . get_objective_value() return x,cost def populatebyrow ( self ,prob,my_obj,my_ub,my_lb,\\ my_ctype,my_sense,my_rhs): n = self . n prob . objective . set_sense(prob . objective . sense . minimize) prob . variables . add(obj = my_obj, lb = my_lb, \\ ub = my_ub, types = my_ctype) prob . set_log_stream( None ) prob . set_error_stream( None ) prob . set_warning_stream( None ) prob . set_results_stream( None ) rows = [] for ii in range ( 0 ,n): col = [x for x in range ( 0 + n * ii,n + n * ii)] coef = [ 1 for x in range ( 0 ,n)] rows . append([col, coef]) for ii in range ( 0 ,n): col = [x for x in range ( 0 + ii,n ** 2 ,n)] coef = [ 1 for x in range ( 0 ,n)] rows . append([col, coef]) # Sub-tour elimination constraints: for ii in range ( 0 , n): for jj in range ( 0 ,n): if (ii != jj) and (ii * jj > 0 ): col = [ii + (jj * n), n ** 2 + ii - 1 , n ** 2 + jj - 1 ] coef = [ 1 , 1 , - 1 ] rows . append([col, coef]) for ii in range ( 0 ,n): col = [(ii) * (n + 1 )] coef = [ 1 ] rows . append([col, coef]) prob . linear_constraints . add(lin_expr = rows,\\ senses = my_sense, rhs = my_rhs) # Instantiate the classical optimizer class classical_optimizer = ClassicalOptimizer(instance,n,K) # Print number of feasible solutions print ( 'Number of feasible solutions = ' \\ + str (classical_optimizer . compute_allowed_combinations())) Number of feasible solutions = 3.0 # Solve the problem in a classical fashion via CPLEX x = None z = None try : x,classical_cost = classical_optimizer . cplex_solution() # Put the solution in the z variable z = [x[ii] for ii in range (n ** 2 ) if ii // n != ii % n] # Print the solution print (z) except : print ( \"CPLEX may be missing.\" ) CPLEX may be missing. # Visualize the solution def visualize_solution (xc, yc, x, C, n, K, title_str): plt . figure() plt . scatter(xc, yc, s = 200 ) for i in range ( len (xc)): plt . annotate(i, (xc[i] + 0.15 , yc[i]), size = 16 , color = 'r' ) plt . plot(xc[ 0 ], yc[ 0 ], 'r*' , ms = 20 ) plt . grid() for ii in range ( 0 , n ** 2 ): if x[ii] > 0 : ix = ii // n iy = ii % n plt . arrow(xc[ix], yc[ix], xc[iy] - xc[ix], yc[iy] \\ - yc[ix], length_includes_head = True , head_width =. 25 ) plt . title(title_str + ' cost = ' + str ( int (C * 100 ) / 100. )) plt . show() if x: visualize_solution(xc, yc, x, classical_cost, n, K, 'Classical' ) If you have CPLEX, the solution shows the depot with a star and the selected routes for the vehicles with arrows.","title":"Classical solution using IBM ILOG CPLEX"},{"location":"optimization/routing/routing/#quantum-solution-from-the-ground-up","text":"For the quantum solution, we use Qiskit. First, we derive the solution from the ground up, using a class QuantumOptimizer that encodes the quantum approach to solve the problem and then we instantiate it and solve it. We define the following methods inside the class: - binary_representation : encodes the problem\\((M)\\)into a the Ising Hamiltonian QP (that's basically linear algebra); - construct_hamiltonian : constructs the Ising Hamiltonian in terms of the\\(Z\\)basis; - check_hamiltonian : makes sure that the Ising Hamiltonian is correctly encoded in the\\(Z\\)basis: to do this, it solves a eigenvalue-eigenvector problem for a symmetric matrix of dimension\\(2^N \\times 2^N\\) For the problem at hand\\(n=3\\) that is\\(N = 12\\)seems the limit; - vqe_solution : solves the problem\\((M)\\)via VQE by using the SPSA solver (with default parameters); - _q_solution : internal routine to represent the solution in a usable format. class QuantumOptimizer : def __init__ ( self , instance, n, K, max_trials = 1000 ): self . instance = instance self . n = n self . K = K self . max_trials = max_trials def binary_representation ( self ,x_sol = 0 ): instance = self . instance n = self . n K = self . K A = np . max(instance) * 100 # A parameter of cost function # Determine the weights w instance_vec = instance . reshape(n ** 2 ) w_list = [instance_vec[x] for x in range (n ** 2 ) \\ if instance_vec[x] > 0 ] w = np . zeros(n * (n - 1 )) for ii in range ( len (w_list)): w[ii] = w_list[ii] # Some variables I will use Id_n = np . eye(n) Im_n_1 = np . ones([n - 1 , n - 1 ]) Iv_n_1 = np . ones(n) Iv_n_1[ 0 ] = 0 Iv_n = np . ones(n - 1 ) neg_Iv_n_1 = np . ones(n) - Iv_n_1 v = np . zeros([n, n * (n - 1 )]) for ii in range (n): count = ii - 1 for jj in range (n * (n - 1 )): if jj // (n - 1 ) == ii: count = ii if jj // (n - 1 ) != ii and jj % (n - 1 ) == count: v[ii][jj] = 1. vn = np . sum(v[ 1 :], axis = 0 ) # Q defines the interactions between variables Q = A * (np . kron(Id_n, Im_n_1) + np . dot(v . T, v)) # g defines the contribution from the individual variables g = w - 2 * A * (np . kron(Iv_n_1,Iv_n) + vn . T) - \\ 2 * A * K * (np . kron(neg_Iv_n_1, Iv_n) + v[ 0 ] . T) # c is the constant offset c = 2 * A * (n - 1 ) + 2 * A * (K ** 2 ) try : max (x_sol) # Evaluates the cost distance from # a binary representation of a path fun = lambda x: np . dot(np . around(x), np . dot(Q, np . around(x))) + \\ np . dot(g, np . around(x)) + c cost = fun(x_sol) except : cost = 0 return Q,g,c,cost def construct_hamiltonian ( self ): instance = self . instance n = self . n K = self . K N = (n - 1 ) * n # number of qubits Q,g,c,_ = self . binary_representation() # Defining the new matrices in the Z-basis Iv = np . ones(N) Qz = (Q / 4 ) gz = ( - g / 2 - np . dot(Iv, Q / 4 ) - np . dot(Q / 4 , Iv)) cz = (c + np . dot(g / 2 , Iv) + np . dot(Iv, np . dot(Q / 4 , Iv))) cz = cz + np . trace(Qz) Qz = Qz - np . diag(np . diag(Qz)) # Getting the Hamiltonian in the form of a list of Pauli terms pauli_list = [] for i in range (N): if gz[i] != 0 : wp = np . zeros(N) vp = np . zeros(N) vp[i] = 1 pauli_list . append((gz[i], Pauli(vp, wp))) for i in range (N): for j in range (i): if Qz[i, j] != 0 : wp = np . zeros(N) vp = np . zeros(N) vp[i] = 1 vp[j] = 1 pauli_list . append(( 2 * Qz[i, j], Pauli(vp, wp))) pauli_list . append((cz, Pauli(np . zeros(N), np . zeros(N)))) return cz, pauli_list def check_hamiltonian ( self ): cz, op = self . construct_hamiltonian() Op = Operator(paulis = op) qubitOp, offset = Op, 0 algo_input = EnergyInput(qubitOp) # Making the Hamiltonian in its full form and # getting the lowest eigenvalue and eigenvector algorithm_cfg = { 'name' : 'ExactEigensolver' , } params = { 'problem' : { 'name' : 'ising' }, 'algorithm' : algorithm_cfg } result = run_algorithm(params, algo_input) quantum_solution = self . _q_solution(result[ 'eigvecs' ][ 0 ],\\ self . n * ( self . n + 1 )) ground_level = result[ 'energy' ] + offset return quantum_solution, ground_level def vqe_solution ( self ): cz, op = self . construct_hamiltonian() Op = Operator(paulis = op) qubitOp, offset = Op, cz algo_input = EnergyInput(qubitOp) algorithm_cfg = { 'name' : 'VQE' , 'operator_mode' : 'paulis' } optimizer_cfg = { 'name' : 'SPSA' , 'max_trials' : self . max_trials } var_form_cfg = { 'name' : 'RY' , 'depth' : 5 , 'entanglement' : 'linear' } params = { 'problem' : { 'name' : 'ising' , 'random_seed' : 10598 }, 'algorithm' : algorithm_cfg, 'optimizer' : optimizer_cfg, 'variational_form' : var_form_cfg, 'backend' : { 'name' : 'qasm_simulator' } } result = run_algorithm(params, algo_input) #quantum_solution = self._q_solution(result['eigvecs'][0],\\ # self.n * (self.n + 1)) quantum_solution_dict = result[ 'eigvecs' ][ 0 ] q_s = max (quantum_solution_dict . items(), key = operator . itemgetter( 1 ))[ 0 ] quantum_solution = [ int (chars) for chars in q_s] quantum_solution = np . flip(quantum_solution, axis = 0 ) _,_,_,level = self . binary_representation(x_sol = quantum_solution) return quantum_solution_dict, quantum_solution, level def _q_solution ( self , v, N): index_value = [x for x in range ( len (v)) if v[x] == max (v)][ 0 ] string_value = \"{0:b}\" . format(index_value) while len (string_value) < N: string_value = '0' + string_value sol = list () for elements in string_value: if elements == '0' : sol . append( 0 ) else : sol . append( 1 ) sol = np . flip(sol, axis = 0 ) return sol","title":"Quantum solution from the ground up"},{"location":"optimization/routing/routing/#step-1","text":"Instantiate the quantum optimizer class with parameters: - the instance; - the number of nodes and vehicles n and K ; - the number of iterations for SPSA in VQE (default 1000) # Instantiate the quantum optimizer class with parameters: quantum_optimizer = QuantumOptimizer(instance,n,K, 100 )","title":"Step 1"},{"location":"optimization/routing/routing/#step-2","text":"Encode the problem as a binary formulation (IH-QP). Sanity check: make sure that the binary formulation in the quantum optimizer is correct (i.e., yields the same cost given the same solution). # Check if the binary representation is correct try : if z: Q,g,c,binary_cost = quantum_optimizer . binary_representation(x_sol = z) print (binary_cost,classical_cost) if np . abs(binary_cost - classical_cost) < 0.01 : print ( 'Binary formulation is correct' ) else : print ( 'Error in the binary formulation' ) else : print ( 'Could not verify the correctness, due to CPLEX solution being unavailable.' ) Q,g,c,binary_cost = quantum_optimizer . binary_representation() except NameError as e: print ( \"Warning: Please run the cells above first.\" ) print (e) Could not verify the correctness, due to CPLEX solution being unavailable.","title":"Step 2"},{"location":"optimization/routing/routing/#step-3","text":"Encode the problem as an Ising Hamiltonian in the Z basis. Sanity check: make sure that the formulation is correct (i.e., yields the same cost given the same solution) ground_state, ground_level = quantum_optimizer . check_hamiltonian() print (ground_state) if z: if np . abs(ground_level - classical_cost) < 0.01 : print ( 'Ising Hamiltonian in Z basis is correct' ) else : print ( 'Error in the Ising Hamiltonian formulation' ) [1 1 1 0 1 0 0 0 0 0 0 0]","title":"Step 3"},{"location":"optimization/routing/routing/#step-4","text":"Solve the problem via VQE. N.B. Depending on the number of qubits, the state-vector simulation can can take a while; for example with 12 qubits, it takes more than 12 hours. Logging useful to see what the program is doing. quantum_dictionary, quantum_solution, quantum_cost = quantum_optimizer . vqe_solution() print (quantum_solution, quantum_cost) [1 1 1 0 1 0] 132.11148115684045","title":"Step 4"},{"location":"optimization/routing/routing/#step-5","text":"Visualize the solution # Put the solution in a way that is compatible with the classical variables x_quantum = np . zeros(n ** 2 ) kk = 0 for ii in range (n ** 2 ): if ii // n != ii % n: x_quantum[ii] = quantum_solution[kk] kk += 1 # visualize the solution visualize_solution(xc, yc, x_quantum, quantum_cost, n, K, 'Quantum' ) # and visualize the classical for comparison if x: visualize_solution(xc, yc, x, classical_cost, n, K, 'Classical' ) The plots present the depot with a star and the selected routes for the vehicles with arrows. Note that in this particular case, we can find the optimal solution of the QP formulation, which happens to coincide with the optimal solution of the ILP. Keep in mind that VQE is an heuristic working on the QP formulation of the Ising Hamiltonian, though. For suitable choices of A, local optima of the QP formulation will be feasible solutions to the ILP. While for some small instances, as above, we can find optimal solutions of the QP formulation which coincide with optima of the ILP, finding optimal solutions of the ILP is harder than finding local optima of the QP formulation, in general, which in turn is harder than finding feasible solutions of the ILP. Even within the VQE, one may provide stronger guarantees, for specific variational forms (trial wave functions). Last but not least, you may be pleased to learn that the above has been packaged in Qiskit Aqua. from qiskit import BasicAer from qiskit.aqua import QuantumInstance from qiskit.aqua import Operator, run_algorithm from qiskit.aqua.input import EnergyInput from qiskit.aqua.algorithms import VQE, QAOA, ExactEigensolver from qiskit.aqua.components.optimizers import COBYLA from qiskit.aqua.components.variational_forms import RY from qiskit.aqua.translators.ising.vehicle_routing import * qubitOp = get_vehiclerouting_qubitops(instance, n, K) backend = BasicAer . get_backend( 'statevector_simulator' ) seed = 50 cobyla = COBYLA() cobyla . set_options(maxiter = 250 ) ry = RY(qubitOp . num_qubits, depth = 3 , entanglement = 'full' ) vqe = VQE(qubitOp, ry, cobyla, 'matrix' ) vqe . random_seed = seed quantum_instance = QuantumInstance(backend = backend,\\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) # print(result) x_quantum2 = get_vehiclerouting_solution(instance, n, K, result) print (x_quantum2) quantum_cost2 = get_vehiclerouting_cost(instance, n, K, x_quantum2) print (quantum_cost2) [1 1 1 0 0 1] 12434.909288240102","title":"Step 5"},{"location":"optimization/salesman/salesman/","text":"Qiskit Aqua: Variational Quantum Eigensolver Experimenting with Max-Cut problem and Traveling Salesman problem with variational quantum eigensolver The latest version of this notebook is available here . Contributors Antonio Mezzacapo [1] , Jay Gambetta [1] , Kristan Temme [1] , Ramis Movassagh [1] , Albert Frisch [1] , Takashi Imamichi [1] , Giacomo Nannicni [1] , Richard Chen [1] , Marco Pistoia [1] , Stephen Wood [1] Affiliation [1] IBMQ Introduction Many problems in quantitative fields such as finance and engineering are optimization problems. Optimization problems lay at the core of complex decision-making and definition of strategies. Optimization (or combinatorial optimization) means searching for an optimal solution in a finite or countably infinite set of potential solutions. Optimality is defined with respect to some criterion function, which is to be minimized or maximized. This is typically called cost function or objective function. Typical optimization problems Minimization: cost, distance, length of a traversal, weight, processing time, material, energy consumption, number of objects Maximization: profit, value, output, return, yield, utility, efficiency, capacity, number of objects We consider here max-cut problem of practical interest in many fields, and show how they can mapped on quantum computers. Weighted Max-Cut Max-Cut is an NP-complete problem, with applications in clustering, network science, and statistical physics. To grasp how practical applications are mapped into given Max-Cut instances, consider a system of many people that can interact and influence each other. Individuals can be represented by vertices of a graph, and their interactions seen as pairwise connections between vertices of the graph, or edges. With this representation in mind, it is easy to model typical marketing problems. For example, suppose that it is assumed that individuals will influence each other's buying decisions, and knowledge is given about how strong they will influence each other. The influence can be modeled by weights assigned on each edge of the graph. It is possible then to predict the outcome of a marketing strategy in which products are offered for free to some individuals, and then ask which is the optimal subset of individuals that should get the free products, in order to maximize revenues. The formal definition of this problem is the following: Consider an \\(n\\)-node undirected graph G = (V, E) where |V| = n with edge weights \\(w_{ij}>0, w_{ij}=w_{ji}\\), for \\((i, j)\\in E\\). A cut is defined as a partition of the original set V into two subsets. The cost function to be optimized is in this case the sum of weights of edges connecting points in the two different subsets, crossing the cut. By assigning \\(x_i=0\\) or \\( x_i=1 \\) to each node \\(i\\), one tries to maximize the global profit function (here and in the following summations run over indices 0,1,...n-1) $$ \\tilde{C}(\\textbf{x}) = \\sum_{i,j} w_{ij} x_i (1-x_j). $$ In our simple marketing model, \\(w_{ij}\\) represents the probability that the person \\(j\\) will buy a product after \\(i\\) gets a free one. Note that the weights \\(w_{ij}\\) can in principle be greater than \\(1\\), corresponding to the case where the individual \\(j\\) will buy more than one product. Maximizing the total buying probability corresponds to maximizing the total future revenues. In the case where the profit probability will be greater than the cost of the initial free samples, the strategy is a convenient one. An extension to this model has the nodes themselves carry weights, which can be regarded, in our marketing model, as the likelihood that a person granted with a free sample of the product will buy it again in the future. With this additional information in our model, the objective function to maximize becomes $$ C(\\textbf{x}) = \\sum_{i,j} w_{ij} x_i (1-x_j)+\\sum_i w_i x_i.$$ In order to find a solution to this problem on a quantum computer, one needs first to map it to an Ising Hamiltonian. This can be done with the assignment \\(x_i\\rightarrow (1-Z_i)/2\\), where \\(Z_i\\) is the Pauli Z operator that has eigenvalues \\( \\pm 1 \\). Doing this we find that $$C(\\textbf{Z}) = \\sum_{i,j} \\frac{w_{ij}}{4} (1-Z_i)(1+Z_j) + \\sum_i \\frac{w_i}{2} (1-Z_i)$$ $$ = -\\frac{1}{2}\\left( \\sum_{i<j} w_{ij} Z_i Z_j +\\sum_i w_i Z_i\\right)+\\mathrm{const},$$ where const = \\(\\sum_{i<j}w_{ij}/2+\\sum_i w_i/2 \\). In other terms, the weighted Max-Cut problem is equivalent to minimizing the Ising Hamiltonian $$H = \\sum_i w_i Z_i + \\sum_{i<j} w_{ij} Z_iZ_j.$$ Aqua can generate the Ising Hamiltonian for the first profit function\\(\\tilde{C}$. Approximate Universal Quantum Computing for Optimization Problems There has been a considerable amount of interest in recent times about the use of quantum computers to find a solution to combinatorial problems. It is important to say that, given the classical nature of combinatorial problems, exponential speedup in using quantum computers compared to the best classical algorithms is not guaranteed. However, due to the nature and importance of the target problems, it is worth investigating heuristic approaches on a quantum computer that could indeed speed up some problem instances. Here we demonstrate an approach that is based on the Quantum Approximate Optimization Algorithm by Farhi, Goldstone, and Gutman (2014). We frame the algorithm in the context of approximate quantum computing , given its heuristic nature. The Algorithm works as follows: Choose the \\(w_i\\) and \\(w_{ij}\\) in the target Ising problem. In principle, even higher powers of Z are allowed. Choose the depth of the quantum circuit \\(m\\). Note that the depth can be modified adaptively. Choose a set of controls \\(\\theta\\) and make a trial function \\(|\\psi(\\boldsymbol\\theta)\\rangle\\), built using a quantum circuit made of C-Phase gates and single-qubit Y rotations, parameterized by the components of \\(\\boldsymbol\\theta\\). Evaluate $$ C(\\boldsymbol\\theta) = \\langle\\psi(\\boldsymbol\\theta)~|H|~\\psi(\\boldsymbol\\theta)\\rangle$$ $$ = \\sum_i w_i \\langle\\psi(\\boldsymbol\\theta)~|Z_i|~\\psi(\\boldsymbol\\theta)\\rangle+ \\sum_{i<j} w_{ij} \\langle\\psi(\\boldsymbol\\theta)~|Z_iZ_j|~\\psi(\\boldsymbol\\theta)\\rangle$$ by sampling the outcome of the circuit in the Z-basis and adding the expectation values of the individual Ising terms together. In general, different control points around \\(\\boldsymbol\\theta\\) have to be estimated, depending on the classical optimizer chosen. Use a classical optimizer to choose a new set of controls. Continue until \\(C(\\boldsymbol\\theta)\\) reaches a minimum, close enough to the solution \\(\\boldsymbol\\theta^*\\). Use the last \\(\\boldsymbol\\theta\\) to generate a final set of samples from the distribution \\(|\\langle z_i~|\\psi(\\boldsymbol\\theta)\\rangle|^2\\;\\forall i\\) to obtain the answer. It is our belief the difficulty of finding good heuristic algorithms will come down to the choice of an appropriate trial wavefunction. For example, one could consider a trial function whose entanglement best aligns with the target problem, or simply make the amount of entanglement a variable. In this tutorial, we will consider a simple trial function of the form $$|\\psi(\\theta)\\rangle = [U_\\mathrm{single}(\\boldsymbol\\theta) U_\\mathrm{entangler}]^m |+\\rangle$$ where\\(U_\\mathrm{entangler}\\)is a collection of C-Phase gates (fully entangling gates), and\\(U_\\mathrm{single}(\\theta) = \\prod_{i=1}^n Y(\\theta_{i})\\), where\\(n\\)is the number of qubits and\\(m\\)is the depth of the quantum circuit. The motivation for this choice is that for these classical problems this choice allows us to search over the space of quantum states that have only real coefficients, still exploiting the entanglement to potentially converge faster to the solution. One advantage of using this sampling method compared to adiabatic approaches is that the target Ising Hamiltonian does not have to be implemented directly on hardware, allowing this algorithm not to be limited to the connectivity of the device. Furthermore, higher-order terms in the cost function, such as\\(Z_iZ_jZ_k\\), can also be sampled efficiently, whereas in adiabatic or annealing approaches they are generally impractical to deal with. References: A. Lucas, Frontiers in Physics 2, 5 (2014) E. Farhi, J. Goldstone, S. Gutmann e-print arXiv 1411.4028 (2014) D. Wecker, M. B. Hastings, M. Troyer Phys. Rev. A 94, 022309 (2016) E. Farhi, J. Goldstone, S. Gutmann, H. Neven e-print arXiv 1703.06199 (2017) # useful additional packages import matplotlib.pyplot as plt import matplotlib.axes as axes % matplotlib inline import numpy as np import networkx as nx from qiskit import BasicAer from qiskit.tools.visualization import plot_histogram from qiskit.aqua import Operator, run_algorithm from qiskit.aqua.input import EnergyInput from qiskit.aqua.translators.ising import max_cut, tsp from qiskit.aqua.algorithms import VQE, ExactEigensolver from qiskit.aqua.components.optimizers import SPSA from qiskit.aqua.components.variational_forms import RY from qiskit.aqua import QuantumInstance # setup aqua logging import logging from qiskit.aqua import set_qiskit_aqua_logging # set_qiskit_aqua_logging(logging.DEBUG) # choose INFO, DEBUG to see the log [Optional] Setup token to run the experiment on a real device If you would like to run the experiement on a real device, you need to setup your account first. Note: If you do not store your token yet, use IBMQ.save_accounts() to store it first. from qiskit import IBMQ # IBMQ.load_accounts() Max-Cut problem Generating a graph of 4 nodes n = 4 # Number of nodes in graph G = nx . Graph() G . add_nodes_from(np . arange( 0 ,n, 1 )) elist = [( 0 , 1 , 1.0 ),( 0 , 2 , 1.0 ),( 0 , 3 , 1.0 ),( 1 , 2 , 1.0 ),( 2 , 3 , 1.0 )] # tuple is (i,j,weight) where (i,j) is the edge G . add_weighted_edges_from(elist) colors = [ 'r' for node in G . nodes()] pos = nx . spring_layout(G) default_axes = plt . axes(frameon = True ) nx . draw_networkx(G, node_color = colors, node_size = 600 , alpha =. 8 , ax = default_axes, pos = pos) Computing the weight matrix from the random graph w = np . zeros([n,n]) for i in range (n): for j in range (n): temp = G . get_edge_data(i,j,default = 0 ) if temp != 0 : w[i,j] = temp[ 'weight' ] print (w) [[0. 1. 1. 1.] [1. 0. 1. 0.] [1. 1. 0. 1.] [1. 0. 1. 0.]] Brute force approach Try all possible\\(2^n\\)combinations. For\\(n = 4\\), as in this example, one deals with only 16 combinations, but for n = 1000, one has 1.071509e+30 combinations, which is impractical to deal with by using a brute force approach. best_cost_brute = 0 for b in range ( 2 ** n): x = [ int (t) for t in reversed ( list ( bin (b)[ 2 :] . zfill(n)))] cost = 0 for i in range (n): for j in range (n): cost = cost + w[i,j] * x[i] * ( 1 - x[j]) if best_cost_brute < cost: best_cost_brute = cost xbest_brute = x print ( 'case = ' + str (x) + ' cost = ' + str (cost)) colors = [ 'r' if xbest_brute[i] == 0 else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors,\\ node_size = 600 , alpha =. 8 , pos = pos) print ( ' \\n Best solution = ' + str (xbest_brute) + \\ ' cost = ' + str (best_cost_brute)) case = [0, 0, 0, 0] cost = 0.0 case = [1, 0, 0, 0] cost = 3.0 case = [0, 1, 0, 0] cost = 2.0 case = [1, 1, 0, 0] cost = 3.0 case = [0, 0, 1, 0] cost = 3.0 case = [1, 0, 1, 0] cost = 4.0 case = [0, 1, 1, 0] cost = 3.0 case = [1, 1, 1, 0] cost = 2.0 case = [0, 0, 0, 1] cost = 2.0 case = [1, 0, 0, 1] cost = 3.0 case = [0, 1, 0, 1] cost = 4.0 case = [1, 1, 0, 1] cost = 3.0 case = [0, 0, 1, 1] cost = 3.0 case = [1, 0, 1, 1] cost = 2.0 case = [0, 1, 1, 1] cost = 3.0 case = [1, 1, 1, 1] cost = 0.0 Best solution = [1, 0, 1, 0] cost = 4.0 Mapping to the Ising problem qubitOp, offset = max_cut . get_max_cut_qubitops(w) algo_input = EnergyInput(qubitOp) [Optional] Using DOcplex for mapping to the Ising problem Using docplex.get_qubitops is a different way to create an Ising Hamiltonian of Max-Cut. docplex.get_qubitops can create a corresponding Ising Hamiltonian from an optimization model of Max-Cut. An example of using docplex.get_qubitops is as below. from docplex.mp.model import Model from qiskit.aqua.translators.ising import docplex # Create an instance of a model and variables. mdl = Model(name = 'max_cut' ) x = {i: mdl . binary_var(name = 'x_{0}' . format(i)) for i in range (n)} # Object function max_cut_func = mdl . sum(w[i,j] * x[i] * ( 1 - x[j] )\\ for i in range (n) for j in range (n)) mdl . maximize(max_cut_func) # No constraints for Max-Cut problems. qubitOp_docplex, offset_docplex = docplex . get_qubitops(mdl) Checking that the full Hamiltonian gives the right cost # Making the Hamiltonian in its full form and # getting the lowest eigenvalue and eigenvector ee = ExactEigensolver(qubitOp, k = 1 ) result = ee . run() \"\"\" algorithm_cfg = { 'name': 'ExactEigensolver', } params = { 'problem': {'name': 'ising'}, 'algorithm': algorithm_cfg } result = run_algorithm(params,algo_input) \"\"\" x = max_cut . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'energy:' , result[ 'energy' ]) print ( 'max-cut objective:' , result[ 'energy' ] + offset) print ( 'solution:' , max_cut . get_graph_solution(x)) print ( 'solution objective:' , max_cut . max_cut_value(x, w)) colors = [ 'r' if max_cut . get_graph_solution(x)[i] == 0 \\ else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors, \\ node_size = 600 , alpha = . 8 , pos = pos) energy: -1.5 max-cut objective: -4.0 solution: [0. 1. 0. 1.] solution objective: 4.0 Running it on quantum computer We run the optimization routine using a feedback loop with a quantum computer that uses trial functions built with Y single-qubit rotations,\\(U_\\mathrm{single}(\\theta) = \\prod_{i=1}^n Y(\\theta_{i})\\), and entangler steps\\(U_\\mathrm{entangler}\\). seed = 10598 spsa = SPSA(max_trials = 300 ) ry = RY(qubitOp . num_qubits, depth = 5 , entanglement = 'linear' ) vqe = VQE(qubitOp, ry, spsa, 'matrix' ) backend = BasicAer . get_backend( 'statevector_simulator' ) quantum_instance = QuantumInstance(backend, \\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) \"\"\"declarative approach algorithm_cfg = { 'name': 'VQE', 'operator_mode': 'matrix' } optimizer_cfg = { 'name': 'SPSA', 'max_trials': 300 } var_form_cfg = { 'name': 'RY', 'depth': 5, 'entanglement': 'linear' } params = { 'problem': {'name': 'ising', 'random_seed': seed}, 'algorithm': algorithm_cfg, 'optimizer': optimizer_cfg, 'variational_form': var_form_cfg, 'backend': {provider': 'qiskit.BasicAer',\\ 'name': 'statevector_simulator'} } result = run_algorithm(params, algo_input) \"\"\" x = max_cut . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'energy:' , result[ 'energy' ]) print ( 'time:' , result[ 'eval_time' ]) print ( 'max-cut objective:' , result[ 'energy' ] + offset) print ( 'solution:' , max_cut . get_graph_solution(x)) print ( 'solution objective:' , max_cut . max_cut_value(x, w)) colors = [ 'r' if max_cut . get_graph_solution(x)[i] == 0 \\ else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors,\\ node_size = 600 , alpha = . 8 , pos = pos) energy: -1.4999760821185284 time: 7.753880739212036 max-cut objective: -3.999976082118528 solution: [1. 0. 1. 0.] solution objective: 4.0 Run quantum algorithm with shots seed = 10598 spsa = SPSA(max_trials = 300 ) ry = RY(qubitOp . num_qubits, depth = 5 , entanglement = 'linear' ) vqe = VQE(qubitOp, ry, spsa, 'grouped_paulis' ) backend = BasicAer . get_backend( 'qasm_simulator' ) quantum_instance = QuantumInstance(backend, shots = 1024 ,\\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) \"\"\"declarative approach, update the param from the previous cell. params['algorithm']['operator_mode'] = 'grouped_paulis' params['backend']['provider'] = 'qiskit.BasicAer' params['backend']['name'] = 'qasm_simulator' params['backend']['shots'] = 1024 result = run_algorithm(params, algo_input) \"\"\" x = max_cut . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'energy:' , result[ 'energy' ]) print ( 'time:' , result[ 'eval_time' ]) print ( 'max-cut objective:' , result[ 'energy' ] + offset) print ( 'solution:' , max_cut . get_graph_solution(x)) print ( 'solution objective:' , max_cut . max_cut_value(x, w)) plot_histogram(result[ 'eigvecs' ][ 0 ]) colors = [ 'r' if max_cut . get_graph_solution(x)[i] == 0 \\ else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors, node_size = 600 ,\\ alpha = . 8 , pos = pos) energy: -1.5 time: 15.852537155151367 max-cut objective: -4.0 solution: [1 0 1 0] solution objective: 4.0 [Optional] Checking that the full Hamiltonian made by docplex.get_qubitops gives the right cost # Making the Hamiltonian in its full form and getting # the lowest eigenvalue and eigenvector ee = ExactEigensolver(qubitOp_docplex, k = 1 ) result = ee . run() x = docplex . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'energy:' , result[ 'energy' ]) print ( 'max-cut objective:' , result[ 'energy' ] + offset_docplex) print ( 'solution:' , max_cut . get_graph_solution(x)) print ( 'solution objective:' , max_cut . max_cut_value(x, w)) colors = [ 'r' if max_cut . get_graph_solution(x)[i] == 0 \\ else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors, \\ node_size = 600 , alpha = . 8 , pos = pos) energy: -1.5 max-cut objective: -4.0 solution: [0. 1. 0. 1.] solution objective: 4.0 Traveling Salesman Problem In addition to being a notorious NP-complete problem that has drawn the attention of computer scientists and mathematicians for over two centuries, the Traveling Salesman Problem (TSP) has important bearings on finance and marketing, as its name suggests. Colloquially speaking, the traveling salesman is a person that goes from city to city to sell merchandise. The objective in this case is to find the shortest path that would enable the salesman to visit all the cities and return to its hometown, i.e. the city where he started traveling. By doing this, the salesman gets to maximize potential sales in the least amount of time. The problem derives its importance from its \"hardness\" and ubiquitous equivalence to other relevant combinatorial optimization problems that arise in practice. The mathematical formulation with some early analysis was proposed by W.R. Hamilton in the early 19th century. Mathematically the problem is, as in the case of Max-Cut, best abstracted in terms of graphs. The TSP on the nodes of a graph asks for the shortest Hamiltonian cycle that can be taken through each of the nodes. A Hamilton cycle is a closed path that uses every vertex of a graph once. The general solution is unknown and an algorithm that finds it efficiently (e.g., in polynomial time) is not expected to exist. Find the shortest Hamiltonian cycle in a graph \\(G=(V,E)\\)with\\(n=|V|\\) nodes and distances,\\(w_{ij}\\) (distance from vertex \\(i\\)to vertex\\(j\\). A Hamiltonian cycle is described by \\(N^2\\)variables\\(x_{i,p}\\), where\\(i\\)represents the node and\\(p\\)represents its order in a prospective cycle. The decision variable takes the value 1 if the solution occurs at node\\(i\\)at time order\\(p\\). We require that every node can only appear once in the cycle, and for each time a node has to occur. This amounts to the two constraints (here and in the following, whenever not specified, the summands run over 0,1,...N-1) $$\\sum_{i} x_{i,p} = 1 ~~\\forall p$$ $$\\sum_{p} x_{i,p} = 1 ~~\\forall i.$$ For nodes in our prospective ordering, if\\(x_{i,p}\\)and\\(x_{j,p+1}\\)are both 1, then there should be an energy penalty if\\((i,j) \\notin E\\)(not connected in the graph). The form of this penalty is $$\\sum_{i,j\\notin E}\\sum_{p} x_{i,p}x_{j,p+1}>0,$$ where it is assumed the boundary condition of the Hamiltonian cycle\\((p=N)\\equiv (p=0)\\). However, here it will be assumed a fully connected graph and not include this term. The distance that needs to be minimized is $$C(\\textbf{x})=\\sum_{i,j}w_{ij}\\sum_{p} x_{i,p}x_{j,p+1}.$$ Putting this all together in a single objective function to be minimized, we get the following: $$C(\\textbf{x})=\\sum_{i,j}w_{ij}\\sum_{p} x_{i,p}x_{j,p+1}+ A\\sum_p\\left(1- \\sum_i x_{i,p}\\right)^2+A\\sum_i\\left(1- \\sum_p x_{i,p}\\right)^2,$$ where\\(A\\)is a free parameter. One needs to ensure that\\(A\\)is large enough so that these constraints are respected. One way to do this is to choose\\(A\\)such that\\(A > \\mathrm{max}(w_{ij})\\). Once again, it is easy to map the problem in this form to a quantum computer, and the solution will be found by minimizing a Ising Hamiltonian. # Generating a graph of 3 nodes n = 3 num_qubits = n ** 2 ins = tsp . random_tsp(n) G = nx . Graph() G . add_nodes_from(np . arange( 0 , n, 1 )) colors = [ 'r' for node in G . nodes()] pos = {k: v for k, v in enumerate (ins . coord)} default_axes = plt . axes(frameon = True ) nx . draw_networkx(G, node_color = colors, node_size = 600 , alpha =. 8 , ax = default_axes, pos = pos) print ( 'distance \\n ' , ins . w) distance [[ 0. 51. 81.] [51. 0. 99.] [81. 99. 0.]] Brute force approach from itertools import permutations def brute_force_tsp (w, N): a = list (permutations( range ( 1 ,N))) last_best_distance = 1e10 for i in a: distance = 0 pre_j = 0 for j in i: distance = distance + w[j,pre_j] pre_j = j distance = distance + w[pre_j, 0 ] order = ( 0 ,) + i if distance < last_best_distance: best_order = order last_best_distance = distance print ( 'order = ' + str (order) + \\ ' Distance = ' + str (distance)) return last_best_distance, best_order best_distance, best_order = brute_force_tsp(ins . w, ins . dim) print ( 'Best order from brute force = ' + str (best_order) + \\ ' with total distance = ' + str (best_distance)) def draw_tsp_solution (G, order, colors, pos): G2 = G . copy() n = len (order) for i in range (n): j = (i + 1 ) % n G2 . add_edge(order[i], order[j]) default_axes = plt . axes(frameon = True ) nx . draw_networkx(G2, node_color = colors, \\ node_size = 600 , alpha =. 8 , ax = default_axes, pos = pos) draw_tsp_solution(G, best_order, colors, pos) order = (0, 1, 2) Distance = 231.0 Best order from brute force = (0, 1, 2) with total distance = 231.0 Mapping to the Ising problem qubitOp, offset = tsp . get_tsp_qubitops(ins) algo_input = EnergyInput(qubitOp) [Optional] Using DOcplex for mapping to the Ising problem Using docplex.get_qubitops is a different way to create an Ising Hamiltonian of TSP. docplex.get_qubitops can create a corresponding Ising Hamiltonian from an optimization model of TSP. An example of using docplex.get_qubitops is as below. # Create an instance of a model and variables mdl = Model(name = 'tsp' ) x = {(i,p): mdl . binary_var(name = 'x_{0}_{1}' . format(i,p)) \\ for i in range (n) for p in range (n)} # Object function tsp_func = mdl . sum(ins . w[i,j] * x[(i,p)] * x[(j,(p + 1 ) % n)] \\ for i in range (n) for j in range (n) for p in range (n)) mdl . minimize(tsp_func) # Constrains for i in range (n): mdl . add_constraint(mdl . sum(x[(i,p)] for p in range (n)) == 1 ) for p in range (n): mdl . add_constraint(mdl . sum(x[(i,p)] for i in range (n)) == 1 ) qubitOp_docplex, offset_docplex = docplex . get_qubitops(mdl) Checking that the full Hamiltonian gives the right cost # Making the Hamiltonian in its full form and getting # the lowest eigenvalue and eigenvector ee = ExactEigensolver(qubitOp, k = 1 ) result = ee . run() \"\"\" algorithm_cfg = { 'name': 'ExactEigensolver', } params = { 'problem': {'name': 'ising'}, 'algorithm': algorithm_cfg } result = run_algorithm(params,algo_input) \"\"\" print ( 'energy:' , result[ 'energy' ]) print ( 'tsp objective:' , result[ 'energy' ] + offset) x = tsp . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'feasible:' , tsp . tsp_feasible(x)) z = tsp . get_tsp_solution(x) print ( 'solution:' , z) print ( 'solution objective:' , tsp . tsp_value(z, ins . w)) draw_tsp_solution(G, z, colors, pos) energy: -600115.5 tsp objective: 231.0 feasible: True solution: [2, 1, 0] solution objective: 231.0 Running it on quantum computer We run the optimization routine using a feedback loop with a quantum computer that uses trial functions built with Y single-qubit rotations,\\(U_\\mathrm{single}(\\theta) = \\prod_{i=1}^n Y(\\theta_{i})\\), and entangler steps\\(U_\\mathrm{entangler}\\). seed = 10598 spsa = SPSA(max_trials = 300 ) ry = RY(qubitOp . num_qubits, depth = 5 , entanglement = 'linear' ) vqe = VQE(qubitOp, ry, spsa, 'matrix' ) backend = BasicAer . get_backend( 'statevector_simulator' ) quantum_instance = QuantumInstance(backend, \\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) \"\"\" algorithm_cfg = { 'name': 'VQE', 'operator_mode': 'matrix' } optimizer_cfg = { 'name': 'SPSA', 'max_trials': 300 } var_form_cfg = { 'name': 'RY', 'depth': 5, 'entanglement': 'linear' } params = { 'problem': {'name': 'ising', 'random_seed': seed}, 'algorithm': algorithm_cfg, 'optimizer': optimizer_cfg, 'variational_form': var_form_cfg, 'backend': {'provider': 'qiskit.BasicAer',\\ 'name': 'statevector_simulator'} } result = run_algorithm(parahms,algo_input) \"\"\" print ( 'energy:' , result[ 'energy' ]) print ( 'time:' , result[ 'eval_time' ]) #print('tsp objective:', result['energy'] + offset) x = tsp . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'feasible:' , tsp . tsp_feasible(x)) z = tsp . get_tsp_solution(x) print ( 'solution:' , z) print ( 'solution objective:' , tsp . tsp_value(z, ins . w)) draw_tsp_solution(G, z, colors, pos) energy: -590938.6460660461 time: 20.48488998413086 feasible: True solution: [2, 1, 0] solution objective: 231.0 # run quantum algorithm with shots seed = 10598 spsa = SPSA(max_trials = 300 ) ry = RY(qubitOp . num_qubits, depth = 5 , entanglement = 'linear' ) vqe = VQE(qubitOp, ry, spsa, 'grouped_paulis' ) backend = BasicAer . get_backend( 'qasm_simulator' ) quantum_instance = QuantumInstance(backend, shots = 1024 ,\\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) \"\"\"update params in the previous cell params['algorithm']['operator_mode'] = 'grouped_paulis' params['backend']['provider'] = 'qiskit.BasicAer' params['backend']['name'] = 'qasm_simulator' params['backend']['shots'] = 1024 result = run_algorithm(params,algo_input) \"\"\" print ( 'energy:' , result[ 'energy' ]) print ( 'time:' , result[ 'eval_time' ]) #print('tsp objective:', result['energy'] + offset) x = tsp . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'feasible:' , tsp . tsp_feasible(x)) z = tsp . get_tsp_solution(x) print ( 'solution:' , z) print ( 'solution objective:' , tsp . tsp_value(z, ins . w)) plot_histogram(result[ 'eigvecs' ][ 0 ]) draw_tsp_solution(G, z, colors, pos) [Optional] Checking that the full Hamiltonian made by docplex.get_qubitops gives the right cost ee = ExactEigensolver(qubitOp_docplex, k = 1 ) result = ee . run() print ( 'energy:' , result[ 'energy' ]) print ( 'tsp objective:' , result[ 'energy' ] + offset_docplex) x = docplex . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'feasible:' , tsp . tsp_feasible(x)) z = tsp . get_tsp_solution(x) print ( 'solution:' , z) print ( 'solution objective:' , tsp . tsp_value(z, ins . w)) draw_tsp_solution(G, z, colors, pos)","title":"Travelling Salsesman"},{"location":"optimization/salesman/salesman/#qiskit-aqua-variational-quantum-eigensolver","text":"Experimenting with Max-Cut problem and Traveling Salesman problem with variational quantum eigensolver The latest version of this notebook is available here .","title":"Qiskit Aqua: Variational Quantum Eigensolver"},{"location":"optimization/salesman/salesman/#contributors","text":"Antonio Mezzacapo [1] , Jay Gambetta [1] , Kristan Temme [1] , Ramis Movassagh [1] , Albert Frisch [1] , Takashi Imamichi [1] , Giacomo Nannicni [1] , Richard Chen [1] , Marco Pistoia [1] , Stephen Wood [1]","title":"Contributors"},{"location":"optimization/salesman/salesman/#affiliation","text":"[1] IBMQ","title":"Affiliation"},{"location":"optimization/salesman/salesman/#introduction","text":"Many problems in quantitative fields such as finance and engineering are optimization problems. Optimization problems lay at the core of complex decision-making and definition of strategies. Optimization (or combinatorial optimization) means searching for an optimal solution in a finite or countably infinite set of potential solutions. Optimality is defined with respect to some criterion function, which is to be minimized or maximized. This is typically called cost function or objective function. Typical optimization problems Minimization: cost, distance, length of a traversal, weight, processing time, material, energy consumption, number of objects Maximization: profit, value, output, return, yield, utility, efficiency, capacity, number of objects We consider here max-cut problem of practical interest in many fields, and show how they can mapped on quantum computers.","title":"Introduction"},{"location":"optimization/salesman/salesman/#weighted-max-cut","text":"Max-Cut is an NP-complete problem, with applications in clustering, network science, and statistical physics. To grasp how practical applications are mapped into given Max-Cut instances, consider a system of many people that can interact and influence each other. Individuals can be represented by vertices of a graph, and their interactions seen as pairwise connections between vertices of the graph, or edges. With this representation in mind, it is easy to model typical marketing problems. For example, suppose that it is assumed that individuals will influence each other's buying decisions, and knowledge is given about how strong they will influence each other. The influence can be modeled by weights assigned on each edge of the graph. It is possible then to predict the outcome of a marketing strategy in which products are offered for free to some individuals, and then ask which is the optimal subset of individuals that should get the free products, in order to maximize revenues. The formal definition of this problem is the following: Consider an \\(n\\)-node undirected graph G = (V, E) where |V| = n with edge weights \\(w_{ij}>0, w_{ij}=w_{ji}\\), for \\((i, j)\\in E\\). A cut is defined as a partition of the original set V into two subsets. The cost function to be optimized is in this case the sum of weights of edges connecting points in the two different subsets, crossing the cut. By assigning \\(x_i=0\\) or \\( x_i=1 \\) to each node \\(i\\), one tries to maximize the global profit function (here and in the following summations run over indices 0,1,...n-1) $$ \\tilde{C}(\\textbf{x}) = \\sum_{i,j} w_{ij} x_i (1-x_j). $$ In our simple marketing model, \\(w_{ij}\\) represents the probability that the person \\(j\\) will buy a product after \\(i\\) gets a free one. Note that the weights \\(w_{ij}\\) can in principle be greater than \\(1\\), corresponding to the case where the individual \\(j\\) will buy more than one product. Maximizing the total buying probability corresponds to maximizing the total future revenues. In the case where the profit probability will be greater than the cost of the initial free samples, the strategy is a convenient one. An extension to this model has the nodes themselves carry weights, which can be regarded, in our marketing model, as the likelihood that a person granted with a free sample of the product will buy it again in the future. With this additional information in our model, the objective function to maximize becomes $$ C(\\textbf{x}) = \\sum_{i,j} w_{ij} x_i (1-x_j)+\\sum_i w_i x_i.$$ In order to find a solution to this problem on a quantum computer, one needs first to map it to an Ising Hamiltonian. This can be done with the assignment \\(x_i\\rightarrow (1-Z_i)/2\\), where \\(Z_i\\) is the Pauli Z operator that has eigenvalues \\( \\pm 1 \\). Doing this we find that $$C(\\textbf{Z}) = \\sum_{i,j} \\frac{w_{ij}}{4} (1-Z_i)(1+Z_j) + \\sum_i \\frac{w_i}{2} (1-Z_i)$$ $$ = -\\frac{1}{2}\\left( \\sum_{i<j} w_{ij} Z_i Z_j +\\sum_i w_i Z_i\\right)+\\mathrm{const},$$ where const = \\(\\sum_{i<j}w_{ij}/2+\\sum_i w_i/2 \\). In other terms, the weighted Max-Cut problem is equivalent to minimizing the Ising Hamiltonian $$H = \\sum_i w_i Z_i + \\sum_{i<j} w_{ij} Z_iZ_j.$$ Aqua can generate the Ising Hamiltonian for the first profit function\\(\\tilde{C}$.","title":"Weighted Max-Cut"},{"location":"optimization/salesman/salesman/#approximate-universal-quantum-computing-for-optimization-problems","text":"There has been a considerable amount of interest in recent times about the use of quantum computers to find a solution to combinatorial problems. It is important to say that, given the classical nature of combinatorial problems, exponential speedup in using quantum computers compared to the best classical algorithms is not guaranteed. However, due to the nature and importance of the target problems, it is worth investigating heuristic approaches on a quantum computer that could indeed speed up some problem instances. Here we demonstrate an approach that is based on the Quantum Approximate Optimization Algorithm by Farhi, Goldstone, and Gutman (2014). We frame the algorithm in the context of approximate quantum computing , given its heuristic nature. The Algorithm works as follows: Choose the \\(w_i\\) and \\(w_{ij}\\) in the target Ising problem. In principle, even higher powers of Z are allowed. Choose the depth of the quantum circuit \\(m\\). Note that the depth can be modified adaptively. Choose a set of controls \\(\\theta\\) and make a trial function \\(|\\psi(\\boldsymbol\\theta)\\rangle\\), built using a quantum circuit made of C-Phase gates and single-qubit Y rotations, parameterized by the components of \\(\\boldsymbol\\theta\\). Evaluate $$ C(\\boldsymbol\\theta) = \\langle\\psi(\\boldsymbol\\theta)~|H|~\\psi(\\boldsymbol\\theta)\\rangle$$ $$ = \\sum_i w_i \\langle\\psi(\\boldsymbol\\theta)~|Z_i|~\\psi(\\boldsymbol\\theta)\\rangle+ \\sum_{i<j} w_{ij} \\langle\\psi(\\boldsymbol\\theta)~|Z_iZ_j|~\\psi(\\boldsymbol\\theta)\\rangle$$ by sampling the outcome of the circuit in the Z-basis and adding the expectation values of the individual Ising terms together. In general, different control points around \\(\\boldsymbol\\theta\\) have to be estimated, depending on the classical optimizer chosen. Use a classical optimizer to choose a new set of controls. Continue until \\(C(\\boldsymbol\\theta)\\) reaches a minimum, close enough to the solution \\(\\boldsymbol\\theta^*\\). Use the last \\(\\boldsymbol\\theta\\) to generate a final set of samples from the distribution \\(|\\langle z_i~|\\psi(\\boldsymbol\\theta)\\rangle|^2\\;\\forall i\\) to obtain the answer. It is our belief the difficulty of finding good heuristic algorithms will come down to the choice of an appropriate trial wavefunction. For example, one could consider a trial function whose entanglement best aligns with the target problem, or simply make the amount of entanglement a variable. In this tutorial, we will consider a simple trial function of the form $$|\\psi(\\theta)\\rangle = [U_\\mathrm{single}(\\boldsymbol\\theta) U_\\mathrm{entangler}]^m |+\\rangle$$ where\\(U_\\mathrm{entangler}\\)is a collection of C-Phase gates (fully entangling gates), and\\(U_\\mathrm{single}(\\theta) = \\prod_{i=1}^n Y(\\theta_{i})\\), where\\(n\\)is the number of qubits and\\(m\\)is the depth of the quantum circuit. The motivation for this choice is that for these classical problems this choice allows us to search over the space of quantum states that have only real coefficients, still exploiting the entanglement to potentially converge faster to the solution. One advantage of using this sampling method compared to adiabatic approaches is that the target Ising Hamiltonian does not have to be implemented directly on hardware, allowing this algorithm not to be limited to the connectivity of the device. Furthermore, higher-order terms in the cost function, such as\\(Z_iZ_jZ_k\\), can also be sampled efficiently, whereas in adiabatic or annealing approaches they are generally impractical to deal with. References: A. Lucas, Frontiers in Physics 2, 5 (2014) E. Farhi, J. Goldstone, S. Gutmann e-print arXiv 1411.4028 (2014) D. Wecker, M. B. Hastings, M. Troyer Phys. Rev. A 94, 022309 (2016) E. Farhi, J. Goldstone, S. Gutmann, H. Neven e-print arXiv 1703.06199 (2017) # useful additional packages import matplotlib.pyplot as plt import matplotlib.axes as axes % matplotlib inline import numpy as np import networkx as nx from qiskit import BasicAer from qiskit.tools.visualization import plot_histogram from qiskit.aqua import Operator, run_algorithm from qiskit.aqua.input import EnergyInput from qiskit.aqua.translators.ising import max_cut, tsp from qiskit.aqua.algorithms import VQE, ExactEigensolver from qiskit.aqua.components.optimizers import SPSA from qiskit.aqua.components.variational_forms import RY from qiskit.aqua import QuantumInstance # setup aqua logging import logging from qiskit.aqua import set_qiskit_aqua_logging # set_qiskit_aqua_logging(logging.DEBUG) # choose INFO, DEBUG to see the log","title":"Approximate Universal Quantum Computing for Optimization Problems"},{"location":"optimization/salesman/salesman/#optional-setup-token-to-run-the-experiment-on-a-real-device","text":"If you would like to run the experiement on a real device, you need to setup your account first. Note: If you do not store your token yet, use IBMQ.save_accounts() to store it first. from qiskit import IBMQ # IBMQ.load_accounts()","title":"[Optional] Setup token to run the experiment on a real device"},{"location":"optimization/salesman/salesman/#max-cut-problem","text":"","title":"Max-Cut problem"},{"location":"optimization/salesman/salesman/#generating-a-graph-of-4-nodes","text":"n = 4 # Number of nodes in graph G = nx . Graph() G . add_nodes_from(np . arange( 0 ,n, 1 )) elist = [( 0 , 1 , 1.0 ),( 0 , 2 , 1.0 ),( 0 , 3 , 1.0 ),( 1 , 2 , 1.0 ),( 2 , 3 , 1.0 )] # tuple is (i,j,weight) where (i,j) is the edge G . add_weighted_edges_from(elist) colors = [ 'r' for node in G . nodes()] pos = nx . spring_layout(G) default_axes = plt . axes(frameon = True ) nx . draw_networkx(G, node_color = colors, node_size = 600 , alpha =. 8 , ax = default_axes, pos = pos)","title":"Generating a graph of 4 nodes"},{"location":"optimization/salesman/salesman/#computing-the-weight-matrix-from-the-random-graph","text":"w = np . zeros([n,n]) for i in range (n): for j in range (n): temp = G . get_edge_data(i,j,default = 0 ) if temp != 0 : w[i,j] = temp[ 'weight' ] print (w) [[0. 1. 1. 1.] [1. 0. 1. 0.] [1. 1. 0. 1.] [1. 0. 1. 0.]]","title":"Computing the weight matrix from the random graph"},{"location":"optimization/salesman/salesman/#brute-force-approach","text":"Try all possible\\(2^n\\)combinations. For\\(n = 4\\), as in this example, one deals with only 16 combinations, but for n = 1000, one has 1.071509e+30 combinations, which is impractical to deal with by using a brute force approach. best_cost_brute = 0 for b in range ( 2 ** n): x = [ int (t) for t in reversed ( list ( bin (b)[ 2 :] . zfill(n)))] cost = 0 for i in range (n): for j in range (n): cost = cost + w[i,j] * x[i] * ( 1 - x[j]) if best_cost_brute < cost: best_cost_brute = cost xbest_brute = x print ( 'case = ' + str (x) + ' cost = ' + str (cost)) colors = [ 'r' if xbest_brute[i] == 0 else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors,\\ node_size = 600 , alpha =. 8 , pos = pos) print ( ' \\n Best solution = ' + str (xbest_brute) + \\ ' cost = ' + str (best_cost_brute)) case = [0, 0, 0, 0] cost = 0.0 case = [1, 0, 0, 0] cost = 3.0 case = [0, 1, 0, 0] cost = 2.0 case = [1, 1, 0, 0] cost = 3.0 case = [0, 0, 1, 0] cost = 3.0 case = [1, 0, 1, 0] cost = 4.0 case = [0, 1, 1, 0] cost = 3.0 case = [1, 1, 1, 0] cost = 2.0 case = [0, 0, 0, 1] cost = 2.0 case = [1, 0, 0, 1] cost = 3.0 case = [0, 1, 0, 1] cost = 4.0 case = [1, 1, 0, 1] cost = 3.0 case = [0, 0, 1, 1] cost = 3.0 case = [1, 0, 1, 1] cost = 2.0 case = [0, 1, 1, 1] cost = 3.0 case = [1, 1, 1, 1] cost = 0.0 Best solution = [1, 0, 1, 0] cost = 4.0","title":"Brute force approach"},{"location":"optimization/salesman/salesman/#mapping-to-the-ising-problem","text":"qubitOp, offset = max_cut . get_max_cut_qubitops(w) algo_input = EnergyInput(qubitOp)","title":"Mapping to the Ising problem"},{"location":"optimization/salesman/salesman/#optional-using-docplex-for-mapping-to-the-ising-problem","text":"Using docplex.get_qubitops is a different way to create an Ising Hamiltonian of Max-Cut. docplex.get_qubitops can create a corresponding Ising Hamiltonian from an optimization model of Max-Cut. An example of using docplex.get_qubitops is as below. from docplex.mp.model import Model from qiskit.aqua.translators.ising import docplex # Create an instance of a model and variables. mdl = Model(name = 'max_cut' ) x = {i: mdl . binary_var(name = 'x_{0}' . format(i)) for i in range (n)} # Object function max_cut_func = mdl . sum(w[i,j] * x[i] * ( 1 - x[j] )\\ for i in range (n) for j in range (n)) mdl . maximize(max_cut_func) # No constraints for Max-Cut problems. qubitOp_docplex, offset_docplex = docplex . get_qubitops(mdl)","title":"[Optional] Using DOcplex for mapping to the Ising problem"},{"location":"optimization/salesman/salesman/#checking-that-the-full-hamiltonian-gives-the-right-cost","text":"# Making the Hamiltonian in its full form and # getting the lowest eigenvalue and eigenvector ee = ExactEigensolver(qubitOp, k = 1 ) result = ee . run() \"\"\" algorithm_cfg = { 'name': 'ExactEigensolver', } params = { 'problem': {'name': 'ising'}, 'algorithm': algorithm_cfg } result = run_algorithm(params,algo_input) \"\"\" x = max_cut . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'energy:' , result[ 'energy' ]) print ( 'max-cut objective:' , result[ 'energy' ] + offset) print ( 'solution:' , max_cut . get_graph_solution(x)) print ( 'solution objective:' , max_cut . max_cut_value(x, w)) colors = [ 'r' if max_cut . get_graph_solution(x)[i] == 0 \\ else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors, \\ node_size = 600 , alpha = . 8 , pos = pos) energy: -1.5 max-cut objective: -4.0 solution: [0. 1. 0. 1.] solution objective: 4.0","title":"Checking that the full Hamiltonian gives the right cost"},{"location":"optimization/salesman/salesman/#running-it-on-quantum-computer","text":"We run the optimization routine using a feedback loop with a quantum computer that uses trial functions built with Y single-qubit rotations,\\(U_\\mathrm{single}(\\theta) = \\prod_{i=1}^n Y(\\theta_{i})\\), and entangler steps\\(U_\\mathrm{entangler}\\). seed = 10598 spsa = SPSA(max_trials = 300 ) ry = RY(qubitOp . num_qubits, depth = 5 , entanglement = 'linear' ) vqe = VQE(qubitOp, ry, spsa, 'matrix' ) backend = BasicAer . get_backend( 'statevector_simulator' ) quantum_instance = QuantumInstance(backend, \\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) \"\"\"declarative approach algorithm_cfg = { 'name': 'VQE', 'operator_mode': 'matrix' } optimizer_cfg = { 'name': 'SPSA', 'max_trials': 300 } var_form_cfg = { 'name': 'RY', 'depth': 5, 'entanglement': 'linear' } params = { 'problem': {'name': 'ising', 'random_seed': seed}, 'algorithm': algorithm_cfg, 'optimizer': optimizer_cfg, 'variational_form': var_form_cfg, 'backend': {provider': 'qiskit.BasicAer',\\ 'name': 'statevector_simulator'} } result = run_algorithm(params, algo_input) \"\"\" x = max_cut . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'energy:' , result[ 'energy' ]) print ( 'time:' , result[ 'eval_time' ]) print ( 'max-cut objective:' , result[ 'energy' ] + offset) print ( 'solution:' , max_cut . get_graph_solution(x)) print ( 'solution objective:' , max_cut . max_cut_value(x, w)) colors = [ 'r' if max_cut . get_graph_solution(x)[i] == 0 \\ else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors,\\ node_size = 600 , alpha = . 8 , pos = pos) energy: -1.4999760821185284 time: 7.753880739212036 max-cut objective: -3.999976082118528 solution: [1. 0. 1. 0.] solution objective: 4.0","title":"Running it on quantum computer"},{"location":"optimization/salesman/salesman/#run-quantum-algorithm-with-shots","text":"seed = 10598 spsa = SPSA(max_trials = 300 ) ry = RY(qubitOp . num_qubits, depth = 5 , entanglement = 'linear' ) vqe = VQE(qubitOp, ry, spsa, 'grouped_paulis' ) backend = BasicAer . get_backend( 'qasm_simulator' ) quantum_instance = QuantumInstance(backend, shots = 1024 ,\\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) \"\"\"declarative approach, update the param from the previous cell. params['algorithm']['operator_mode'] = 'grouped_paulis' params['backend']['provider'] = 'qiskit.BasicAer' params['backend']['name'] = 'qasm_simulator' params['backend']['shots'] = 1024 result = run_algorithm(params, algo_input) \"\"\" x = max_cut . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'energy:' , result[ 'energy' ]) print ( 'time:' , result[ 'eval_time' ]) print ( 'max-cut objective:' , result[ 'energy' ] + offset) print ( 'solution:' , max_cut . get_graph_solution(x)) print ( 'solution objective:' , max_cut . max_cut_value(x, w)) plot_histogram(result[ 'eigvecs' ][ 0 ]) colors = [ 'r' if max_cut . get_graph_solution(x)[i] == 0 \\ else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors, node_size = 600 ,\\ alpha = . 8 , pos = pos) energy: -1.5 time: 15.852537155151367 max-cut objective: -4.0 solution: [1 0 1 0] solution objective: 4.0","title":"Run quantum algorithm with shots"},{"location":"optimization/salesman/salesman/#optional-checking-that-the-full-hamiltonian-made-by-docplexget_qubitops-gives-the-right-cost","text":"# Making the Hamiltonian in its full form and getting # the lowest eigenvalue and eigenvector ee = ExactEigensolver(qubitOp_docplex, k = 1 ) result = ee . run() x = docplex . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'energy:' , result[ 'energy' ]) print ( 'max-cut objective:' , result[ 'energy' ] + offset_docplex) print ( 'solution:' , max_cut . get_graph_solution(x)) print ( 'solution objective:' , max_cut . max_cut_value(x, w)) colors = [ 'r' if max_cut . get_graph_solution(x)[i] == 0 \\ else 'b' for i in range (n)] nx . draw_networkx(G, node_color = colors, \\ node_size = 600 , alpha = . 8 , pos = pos) energy: -1.5 max-cut objective: -4.0 solution: [0. 1. 0. 1.] solution objective: 4.0","title":"[Optional] Checking that the full Hamiltonian made by docplex.get_qubitops  gives the right cost"},{"location":"optimization/salesman/salesman/#traveling-salesman-problem","text":"In addition to being a notorious NP-complete problem that has drawn the attention of computer scientists and mathematicians for over two centuries, the Traveling Salesman Problem (TSP) has important bearings on finance and marketing, as its name suggests. Colloquially speaking, the traveling salesman is a person that goes from city to city to sell merchandise. The objective in this case is to find the shortest path that would enable the salesman to visit all the cities and return to its hometown, i.e. the city where he started traveling. By doing this, the salesman gets to maximize potential sales in the least amount of time. The problem derives its importance from its \"hardness\" and ubiquitous equivalence to other relevant combinatorial optimization problems that arise in practice. The mathematical formulation with some early analysis was proposed by W.R. Hamilton in the early 19th century. Mathematically the problem is, as in the case of Max-Cut, best abstracted in terms of graphs. The TSP on the nodes of a graph asks for the shortest Hamiltonian cycle that can be taken through each of the nodes. A Hamilton cycle is a closed path that uses every vertex of a graph once. The general solution is unknown and an algorithm that finds it efficiently (e.g., in polynomial time) is not expected to exist. Find the shortest Hamiltonian cycle in a graph \\(G=(V,E)\\)with\\(n=|V|\\) nodes and distances,\\(w_{ij}\\) (distance from vertex \\(i\\)to vertex\\(j\\). A Hamiltonian cycle is described by \\(N^2\\)variables\\(x_{i,p}\\), where\\(i\\)represents the node and\\(p\\)represents its order in a prospective cycle. The decision variable takes the value 1 if the solution occurs at node\\(i\\)at time order\\(p\\). We require that every node can only appear once in the cycle, and for each time a node has to occur. This amounts to the two constraints (here and in the following, whenever not specified, the summands run over 0,1,...N-1) $$\\sum_{i} x_{i,p} = 1 ~~\\forall p$$ $$\\sum_{p} x_{i,p} = 1 ~~\\forall i.$$ For nodes in our prospective ordering, if\\(x_{i,p}\\)and\\(x_{j,p+1}\\)are both 1, then there should be an energy penalty if\\((i,j) \\notin E\\)(not connected in the graph). The form of this penalty is $$\\sum_{i,j\\notin E}\\sum_{p} x_{i,p}x_{j,p+1}>0,$$ where it is assumed the boundary condition of the Hamiltonian cycle\\((p=N)\\equiv (p=0)\\). However, here it will be assumed a fully connected graph and not include this term. The distance that needs to be minimized is $$C(\\textbf{x})=\\sum_{i,j}w_{ij}\\sum_{p} x_{i,p}x_{j,p+1}.$$ Putting this all together in a single objective function to be minimized, we get the following: $$C(\\textbf{x})=\\sum_{i,j}w_{ij}\\sum_{p} x_{i,p}x_{j,p+1}+ A\\sum_p\\left(1- \\sum_i x_{i,p}\\right)^2+A\\sum_i\\left(1- \\sum_p x_{i,p}\\right)^2,$$ where\\(A\\)is a free parameter. One needs to ensure that\\(A\\)is large enough so that these constraints are respected. One way to do this is to choose\\(A\\)such that\\(A > \\mathrm{max}(w_{ij})\\). Once again, it is easy to map the problem in this form to a quantum computer, and the solution will be found by minimizing a Ising Hamiltonian. # Generating a graph of 3 nodes n = 3 num_qubits = n ** 2 ins = tsp . random_tsp(n) G = nx . Graph() G . add_nodes_from(np . arange( 0 , n, 1 )) colors = [ 'r' for node in G . nodes()] pos = {k: v for k, v in enumerate (ins . coord)} default_axes = plt . axes(frameon = True ) nx . draw_networkx(G, node_color = colors, node_size = 600 , alpha =. 8 , ax = default_axes, pos = pos) print ( 'distance \\n ' , ins . w) distance [[ 0. 51. 81.] [51. 0. 99.] [81. 99. 0.]]","title":"Traveling Salesman Problem"},{"location":"optimization/salesman/salesman/#brute-force-approach_1","text":"from itertools import permutations def brute_force_tsp (w, N): a = list (permutations( range ( 1 ,N))) last_best_distance = 1e10 for i in a: distance = 0 pre_j = 0 for j in i: distance = distance + w[j,pre_j] pre_j = j distance = distance + w[pre_j, 0 ] order = ( 0 ,) + i if distance < last_best_distance: best_order = order last_best_distance = distance print ( 'order = ' + str (order) + \\ ' Distance = ' + str (distance)) return last_best_distance, best_order best_distance, best_order = brute_force_tsp(ins . w, ins . dim) print ( 'Best order from brute force = ' + str (best_order) + \\ ' with total distance = ' + str (best_distance)) def draw_tsp_solution (G, order, colors, pos): G2 = G . copy() n = len (order) for i in range (n): j = (i + 1 ) % n G2 . add_edge(order[i], order[j]) default_axes = plt . axes(frameon = True ) nx . draw_networkx(G2, node_color = colors, \\ node_size = 600 , alpha =. 8 , ax = default_axes, pos = pos) draw_tsp_solution(G, best_order, colors, pos) order = (0, 1, 2) Distance = 231.0 Best order from brute force = (0, 1, 2) with total distance = 231.0","title":"Brute force approach"},{"location":"optimization/salesman/salesman/#mapping-to-the-ising-problem_1","text":"qubitOp, offset = tsp . get_tsp_qubitops(ins) algo_input = EnergyInput(qubitOp)","title":"Mapping to the Ising problem"},{"location":"optimization/salesman/salesman/#optional-using-docplex-for-mapping-to-the-ising-problem_1","text":"Using docplex.get_qubitops is a different way to create an Ising Hamiltonian of TSP. docplex.get_qubitops can create a corresponding Ising Hamiltonian from an optimization model of TSP. An example of using docplex.get_qubitops is as below. # Create an instance of a model and variables mdl = Model(name = 'tsp' ) x = {(i,p): mdl . binary_var(name = 'x_{0}_{1}' . format(i,p)) \\ for i in range (n) for p in range (n)} # Object function tsp_func = mdl . sum(ins . w[i,j] * x[(i,p)] * x[(j,(p + 1 ) % n)] \\ for i in range (n) for j in range (n) for p in range (n)) mdl . minimize(tsp_func) # Constrains for i in range (n): mdl . add_constraint(mdl . sum(x[(i,p)] for p in range (n)) == 1 ) for p in range (n): mdl . add_constraint(mdl . sum(x[(i,p)] for i in range (n)) == 1 ) qubitOp_docplex, offset_docplex = docplex . get_qubitops(mdl)","title":"[Optional] Using DOcplex for mapping to the Ising problem"},{"location":"optimization/salesman/salesman/#checking-that-the-full-hamiltonian-gives-the-right-cost_1","text":"# Making the Hamiltonian in its full form and getting # the lowest eigenvalue and eigenvector ee = ExactEigensolver(qubitOp, k = 1 ) result = ee . run() \"\"\" algorithm_cfg = { 'name': 'ExactEigensolver', } params = { 'problem': {'name': 'ising'}, 'algorithm': algorithm_cfg } result = run_algorithm(params,algo_input) \"\"\" print ( 'energy:' , result[ 'energy' ]) print ( 'tsp objective:' , result[ 'energy' ] + offset) x = tsp . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'feasible:' , tsp . tsp_feasible(x)) z = tsp . get_tsp_solution(x) print ( 'solution:' , z) print ( 'solution objective:' , tsp . tsp_value(z, ins . w)) draw_tsp_solution(G, z, colors, pos) energy: -600115.5 tsp objective: 231.0 feasible: True solution: [2, 1, 0] solution objective: 231.0","title":"Checking that the full Hamiltonian gives the right cost"},{"location":"optimization/salesman/salesman/#running-it-on-quantum-computer_1","text":"We run the optimization routine using a feedback loop with a quantum computer that uses trial functions built with Y single-qubit rotations,\\(U_\\mathrm{single}(\\theta) = \\prod_{i=1}^n Y(\\theta_{i})\\), and entangler steps\\(U_\\mathrm{entangler}\\). seed = 10598 spsa = SPSA(max_trials = 300 ) ry = RY(qubitOp . num_qubits, depth = 5 , entanglement = 'linear' ) vqe = VQE(qubitOp, ry, spsa, 'matrix' ) backend = BasicAer . get_backend( 'statevector_simulator' ) quantum_instance = QuantumInstance(backend, \\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) \"\"\" algorithm_cfg = { 'name': 'VQE', 'operator_mode': 'matrix' } optimizer_cfg = { 'name': 'SPSA', 'max_trials': 300 } var_form_cfg = { 'name': 'RY', 'depth': 5, 'entanglement': 'linear' } params = { 'problem': {'name': 'ising', 'random_seed': seed}, 'algorithm': algorithm_cfg, 'optimizer': optimizer_cfg, 'variational_form': var_form_cfg, 'backend': {'provider': 'qiskit.BasicAer',\\ 'name': 'statevector_simulator'} } result = run_algorithm(parahms,algo_input) \"\"\" print ( 'energy:' , result[ 'energy' ]) print ( 'time:' , result[ 'eval_time' ]) #print('tsp objective:', result['energy'] + offset) x = tsp . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'feasible:' , tsp . tsp_feasible(x)) z = tsp . get_tsp_solution(x) print ( 'solution:' , z) print ( 'solution objective:' , tsp . tsp_value(z, ins . w)) draw_tsp_solution(G, z, colors, pos) energy: -590938.6460660461 time: 20.48488998413086 feasible: True solution: [2, 1, 0] solution objective: 231.0 # run quantum algorithm with shots seed = 10598 spsa = SPSA(max_trials = 300 ) ry = RY(qubitOp . num_qubits, depth = 5 , entanglement = 'linear' ) vqe = VQE(qubitOp, ry, spsa, 'grouped_paulis' ) backend = BasicAer . get_backend( 'qasm_simulator' ) quantum_instance = QuantumInstance(backend, shots = 1024 ,\\ seed = seed, seed_transpiler = seed) result = vqe . run(quantum_instance) \"\"\"update params in the previous cell params['algorithm']['operator_mode'] = 'grouped_paulis' params['backend']['provider'] = 'qiskit.BasicAer' params['backend']['name'] = 'qasm_simulator' params['backend']['shots'] = 1024 result = run_algorithm(params,algo_input) \"\"\" print ( 'energy:' , result[ 'energy' ]) print ( 'time:' , result[ 'eval_time' ]) #print('tsp objective:', result['energy'] + offset) x = tsp . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'feasible:' , tsp . tsp_feasible(x)) z = tsp . get_tsp_solution(x) print ( 'solution:' , z) print ( 'solution objective:' , tsp . tsp_value(z, ins . w)) plot_histogram(result[ 'eigvecs' ][ 0 ]) draw_tsp_solution(G, z, colors, pos)","title":"Running it on quantum computer"},{"location":"optimization/salesman/salesman/#optional-checking-that-the-full-hamiltonian-made-by-docplexget_qubitops-gives-the-right-cost_1","text":"ee = ExactEigensolver(qubitOp_docplex, k = 1 ) result = ee . run() print ( 'energy:' , result[ 'energy' ]) print ( 'tsp objective:' , result[ 'energy' ] + offset_docplex) x = docplex . sample_most_likely(result[ 'eigvecs' ][ 0 ]) print ( 'feasible:' , tsp . tsp_feasible(x)) z = tsp . get_tsp_solution(x) print ( 'solution:' , z) print ( 'solution objective:' , tsp . tsp_value(z, ins . w)) draw_tsp_solution(G, z, colors, pos)","title":"[Optional] Checking that the full Hamiltonian made by docplex.get_qubitops  gives the right cost"},{"location":"qml/qsvm/qsvm/","text":"Qiskit Aqua: Quantum Support Vector Machine Experiment with classification problem with quantum-enhanced support vector machines The latest version of this notebook is available here . Contributors Vojtech Havlicek [1] , Kristan Temme [1] , Antonio C\u00f3rcoles [1] , Peng Liu [1] , Richard Chen [1] , Marco Pistoia [1] and Jay Gambetta [1] Affiliation [1] IBMQ Introduction Classification algorithms and methods for machine learning are essential for pattern recognition and data mining applications. Well known techniques such as support vector machines and neural networks have blossomed over the last two decades as a result of the spectacular advances in classical hardware computational capabilities and speed. This progress in computer power made it possible to apply techniques, that were theoretically developed towards the middle of the 20th century, on classification problems that were becoming increasingly challenging. A key concept in classification methods is that of a kernel. Data cannot typically be separated by a hyperplane in its original space. A common technique used to find such a hyperplane consists on applying a non-linear transformation function to the data. This function is called a feature map, as it transforms the raw features, or measurable properties, of the phenomenon or subject under study. Classifying in this new feature space -and, as a matter of fact, also in any other space, including the raw original one- is nothing more than seeing how close data points are to each other. This is the same as computing the inner product for each pair of data in the set. So, in fact we do not need to compute the non-linear feature map for each datum, but only the inner product of each pair of data points in the new feature space. This collection of inner products is called the kernel and it is perfectly possible to have feature maps that are hard to compute but whose kernels are not. In this notebook we provide an example of a classification problem that requires a feature map for which computing the kernel is not efficient classically -this means that the required computational resources are expected to scale exponentially with the size of the problem. We show how this can be solved in a quantum processor by a direct estimation of the kernel in the feature space. The method we used falls in the category of what is called supervised learning, consisting of a training phase (where the kernel is calculated and the support vectors obtained) and a test or classification phase (where new unlabelled data is classified according to the solution found in the training phase). References and additional details: [1] Vojtech Havlicek, Antonio D. C\u00b4orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta1, \"Supervised learning with quantum enhanced feature spaces,\" arXiv: 1804.11326 from datasets import * from qiskit import BasicAer from qiskit.aqua.utils import split_dataset_to_data_and_labels from qiskit.aqua.utils import map_label_to_class_name from qiskit.aqua.input import ClassificationInput from qiskit.aqua import run_algorithm, QuantumInstance from qiskit.aqua.algorithms import QSVM from qiskit.aqua.components.feature_maps import SecondOrderExpansion # setup aqua logging import logging from qiskit.aqua import set_qiskit_aqua_logging # set_qiskit_aqua_logging(logging.DEBUG) # choose INFO, DEBUG to see the log [Optional] Setup token to run the experiment on a real device If you would like to run the experiement on a real device, you need to setup your account first. Note: If you do not store your token yet, use IBMQ.save_accounts() to store it first. # from qiskit import IBMQ # IBMQ.load_accounts() First we prepare the dataset, which is used for training, testing and the finally prediction. Note: You can easily switch to a different dataset, such as the Breast Cancer dataset, by replacing 'ad_hoc_data' to 'Breast_cancer' below. feature_dim = 2 # we support feature_dim 2 or 3 sample_Total, training_input, test_input, class_labels = ad_hoc_data( training_size = 20 , test_size = 10 , n = feature_dim, gap = 0.3 , PLOT_DATA = True ) extra_test_data = sample_ad_hoc_data(sample_Total, 10 , n = feature_dim) datapoints, class_to_label = \\ split_dataset_to_data_and_labels(extra_test_data) print (class_to_label) {'A': 0, 'B': 1} With the dataset ready we initialize the necessary inputs for the algorithm: - the input dictionary (params) - the input object containing the dataset info (algo_input). With everything setup, we can now run the algorithm. For the testing, the result includes the details and the success ratio. For the prediction, the result includes the predicted labels. seed = 10598 feature_map = SecondOrderExpansion(feature_dimension = feature_dim,\\ depth = 2 ,\\ entanglement = 'linear' ) qsvm = QSVM(feature_map, training_input, test_input, datapoints[ 0 ]) backend = BasicAer . get_backend( 'qasm_simulator' ) quantum_instance = QuantumInstance(backend, shots = 1024 ,\\ seed = seed, seed_transpiler = seed) result = qsvm . run(quantum_instance) \"\"\"declarative approach params = { 'problem': {'name': 'classification', 'random_seed': 10598}, 'algorithm': { 'name': 'QSVM' }, 'backend': {'provider': 'qiskit.BasicAer',\\ 'name': 'qasm_simulator', 'shots': 1024}, 'feature_map': {'name': 'SecondOrderExpansion', \\ 'depth': 2, 'entanglement': 'linear'} } algo_input = ClassificationInput(training_input, \\ test_input, datapoints[0]) result = run_algorithm(params, algo_input) \"\"\" print ( \"testing success ratio: {}\" . format(result[ 'testing_accuracy' ])) print ( \"preduction of datapoints:\" ) print ( \"ground truth: {}\" . format(map_label_to_class_name(datapoints[ 1 ],\\ qsvm . label_to_class))) print ( \"prediction: {}\" . format(result[ 'predicted_classes' ])) testing success ratio: 1.0 preduction of datapoints: ground truth: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A',\\ 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B'] prediction: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', \\ 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B'] print ( \"kernel matrix during the training:\" ) kernel_matrix = result[ 'kernel_matrix_training' ] img = plt . imshow(np . asmatrix(kernel_matrix),interpolation = 'nearest' ,\\ origin = 'upper' ,cmap = 'bone_r' ) plt . show() kernel matrix during the training: The breast cancer dataset Now we run our algorithm with the real-world dataset: the breast cancer dataset, we use the first two principal components as features. sample_Total, training_input, test_input, class_labels = Breast_cancer( training_size = 20 , test_size = 10 , n = 2 , PLOT_DATA = True ) seed = 10598 feature_map = SecondOrderExpansion(feature_dimension = feature_dim,\\ depth = 2 , entanglement = 'linear' ) qsvm = QSVM(feature_map, training_input, test_input) backend = BasicAer . get_backend( 'qasm_simulator' ) quantum_instance = QuantumInstance(backend, shots = 1024 , \\ seed = seed, seed_transpiler = seed) result = qsvm . run(quantum_instance) \"\"\"declarative approach, re-use the params above algo_input = ClassificationInput(training_input, test_input) result = run_algorithm(params, algo_input) \"\"\" print ( \"testing success ratio: \" , result[ 'testing_accuracy' ]) testing success ratio: 0.8 print ( \"kernel matrix during the training:\" ) kernel_matrix = result[ 'kernel_matrix_training' ] img = plt . imshow(np . asmatrix(kernel_matrix),interpolation = 'nearest' ,\\ origin = 'upper' ,cmap = 'bone_r' ) plt . show() kernel matrix during the training:","title":"Quantum SVM"},{"location":"qml/qsvm/qsvm/#qiskit-aqua-quantum-support-vector-machine","text":"Experiment with classification problem with quantum-enhanced support vector machines The latest version of this notebook is available here .","title":"Qiskit Aqua: Quantum Support Vector Machine"},{"location":"qml/qsvm/qsvm/#contributors","text":"Vojtech Havlicek [1] , Kristan Temme [1] , Antonio C\u00f3rcoles [1] , Peng Liu [1] , Richard Chen [1] , Marco Pistoia [1] and Jay Gambetta [1]","title":"Contributors"},{"location":"qml/qsvm/qsvm/#affiliation","text":"[1] IBMQ","title":"Affiliation"},{"location":"qml/qsvm/qsvm/#introduction","text":"Classification algorithms and methods for machine learning are essential for pattern recognition and data mining applications. Well known techniques such as support vector machines and neural networks have blossomed over the last two decades as a result of the spectacular advances in classical hardware computational capabilities and speed. This progress in computer power made it possible to apply techniques, that were theoretically developed towards the middle of the 20th century, on classification problems that were becoming increasingly challenging. A key concept in classification methods is that of a kernel. Data cannot typically be separated by a hyperplane in its original space. A common technique used to find such a hyperplane consists on applying a non-linear transformation function to the data. This function is called a feature map, as it transforms the raw features, or measurable properties, of the phenomenon or subject under study. Classifying in this new feature space -and, as a matter of fact, also in any other space, including the raw original one- is nothing more than seeing how close data points are to each other. This is the same as computing the inner product for each pair of data in the set. So, in fact we do not need to compute the non-linear feature map for each datum, but only the inner product of each pair of data points in the new feature space. This collection of inner products is called the kernel and it is perfectly possible to have feature maps that are hard to compute but whose kernels are not. In this notebook we provide an example of a classification problem that requires a feature map for which computing the kernel is not efficient classically -this means that the required computational resources are expected to scale exponentially with the size of the problem. We show how this can be solved in a quantum processor by a direct estimation of the kernel in the feature space. The method we used falls in the category of what is called supervised learning, consisting of a training phase (where the kernel is calculated and the support vectors obtained) and a test or classification phase (where new unlabelled data is classified according to the solution found in the training phase). References and additional details: [1] Vojtech Havlicek, Antonio D. C\u00b4orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta1, \"Supervised learning with quantum enhanced feature spaces,\" arXiv: 1804.11326 from datasets import * from qiskit import BasicAer from qiskit.aqua.utils import split_dataset_to_data_and_labels from qiskit.aqua.utils import map_label_to_class_name from qiskit.aqua.input import ClassificationInput from qiskit.aqua import run_algorithm, QuantumInstance from qiskit.aqua.algorithms import QSVM from qiskit.aqua.components.feature_maps import SecondOrderExpansion # setup aqua logging import logging from qiskit.aqua import set_qiskit_aqua_logging # set_qiskit_aqua_logging(logging.DEBUG) # choose INFO, DEBUG to see the log","title":"Introduction"},{"location":"qml/qsvm/qsvm/#optional-setup-token-to-run-the-experiment-on-a-real-device","text":"If you would like to run the experiement on a real device, you need to setup your account first. Note: If you do not store your token yet, use IBMQ.save_accounts() to store it first. # from qiskit import IBMQ # IBMQ.load_accounts() First we prepare the dataset, which is used for training, testing and the finally prediction. Note: You can easily switch to a different dataset, such as the Breast Cancer dataset, by replacing 'ad_hoc_data' to 'Breast_cancer' below. feature_dim = 2 # we support feature_dim 2 or 3 sample_Total, training_input, test_input, class_labels = ad_hoc_data( training_size = 20 , test_size = 10 , n = feature_dim, gap = 0.3 , PLOT_DATA = True ) extra_test_data = sample_ad_hoc_data(sample_Total, 10 , n = feature_dim) datapoints, class_to_label = \\ split_dataset_to_data_and_labels(extra_test_data) print (class_to_label) {'A': 0, 'B': 1} With the dataset ready we initialize the necessary inputs for the algorithm: - the input dictionary (params) - the input object containing the dataset info (algo_input). With everything setup, we can now run the algorithm. For the testing, the result includes the details and the success ratio. For the prediction, the result includes the predicted labels. seed = 10598 feature_map = SecondOrderExpansion(feature_dimension = feature_dim,\\ depth = 2 ,\\ entanglement = 'linear' ) qsvm = QSVM(feature_map, training_input, test_input, datapoints[ 0 ]) backend = BasicAer . get_backend( 'qasm_simulator' ) quantum_instance = QuantumInstance(backend, shots = 1024 ,\\ seed = seed, seed_transpiler = seed) result = qsvm . run(quantum_instance) \"\"\"declarative approach params = { 'problem': {'name': 'classification', 'random_seed': 10598}, 'algorithm': { 'name': 'QSVM' }, 'backend': {'provider': 'qiskit.BasicAer',\\ 'name': 'qasm_simulator', 'shots': 1024}, 'feature_map': {'name': 'SecondOrderExpansion', \\ 'depth': 2, 'entanglement': 'linear'} } algo_input = ClassificationInput(training_input, \\ test_input, datapoints[0]) result = run_algorithm(params, algo_input) \"\"\" print ( \"testing success ratio: {}\" . format(result[ 'testing_accuracy' ])) print ( \"preduction of datapoints:\" ) print ( \"ground truth: {}\" . format(map_label_to_class_name(datapoints[ 1 ],\\ qsvm . label_to_class))) print ( \"prediction: {}\" . format(result[ 'predicted_classes' ])) testing success ratio: 1.0 preduction of datapoints: ground truth: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A',\\ 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B'] prediction: ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', \\ 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B'] print ( \"kernel matrix during the training:\" ) kernel_matrix = result[ 'kernel_matrix_training' ] img = plt . imshow(np . asmatrix(kernel_matrix),interpolation = 'nearest' ,\\ origin = 'upper' ,cmap = 'bone_r' ) plt . show() kernel matrix during the training:","title":"[Optional] Setup token to run the experiment on a real device"},{"location":"qml/qsvm/qsvm/#the-breast-cancer-dataset","text":"Now we run our algorithm with the real-world dataset: the breast cancer dataset, we use the first two principal components as features. sample_Total, training_input, test_input, class_labels = Breast_cancer( training_size = 20 , test_size = 10 , n = 2 , PLOT_DATA = True ) seed = 10598 feature_map = SecondOrderExpansion(feature_dimension = feature_dim,\\ depth = 2 , entanglement = 'linear' ) qsvm = QSVM(feature_map, training_input, test_input) backend = BasicAer . get_backend( 'qasm_simulator' ) quantum_instance = QuantumInstance(backend, shots = 1024 , \\ seed = seed, seed_transpiler = seed) result = qsvm . run(quantum_instance) \"\"\"declarative approach, re-use the params above algo_input = ClassificationInput(training_input, test_input) result = run_algorithm(params, algo_input) \"\"\" print ( \"testing success ratio: \" , result[ 'testing_accuracy' ]) testing success ratio: 0.8 print ( \"kernel matrix during the training:\" ) kernel_matrix = result[ 'kernel_matrix_training' ] img = plt . imshow(np . asmatrix(kernel_matrix),interpolation = 'nearest' ,\\ origin = 'upper' ,cmap = 'bone_r' ) plt . show() kernel matrix during the training:","title":"The breast cancer dataset"}]}